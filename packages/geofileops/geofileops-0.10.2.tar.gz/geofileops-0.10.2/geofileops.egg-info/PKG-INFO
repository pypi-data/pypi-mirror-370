Metadata-Version: 2.4
Name: geofileops
Version: 0.10.2
Summary: Python toolbox to process large vector files faster.
Home-page: https://github.com/geofileops/geofileops
Author: Pieter Roggemans
Author-email: pieter.roggemans@gmail.com
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: BSD License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3 :: Only
Classifier: Topic :: Scientific/Engineering :: GIS
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE.txt
Requires-Dist: cloudpickle
Requires-Dist: gdal>=3.6
Requires-Dist: geopandas>=0.12
Requires-Dist: numpy
Requires-Dist: packaging
Requires-Dist: pandas>=1.5
Requires-Dist: psutil
Requires-Dist: pygeoops>=0.4
Requires-Dist: pyogrio>=0.7
Requires-Dist: pyproj
Requires-Dist: shapely>=2
Provides-Extra: full
Requires-Dist: simplification; extra == "full"
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: license-file
Dynamic: provides-extra
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# geofileops 

[![Actions Status](https://github.com/geofileops/geofileops/actions/workflows/tests.yml/badge.svg?branch=main)](https://github.com/geofileops/geofileops/actions/workflows/tests.yml?query=workflow%3ATests) 
[![Coverage Status](https://codecov.io/gh/geofileops/geofileops/branch/main/graph/badge.svg)](https://codecov.io/gh/geofileops/geofileops)
[![PyPI version](https://img.shields.io/pypi/v/geofileops.svg)](https://pypi.org/project/geofileops)
[![Conda version](https://anaconda.org/conda-forge/geofileops/badges/version.svg)](https://anaconda.org/conda-forge/geofileops)
[![DOI](https://zenodo.org/badge/203202318.svg)](https://zenodo.org/doi/10.5281/zenodo.10340100)

Geofileops is a python toolbox to process large vector files faster.

Most typical GIS operations are available: e.g.
[buffer](https://geofileops.readthedocs.io/en/stable/api/geofileops.apply.html#geofileops.buffer), 
[dissolve](https://geofileops.readthedocs.io/en/stable/api/geofileops.apply.html#geofileops.dissolve),
[difference](https://geofileops.readthedocs.io/en/stable/api/geofileops.apply.html#geofileops.difference), 
[intersection](https://geofileops.readthedocs.io/en/stable/api/geofileops.apply.html#geofileops.intersection), 
[union](https://geofileops.readthedocs.io/en/stable/api/geofileops.apply.html#geofileops.union),... 

The spatial operations are tested on geopackage and shapefile input files, but
geopackage is recommended as it will give better performance. General 
[layer](https://geofileops.readthedocs.io/en/stable/reference.html#general-layer-operations)
and [file operations](https://geofileops.readthedocs.io/en/stable/reference.html#general-file-operations) can be used on the file formats supported by 
[GDAL](https://gdal.org/).

The full documentation is available on [readthedocs](https://geofileops.readthedocs.io).

Different techniques are used under the hood to be able to process large files as fast
as possible:

* process data in batches
* subdivide/merge complex geometries on the fly
* process data in different passes
* use all available CPUs

The following chart gives an impression of the speed improvement that can be expected
when processing larger files. The [benchmarks](https://github.com/geofileops/geobenchmark)
typically use input file(s) with 500K polygons, ran on a Windows PC with 12 cores and include I/O.

![Geo benchmark](https://github.com/geofileops/geobenchmark/blob/main/results_vector_ops/GeoBenchmark.png)
