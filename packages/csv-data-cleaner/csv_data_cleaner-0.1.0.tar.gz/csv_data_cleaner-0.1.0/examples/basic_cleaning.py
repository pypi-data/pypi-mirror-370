#!/usr/bin/env python3
"""
Basic CSV Data Cleaning Example

This example demonstrates the fundamental usage of the CSV Data Cleaner library
for simple data cleaning operations.

Key concepts covered:
- Initializing the cleaner
- Basic cleaning operations
- Working with file paths
- Understanding cleaning results
"""

import pandas as pd
import numpy as np
from pathlib import Path
from csv_cleaner.core.cleaner import CSVCleaner
from csv_cleaner.core.config import Config


def create_sample_data():
    """Create sample messy data for demonstration."""
    np.random.seed(42)

    # Create sample data with common issues
    data = {
        'customer_id': range(1, 101),
        'customer_name': [f'Customer_{i}' for i in range(1, 101)],
        'email': [f'customer{i}@example.com' for i in range(1, 101)],
        'age': np.random.randint(18, 80, 100),
        'salary': np.random.randint(30000, 150000, 100),
        'join_date': pd.date_range('2020-01-01', periods=100, freq='D'),
        'status': np.random.choice(['active', 'inactive', 'pending'], 100),
        'notes': [f'Note for customer {i}' for i in range(1, 101)]
    }

    df = pd.DataFrame(data)

    # Introduce common data quality issues
    # 1. Duplicate rows
    df = pd.concat([df, df.iloc[:5]])  # Add 5 duplicate rows

    # 2. Missing values
    df.loc[10:15, 'age'] = np.nan
    df.loc[20:25, 'salary'] = np.nan
    df.loc[30:35, 'email'] = ''

    # 3. Inconsistent text
    df.loc[40:45, 'customer_name'] = df.loc[40:45, 'customer_name'].str.upper()
    df.loc[50:55, 'customer_name'] = df.loc[50:55, 'customer_name'].str.lower()

    # 4. Mixed data types
    df.loc[60:65, 'age'] = 'unknown'
    df.loc[70:75, 'salary'] = 'N/A'

    return df


def basic_cleaning_example():
    """Demonstrate basic cleaning operations."""
    print("ðŸ§¹ CSV Data Cleaner - Basic Cleaning Example")
    print("=" * 50)

    # Step 1: Create sample data
    print("\n1ï¸âƒ£ Creating sample data with common issues...")
    df = create_sample_data()

    # Save original data
    input_file = "sample_data.csv"
    df.to_csv(input_file, index=False)
    print(f"   ðŸ“ Saved sample data to: {input_file}")
    print(f"   ðŸ“Š Original data shape: {df.shape}")
    print(f"   ðŸ” Issues detected:")
    print(f"      - Duplicate rows: {df.duplicated().sum()}")
    print(f"      - Missing values: {df.isnull().sum().sum()}")
    print(f"      - Empty strings: {(df == '').sum().sum()}")

    # Step 2: Initialize the cleaner
    print("\n2ï¸âƒ£ Initializing CSV Cleaner...")
    cleaner = CSVCleaner()
    print("   âœ… Cleaner initialized successfully")

    # Step 3: Define cleaning operations
    print("\n3ï¸âƒ£ Defining cleaning operations...")
    operations = [
        "remove_duplicates",    # Remove duplicate rows
        "fill_missing",         # Fill missing values
        "clean_text",           # Clean text data
        "convert_types",        # Convert data types
        "clean_names"           # Clean column names
    ]
    print(f"   ðŸŽ¯ Operations: {', '.join(operations)}")

    # Step 4: Clean the data
    print("\n4ï¸âƒ£ Performing data cleaning...")
    try:
        cleaned_df = cleaner.clean_dataframe(df, operations=operations)
        print("   âœ… Data cleaning completed successfully!")

        # Step 5: Analyze results
        print("\n5ï¸âƒ£ Analyzing cleaning results...")
        print(f"   ðŸ“Š Original shape: {df.shape}")
        print(f"   ðŸ“Š Cleaned shape: {cleaned_df.shape}")
        print(f"   ðŸ—‘ï¸  Rows removed: {df.shape[0] - cleaned_df.shape[0]}")
        print(f"   ðŸ§¹ Missing values before: {df.isnull().sum().sum()}")
        print(f"   ðŸ§¹ Missing values after: {cleaned_df.isnull().sum().sum()}")

        # Step 6: Save cleaned data
        output_file = "cleaned_data.csv"
        cleaned_df.to_csv(output_file, index=False)
        print(f"\n6ï¸âƒ£ Saving cleaned data...")
        print(f"   ðŸ’¾ Cleaned data saved to: {output_file}")

        # Step 7: Display sample of cleaned data
        print("\n7ï¸âƒ£ Sample of cleaned data:")
        print(cleaned_df.head())

        return cleaned_df

    except Exception as e:
        print(f"   âŒ Error during cleaning: {e}")
        return None


def file_cleaning_example():
    """Demonstrate cleaning files directly."""
    print("\n" + "=" * 50)
    print("ðŸ“ File-Based Cleaning Example")
    print("=" * 50)

    # Create sample file if it doesn't exist
    input_file = "sample_data.csv"
    if not Path(input_file).exists():
        df = create_sample_data()
        df.to_csv(input_file, index=False)

    # Initialize cleaner
    cleaner = CSVCleaner()

    # Clean file directly
    output_file = "file_cleaned_data.csv"
    operations = ["remove_duplicates", "fill_missing", "clean_names"]

    print(f"\nðŸŽ¯ Cleaning file: {input_file} -> {output_file}")
    print(f"ðŸ”§ Operations: {', '.join(operations)}")

    try:
        # Clean file and get summary
        summary = cleaner.clean_file(input_file, output_file, operations=operations)

        print("\nðŸ“Š Cleaning Summary:")
        print(f"   â±ï¸  Processing time: {summary.get('processing_time', 'N/A')}")
        print(f"   ðŸ“ˆ Rows processed: {summary.get('rows_processed', 'N/A')}")
        print(f"   ðŸ—‘ï¸  Rows removed: {summary.get('rows_removed', 'N/A')}")
        print(f"   ðŸ—‘ï¸  Columns removed: {summary.get('columns_removed', 'N/A')}")
        print(f"   âœ… Success: {summary.get('success', 'N/A')}")

        # Load and display results
        cleaned_df = pd.read_csv(output_file)
        print(f"\nðŸ“Š Final data shape: {cleaned_df.shape}")
        print("\nðŸ“‹ Sample of cleaned data:")
        print(cleaned_df.head())

    except Exception as e:
        print(f"âŒ Error: {e}")


def custom_configuration_example():
    """Demonstrate custom configuration."""
    print("\n" + "=" * 50)
    print("âš™ï¸ Custom Configuration Example")
    print("=" * 50)

    # Create custom configuration
    config = Config(
        # Performance settings
        max_memory_gb=1.0,
        chunk_size=5000,
        max_workers=2,

        # File settings
        backup_enabled=True,
        backup_suffix=".backup",

        # Logging
        log_level="INFO",

        # Default operations
        default_operations=["remove_duplicates", "fill_missing"]
    )

    print("ðŸ”§ Custom configuration created:")
    print(f"   ðŸ’¾ Max memory: {config.max_memory_gb}GB")
    print(f"   ðŸ“¦ Chunk size: {config.chunk_size}")
    print(f"   ðŸ”„ Max workers: {config.max_workers}")
    print(f"   ðŸ’¿ Backup enabled: {config.backup_enabled}")
    print(f"   ðŸŽ¯ Default operations: {config.default_operations}")

    # Initialize cleaner with custom config
    cleaner = CSVCleaner(config)

    # Create sample data
    df = create_sample_data()

    # Clean with custom configuration
    print("\nðŸ§¹ Cleaning with custom configuration...")
    cleaned_df = cleaner.clean_dataframe(df)  # Uses default operations from config

    print(f"âœ… Cleaning completed!")
    print(f"ðŸ“Š Results: {df.shape} -> {cleaned_df.shape}")


def main():
    """Run all basic cleaning examples."""
    print("ðŸš€ Starting CSV Data Cleaner Basic Examples")
    print("=" * 60)

    # Example 1: Basic DataFrame cleaning
    basic_cleaning_example()

    # Example 2: File-based cleaning
    file_cleaning_example()

    # Example 3: Custom configuration
    custom_configuration_example()

    print("\n" + "=" * 60)
    print("âœ… All basic examples completed!")
    print("\nðŸ“š Next steps:")
    print("   - Try the AI-powered cleaning examples")
    print("   - Explore performance optimization examples")
    print("   - Check out real-world scenario examples")
    print("\nðŸ“– For more information, see the documentation and other examples.")


if __name__ == "__main__":
    main()
