"""
Comprehensive tests for the text chunk overlapping utility (`inject_overlap`).

Purpose & Context:
This module provides a complete test suite for the chunk overlapping utility,
`ingenious.chunk.utils.overlap.inject_overlap`. This utility is a critical
component of the Insight Ingenious document processing pipeline for
Retrieval-Augmented Generation (RAG).

This file consolidates multiple testing strategies (property-based fuzzing and
scenario-based unit tests) to validate the function's behavior with both raw
strings and LangChain `Document` objects.
"""

from __future__ import annotations

import pytest
import regex as re
import tiktoken
from hypothesis import given
from hypothesis import strategies as st
from langchain_core.documents import Document

from ingenious.chunk.utils.overlap import inject_overlap

# Re-use the project's standard tokenizer for consistency in tests.
ENC = tiktoken.get_encoding("cl100k_base")


class TestOnRawStrings:
    """Tests the core string-manipulation logic using raw string inputs.

    These tests use property-based fuzzing to ensure the overlap algorithm is
    robust against a wide variety of text inputs and edge cases, including
    Unicode grapheme integrity.
    """

    @given(
        chunks=st.lists(
            st.text(min_size=1, max_size=120),
            min_size=2,
            max_size=6,
        ),
        k=st.integers(min_value=1, max_value=10),
    )
    def test_token_overlap_invariant(self, chunks: list[str], k: int) -> None:
        """Verifies that token-based overlap is correctly injected between raw strings.

        Rationale:
            This focused property-based test ensures the core token overlap logic is
            sound across many auto-generated inputs. This is more robust than
            relying on a few fixed examples and provides strong guarantees about
            the algorithm's behavior with varied text content.

        Args:
            chunks (list[str]): A list of strings generated by Hypothesis,
                representing the initial, non-overlapping text chunks.
            k (int): An integer generated by Hypothesis, representing the desired
                number of overlapping tokens.

        Raises:
            AssertionError: If the text at the end of a chunk does not appear
                at the beginning of the next chunk after overlap is injected.
        """
        out = inject_overlap(chunks, k, unit="tokens")

        for prev, curr in zip(out, out[1:]):
            tail_tokens = ENC.encode(prev)[-k:]
            tail_text = ENC.decode(tail_tokens)
            # Check a slightly larger segment to accommodate tokenization artifacts.
            head_text = curr[: len(tail_text) + 2]
            # Use .lstrip() to handle potential leading space tokens.
            assert head_text.lstrip().startswith(tail_text.lstrip())

    @given(
        chunks=st.lists(st.text(min_size=1, max_size=60), min_size=2, max_size=6),
        k=st.integers(min_value=1, max_value=12),
        unit=st.sampled_from(["tokens", "characters"]),
    )
    def test_overlap_fuzz_comprehensive(
        self, chunks: list[str], k: int, unit: str
    ) -> None:
        """Fuzzes both units and verifies Unicode grapheme safety.

        Rationale:
            This is a critical, broad test that ensures the function is safe for
            all its modes and doesn't corrupt complex Unicode text (like emojis
            or accented letters), a common and subtle failure point for naive
            string-slicing operations. Verifying this prevents data corruption.

        Args:
            chunks (list[str]): A list of strings generated by Hypothesis.
            k (int): The overlap size, generated by Hypothesis.
            unit (str): The unit of overlap ('tokens' or 'characters'), sampled
                by Hypothesis.

        Raises:
            AssertionError: If the overlap invariant fails or a corrupted Unicode
                grapheme is detected.
        """
        out = inject_overlap(chunks, k, unit=unit)
        assert len(out) == len(chunks)

        # 1. Verify the overlap invariant for the given unit.
        for i in range(1, len(out)):
            if unit == "characters":
                tail = out[i - 1][-k:]
                head = out[i][: k + 2]
                assert head.lstrip().startswith(tail.lstrip())
            else:  # unit == "tokens"
                tail_text = ENC.decode(ENC.encode(out[i - 1])[-k:])
                head_text = out[i][: len(tail_text) + 2]
                assert head_text.lstrip().startswith(tail_text.lstrip())

        # 2. Ensure no broken Unicode graphemes were introduced.
        grapheme_pattern = re.compile(r"\X", re.UNICODE)
        for s in out:
            for g in grapheme_pattern.findall(s):
                try:
                    g.encode("utf-16", "strict")
                except UnicodeEncodeError:
                    assert False, f"Corrupted grapheme {g!r} in string {s!r}"


class TestOnDocuments:
    """Tests behavior when input is a list of LangChain `Document` objects.

    These scenario-based tests ensure that the function's contract holds for
    the primary use case in the RAG pipeline: preserving document metadata
    while correctly injecting overlap into the `page_content`.
    """

    def test_character_overlap_and_metadata_preservation(self) -> None:
        """Validates metadata round-trip and k-character overlap for Documents.

        Rationale:
            This clear, scenario-based test targets the primary use case within
            the RAG pipeline. Preserving metadata is a critical contract for
            maintaining document provenance. This test acts as a simple, highly
            readable regression guard against breaking that contract.

        Raises:
            AssertionError: If metadata is altered or the overlap invariant fails.
        """
        docs = [
            Document(page_content="ABCDEFGHIJ", metadata={"id": 0, "source": "a"}),
            Document(page_content="KLMNOPQRST", metadata={"id": 1, "source": "b"}),
        ]
        k = 3
        out = inject_overlap(docs, k=k, unit="characters")

        # 1. Metadata must be identical.
        assert [d.metadata for d in out] == [d.metadata for d in docs]

        # 2. Overlap invariant must hold.
        # The first document's content should be unchanged.
        assert out[0].page_content == docs[0].page_content

        expected_overlap = docs[0].page_content[-k:]
        original_content = docs[1].page_content

        # The second document must start with the overlap and contain original content.
        assert out[1].page_content.lstrip().startswith(expected_overlap)
        assert original_content in out[1].page_content

    @pytest.mark.parametrize(
        "chunks, k, unit, expected_overlap_text",
        [
            (
                [
                    Document(page_content="Hello world there", metadata={"id": 0}),
                    Document(page_content="This is my friend", metadata={"id": 1}),
                ],
                2,
                "tokens",
                " world there",
            ),
            (
                [
                    Document(page_content="Hello world there", metadata={"id": 0}),
                    Document(page_content="This is my friend", metadata={"id": 1}),
                ],
                5,
                "characters",
                "there",
            ),
        ],
    )
    def test_parametrized_overlap_and_metadata(
        self, chunks: list[Document], k: int, unit: str, expected_overlap_text: str
    ) -> None:
        """Validates metadata and overlap for Documents across multiple scenarios.

        Rationale:
            Using `pytest.mark.parametrize` allows for clean, DRY (Don't Repeat
            Yourself) testing of multiple configurations (tokens vs. characters)
            without duplicating code. It ensures both modes of operation respect
            the `Document` object contract.

        Args:
            chunks (list[Document]): A list of `Document` objects from the fixture.
            k (int): The overlap size from the fixture.
            unit (str): The unit of overlap from the fixture.
            expected_overlap_text (str): The expected string content of the overlap.

        Raises:
            AssertionError: If metadata is altered or the overlap invariant fails.
        """
        out = inject_overlap(chunks, k=k, unit=unit)

        # 1. Metadata must be identical.
        assert [d.metadata for d in out] == [d.metadata for d in chunks]

        # 2. Overlap invariant must hold.
        # Check that the start of the second chunk's content contains the
        # expected overlap text, stripping whitespace to be robust.
        assert out[1].page_content.lstrip().startswith(expected_overlap_text.lstrip())
