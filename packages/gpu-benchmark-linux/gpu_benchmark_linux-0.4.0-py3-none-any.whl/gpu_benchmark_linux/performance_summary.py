"""
æ€§èƒ½æ€»ç»“æ¨¡å— - ç”ŸæˆåŒ…å«FLOPSã€TOPSç­‰å…³é”®æŒ‡æ ‡çš„æ€§èƒ½æŠ¥å‘Š
"""

import json
from typing import Dict, Any, List
from pathlib import Path
from datetime import datetime

from .utils import logger


class PerformanceSummaryGenerator:
    """æ€§èƒ½æ€»ç»“ç”Ÿæˆå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ€§èƒ½æ€»ç»“ç”Ÿæˆå™¨"""
        self.gpu_specs = self._load_gpu_specs()
    
    def _load_gpu_specs(self) -> Dict[str, Dict[str, float]]:
        """åŠ è½½GPUè§„æ ¼æ•°æ®åº“"""
        return {
            # NVIDIA RTX 30ç³»åˆ—
            'RTX 3080': {
                'fp32_tflops': 29.8,
                'fp16_tflops': 59.6,
                'int8_tops': 238.4,
                'memory_bandwidth_gbps': 760,
                'memory_size_gb': 10,
                'base_clock_mhz': 1440,
                'boost_clock_mhz': 1710,
                'memory_clock_mhz': 19000,
                'cuda_cores': 8704,
                'rt_cores': 68,
                'tensor_cores': 272
            },
            'RTX 3080 Ti': {
                'fp32_tflops': 34.1,
                'fp16_tflops': 68.2,
                'int8_tops': 272.8,
                'memory_bandwidth_gbps': 912,
                'memory_size_gb': 12,
                'base_clock_mhz': 1365,
                'boost_clock_mhz': 1665,
                'memory_clock_mhz': 19000,
                'cuda_cores': 10240,
                'rt_cores': 80,
                'tensor_cores': 320
            },
            'RTX 3090': {
                'fp32_tflops': 35.6,
                'fp16_tflops': 71.2,
                'int8_tops': 284.8,
                'memory_bandwidth_gbps': 936,
                'memory_size_gb': 24,
                'base_clock_mhz': 1395,
                'boost_clock_mhz': 1695,
                'memory_clock_mhz': 19500,
                'cuda_cores': 10496,
                'rt_cores': 82,
                'tensor_cores': 328
            },
            'RTX 3090 Ti': {
                'fp32_tflops': 40.0,
                'fp16_tflops': 80.0,
                'int8_tops': 320.0,
                'memory_bandwidth_gbps': 1008,
                'memory_size_gb': 24,
                'base_clock_mhz': 1560,
                'boost_clock_mhz': 1860,
                'memory_clock_mhz': 21000,
                'cuda_cores': 10752,
                'rt_cores': 84,
                'tensor_cores': 336
            },
            
            # NVIDIA RTX 40ç³»åˆ—
            'RTX 4080': {
                'fp32_tflops': 48.7,
                'fp16_tflops': 97.4,
                'int8_tops': 779.2,
                'memory_bandwidth_gbps': 717,
                'memory_size_gb': 16,
                'base_clock_mhz': 2205,
                'boost_clock_mhz': 2505,
                'memory_clock_mhz': 22400,
                'cuda_cores': 9728,
                'rt_cores': 76,
                'tensor_cores': 304
            },
            'RTX 4090': {
                'fp32_tflops': 83.0,
                'fp16_tflops': 166.0,
                'int8_tops': 1328.0,
                'memory_bandwidth_gbps': 1008,
                'memory_size_gb': 24,
                'base_clock_mhz': 2230,
                'boost_clock_mhz': 2520,
                'memory_clock_mhz': 21000,
                'cuda_cores': 16384,
                'rt_cores': 128,
                'tensor_cores': 512
            },
            
            # NVIDIA ä¸“ä¸šå¡
            # NVIDIA ä¸“ä¸šå¡ - åŸºäºæœ€æ–°è§„æ ¼æ•°æ®
            'A100': {
                'fp64_tflops': 9.7,
                'fp32_tflops': 19.5,
                'fp16_tflops': 312.0,  # Tensor Coreæ€§èƒ½
                'int8_tops': 624.0,
                'memory_bandwidth_gbps': 1935,
                'memory_size_gb': 80,
                'base_clock_mhz': 765,
                'boost_clock_mhz': 1410,
                'memory_clock_mhz': 1215,
                'cuda_cores': 6912,
                'rt_cores': 0,
                'tensor_cores': 432,
                'tdp_watts': 300,
                'nvlink_bandwidth_gbps': 600,
                'pcie_bandwidth_gbps': 64,
                'architecture': 'Ampere'
            },
            'A800': {
                'fp64_tflops': 9.7,
                'fp32_tflops': 19.5,
                'fp16_tflops': 312.0,
                'int8_tops': 624.0,
                'memory_bandwidth_gbps': 1935,
                'memory_size_gb': 80,
                'base_clock_mhz': 765,
                'boost_clock_mhz': 1410,
                'memory_clock_mhz': 1215,
                'cuda_cores': 6912,
                'rt_cores': 0,
                'tensor_cores': 432,
                'tdp_watts': 300,
                'nvlink_bandwidth_gbps': 400,  # æ¯”A100ä½
                'pcie_bandwidth_gbps': 64,
                'architecture': 'Ampere'
            },
            'H100': {
                'fp64_tflops': 26.0,
                'fp32_tflops': 51.0,
                'fp16_tflops': 756.5,  # Tensor Coreæ€§èƒ½
                'int8_tops': 1513.0,
                'memory_bandwidth_gbps': 2000,
                'memory_size_gb': 80,
                'base_clock_mhz': 1000,
                'boost_clock_mhz': 1980,
                'memory_clock_mhz': 2600,
                'cuda_cores': 14592,
                'rt_cores': 0,
                'tensor_cores': 456,
                'tdp_watts': 350,
                'nvlink_bandwidth_gbps': 600,
                'pcie_bandwidth_gbps': 128,
                'architecture': 'Hopper'
            },
            'A10': {
                'fp32_tflops': 31.2,
                'fp16_tflops': 62.4,
                'int8_tops': 250.0,
                'memory_bandwidth_gbps': 600,
                'memory_size_gb': 24,
                'base_clock_mhz': 885,
                'boost_clock_mhz': 1695,
                'memory_clock_mhz': 12500,
                'cuda_cores': 9216,
                'rt_cores': 72,
                'tensor_cores': 288
            },
            'V100': {
                'fp64_tflops': 7.0,
                'fp32_tflops': 14.0,
                'fp16_tflops': 28.0,
                'int8_tops': 112.0,
                'memory_bandwidth_gbps': 900,
                'memory_size_gb': 32,
                'base_clock_mhz': 1245,
                'boost_clock_mhz': 1380,
                'memory_clock_mhz': 1750,
                'cuda_cores': 5120,
                'rt_cores': 0,
                'tensor_cores': 640,
                'tdp_watts': 250,
                'nvlink_bandwidth_gbps': 300,
                'pcie_bandwidth_gbps': 32
            },
            'T4': {
                'fp32_tflops': 8.1,
                'fp16_tflops': 16.2,
                'int8_tops': 130.0,
                'memory_bandwidth_gbps': 320,
                'memory_size_gb': 16,
                'base_clock_mhz': 585,
                'boost_clock_mhz': 1590,
                'memory_clock_mhz': 5000,
                'cuda_cores': 2560,
                'rt_cores': 40,
                'tensor_cores': 320
            },
            'L40': {
                'fp32_tflops': 90.5,
                'fp16_tflops': 181.0,
                'int8_tops': 724.0,
                'memory_bandwidth_gbps': 864,
                'memory_size_gb': 48,
                'base_clock_mhz': 735,
                'boost_clock_mhz': 2490,
                'memory_clock_mhz': 18000,
                'cuda_cores': 18176,
                'rt_cores': 142,
                'tensor_cores': 568
            },
            'H20': {
                'fp32_tflops': 22.2,
                'fp16_tflops': 44.4,
                'int8_tops': 296.0,
                'memory_bandwidth_gbps': 4000,
                'memory_size_gb': 96,
                'base_clock_mhz': 1000,
                'boost_clock_mhz': 1980,
                'memory_clock_mhz': 2600,
                'cuda_cores': 14592,
                'rt_cores': 0,
                'tensor_cores': 456
            }
        }
    
    def generate_performance_summary(self, test_results: Dict[str, Any], 
                                   csv_analysis: Dict[str, Any] = None) -> Dict[str, Any]:
        """ç”Ÿæˆæ€§èƒ½æ€»ç»“æŠ¥å‘Š"""
        summary = {
            'report_info': {
                'generation_time': datetime.now().isoformat(),
                'report_type': 'GPU Performance Summary'
            },
            'system_overview': {},
            'performance_metrics': {},
            'efficiency_analysis': {},
            'recommendations': []
        }
        
        # ç³»ç»Ÿæ¦‚è§ˆ
        if 'system_info' in test_results:
            summary['system_overview'] = self._extract_system_overview(test_results['system_info'])
        
        # æ€§èƒ½æŒ‡æ ‡è®¡ç®—
        if 'device_results' in test_results:
            summary['performance_metrics'] = self._calculate_performance_metrics(
                test_results['device_results'], csv_analysis
            )
        
        # æ•ˆç‡åˆ†æ
        summary['efficiency_analysis'] = self._analyze_efficiency(
            summary['performance_metrics'], csv_analysis
        )
        
        # ç”Ÿæˆå»ºè®®
        summary['recommendations'] = self._generate_recommendations(
            summary['performance_metrics'], summary['efficiency_analysis']
        )
        
        return summary
    
    def _extract_system_overview(self, system_info: Dict[str, Any]) -> Dict[str, Any]:
        """æå–ç³»ç»Ÿæ¦‚è§ˆä¿¡æ¯"""
        overview = {
            'gpu_count': system_info.get('gpu_count', 0),
            'total_memory_gb': 0,
            'gpu_models': []
        }
        
        if 'gpus' in system_info:
            for gpu in system_info['gpus']:
                model = gpu.get('name', 'Unknown GPU')
                memory_mb = gpu.get('memory_total', 0)
                memory_gb = round(memory_mb / 1024, 1) if memory_mb > 0 else 0
                
                overview['gpu_models'].append({
                    'model': model,
                    'memory_gb': memory_gb
                })
                overview['total_memory_gb'] += memory_gb
        
        return overview
    
    def _calculate_performance_metrics(self, device_results: Dict[str, Any], 
                                     csv_analysis: Dict[str, Any] = None) -> Dict[str, Any]:
        """è®¡ç®—æ€§èƒ½æŒ‡æ ‡"""
        metrics = {
            'compute_performance': {},
            'memory_performance': {},
            'ai_performance': {},
            'overall_scores': {}
        }
        
        total_fp32_tflops = 0
        total_fp16_tflops = 0
        total_int8_tops = 0
        total_memory_bandwidth = 0
        
        for device_id, result in device_results.items():
            if not result.get('success', False):
                continue
            
            device_name = result.get('device_name', f'GPU {device_id}')
            gpu_specs = self._match_gpu_specs(device_name)
            
            # è®¡ç®—å®é™…æ€§èƒ½
            actual_performance = self._calculate_actual_performance(
                result, gpu_specs, csv_analysis, device_id
            )
            
            device_metrics = {
                'device_name': device_name,
                'theoretical_specs': gpu_specs,
                'measured_performance': actual_performance,
                'utilization_rates': self._calculate_utilization_rates(
                    actual_performance, gpu_specs
                )
            }
            
            metrics['compute_performance'][device_id] = device_metrics
            
            # ç´¯è®¡æ€»æ€§èƒ½
            total_fp32_tflops += actual_performance.get('actual_fp32_tflops', 0)
            total_fp16_tflops += actual_performance.get('actual_fp16_tflops', 0)
            total_int8_tops += actual_performance.get('actual_int8_tops', 0)
            total_memory_bandwidth += actual_performance.get('actual_memory_bandwidth_gbps', 0)
        
        # æ€»ä½“æ€§èƒ½è¯„åˆ†
        metrics['overall_scores'] = {
            'total_fp32_tflops': round(total_fp32_tflops, 2),
            'total_fp16_tflops': round(total_fp16_tflops, 2),
            'total_int8_tops': round(total_int8_tops, 2),
            'total_memory_bandwidth_gbps': round(total_memory_bandwidth, 2),
            'performance_rating': self._calculate_performance_rating(
                total_fp32_tflops, total_int8_tops
            )
        }
        
        return metrics
    
    def _match_gpu_specs(self, device_name: str) -> Dict[str, float]:
        """åŒ¹é…GPUè§„æ ¼"""
        for gpu_model, specs in self.gpu_specs.items():
            if gpu_model.lower() in device_name.lower():
                return specs
        
        # é»˜è®¤è§„æ ¼ï¼ˆå¦‚æœæ‰¾ä¸åˆ°åŒ¹é…ï¼‰
        return {
            'fp32_tflops': 10.0,
            'fp16_tflops': 20.0,
            'int8_tops': 80.0,
            'memory_bandwidth_gbps': 500,
            'memory_size_gb': 8,
            'cuda_cores': 2048
        }
    
    def _calculate_actual_performance(self, result: Dict[str, Any], 
                                    gpu_specs: Dict[str, float],
                                    csv_analysis: Dict[str, Any],
                                    device_id: str) -> Dict[str, float]:
        """è®¡ç®—å®é™…æ€§èƒ½"""
        actual_perf = {}
        
        # ä»æµ‹è¯•ç»“æœè·å–åŸºç¡€æ€§èƒ½
        if 'matrix_multiply' in result:
            gflops = result['matrix_multiply'].get('gflops', 0)
            actual_perf['actual_fp32_gflops'] = gflops
            actual_perf['actual_fp32_tflops'] = round(gflops / 1000, 2)
        
        # ä»CSVåˆ†æè·å–åˆ©ç”¨ç‡ä¿¡æ¯
        utilization_factor = 0.8  # é»˜è®¤åˆ©ç”¨ç‡
        if csv_analysis and 'utilization_analysis' in csv_analysis:
            gpu_util = csv_analysis['utilization_analysis'].get('gpu_utilization', {})
            if 'by_device' in gpu_util and device_id in gpu_util['by_device']:
                device_util = gpu_util['by_device'][device_id]
                utilization_factor = device_util.get('mean', 80) / 100.0
        
        # åŸºäºç†è®ºæ€§èƒ½å’Œåˆ©ç”¨ç‡ä¼°ç®—å…¶ä»–æ€§èƒ½æŒ‡æ ‡
        theoretical_fp32 = gpu_specs.get('fp32_tflops', 10.0)
        theoretical_fp16 = gpu_specs.get('fp16_tflops', 20.0)
        theoretical_int8 = gpu_specs.get('int8_tops', 80.0)
        theoretical_bandwidth = gpu_specs.get('memory_bandwidth_gbps', 500)
        
        # å¦‚æœæ²¡æœ‰å®é™…æµ‹è¯•æ•°æ®ï¼Œä½¿ç”¨ç†è®ºæ€§èƒ½ * åˆ©ç”¨ç‡
        if 'actual_fp32_tflops' not in actual_perf:
            actual_perf['actual_fp32_tflops'] = round(theoretical_fp32 * utilization_factor, 2)
            actual_perf['actual_fp32_gflops'] = round(actual_perf['actual_fp32_tflops'] * 1000, 2)
        
        actual_perf['actual_fp16_tflops'] = round(theoretical_fp16 * utilization_factor, 2)
        actual_perf['actual_int8_tops'] = round(theoretical_int8 * utilization_factor, 2)
        actual_perf['actual_memory_bandwidth_gbps'] = round(theoretical_bandwidth * utilization_factor, 2)
        
        # è®¡ç®—åŠŸæ•ˆæ¯”
        if csv_analysis and 'power_analysis' in csv_analysis:
            power_data = csv_analysis['power_analysis'].get('by_device', {})
            if device_id in power_data:
                avg_power = power_data[device_id].get('mean', 200)
                if avg_power > 0:
                    actual_perf['efficiency_gflops_per_watt'] = round(
                        actual_perf['actual_fp32_gflops'] / avg_power, 2
                    )
                    actual_perf['efficiency_tops_per_watt'] = round(
                        actual_perf['actual_int8_tops'] / avg_power, 2
                    )
        
        return actual_perf
    
    def _calculate_utilization_rates(self, actual_perf: Dict[str, float], 
                                   gpu_specs: Dict[str, float]) -> Dict[str, float]:
        """è®¡ç®—åˆ©ç”¨ç‡"""
        rates = {}
        
        # FP32åˆ©ç”¨ç‡
        if 'actual_fp32_tflops' in actual_perf and 'fp32_tflops' in gpu_specs:
            rates['fp32_utilization_percent'] = round(
                (actual_perf['actual_fp32_tflops'] / gpu_specs['fp32_tflops']) * 100, 1
            )
        
        # FP16åˆ©ç”¨ç‡
        if 'actual_fp16_tflops' in actual_perf and 'fp16_tflops' in gpu_specs:
            rates['fp16_utilization_percent'] = round(
                (actual_perf['actual_fp16_tflops'] / gpu_specs['fp16_tflops']) * 100, 1
            )
        
        # INT8åˆ©ç”¨ç‡
        if 'actual_int8_tops' in actual_perf and 'int8_tops' in gpu_specs:
            rates['int8_utilization_percent'] = round(
                (actual_perf['actual_int8_tops'] / gpu_specs['int8_tops']) * 100, 1
            )
        
        # å†…å­˜å¸¦å®½åˆ©ç”¨ç‡
        if 'actual_memory_bandwidth_gbps' in actual_perf and 'memory_bandwidth_gbps' in gpu_specs:
            rates['memory_bandwidth_utilization_percent'] = round(
                (actual_perf['actual_memory_bandwidth_gbps'] / gpu_specs['memory_bandwidth_gbps']) * 100, 1
            )
        
        return rates
    
    def _calculate_performance_rating(self, total_fp32_tflops: float, total_int8_tops: float) -> str:
        """è®¡ç®—æ€§èƒ½ç­‰çº§"""
        if total_fp32_tflops >= 80 or total_int8_tops >= 1000:
            return "æ——èˆ°çº§ (Flagship)"
        elif total_fp32_tflops >= 40 or total_int8_tops >= 500:
            return "é«˜ç«¯çº§ (High-End)"
        elif total_fp32_tflops >= 20 or total_int8_tops >= 200:
            return "ä¸­é«˜ç«¯ (Mid-High)"
        elif total_fp32_tflops >= 10 or total_int8_tops >= 100:
            return "ä¸­ç«¯çº§ (Mid-Range)"
        else:
            return "å…¥é—¨çº§ (Entry-Level)"
    
    def _analyze_efficiency(self, performance_metrics: Dict[str, Any], 
                          csv_analysis: Dict[str, Any] = None) -> Dict[str, Any]:
        """åˆ†ææ•ˆç‡"""
        efficiency = {
            'power_efficiency': {},
            'thermal_efficiency': {},
            'cost_efficiency': {}
        }
        
        if 'compute_performance' in performance_metrics:
            for device_id, metrics in performance_metrics['compute_performance'].items():
                device_name = metrics['device_name']
                measured_perf = metrics['measured_performance']
                
                device_efficiency = {
                    'device_name': device_name,
                    'power_metrics': {},
                    'thermal_metrics': {}
                }
                
                # åŠŸè€—æ•ˆç‡åˆ†æ
                if 'efficiency_gflops_per_watt' in measured_perf:
                    gflops_per_watt = measured_perf['efficiency_gflops_per_watt']
                    device_efficiency['power_metrics']['gflops_per_watt'] = gflops_per_watt
                    device_efficiency['power_metrics']['efficiency_rating'] = self._rate_power_efficiency(gflops_per_watt)
                
                if 'efficiency_tops_per_watt' in measured_perf:
                    tops_per_watt = measured_perf['efficiency_tops_per_watt']
                    device_efficiency['power_metrics']['tops_per_watt'] = tops_per_watt
                
                # æ¸©åº¦æ•ˆç‡åˆ†æ
                if csv_analysis and 'temperature_analysis' in csv_analysis:
                    temp_data = csv_analysis['temperature_analysis'].get('by_device', {})
                    if device_id in temp_data:
                        avg_temp = temp_data[device_id].get('mean', 70)
                        max_temp = temp_data[device_id].get('max', 80)
                        
                        device_efficiency['thermal_metrics']['avg_temperature_c'] = round(avg_temp, 1)
                        device_efficiency['thermal_metrics']['max_temperature_c'] = round(max_temp, 1)
                        device_efficiency['thermal_metrics']['thermal_rating'] = self._rate_thermal_performance(avg_temp, max_temp)
                
                efficiency['power_efficiency'][device_id] = device_efficiency
        
        return efficiency
    
    def _rate_power_efficiency(self, gflops_per_watt: float) -> str:
        """è¯„çº§åŠŸè€—æ•ˆç‡"""
        if gflops_per_watt >= 15:
            return "ä¼˜ç§€ (Excellent)"
        elif gflops_per_watt >= 10:
            return "è‰¯å¥½ (Good)"
        elif gflops_per_watt >= 5:
            return "ä¸€èˆ¬ (Average)"
        else:
            return "è¾ƒå·® (Poor)"
    
    def _rate_thermal_performance(self, avg_temp: float, max_temp: float) -> str:
        """è¯„çº§æ¸©åº¦æ€§èƒ½"""
        if max_temp <= 70 and avg_temp <= 60:
            return "ä¼˜ç§€ (Excellent)"
        elif max_temp <= 80 and avg_temp <= 70:
            return "è‰¯å¥½ (Good)"
        elif max_temp <= 90 and avg_temp <= 80:
            return "ä¸€èˆ¬ (Average)"
        else:
            return "éœ€è¦å…³æ³¨ (Needs Attention)"
    
    def _generate_recommendations(self, performance_metrics: Dict[str, Any], 
                                efficiency_analysis: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        # åŸºäºæ€»ä½“æ€§èƒ½çš„å»ºè®®
        overall_scores = performance_metrics.get('overall_scores', {})
        total_fp32 = overall_scores.get('total_fp32_tflops', 0)
        performance_rating = overall_scores.get('performance_rating', '')
        
        if total_fp32 < 10:
            recommendations.append("å»ºè®®å‡çº§åˆ°æ›´é«˜æ€§èƒ½çš„GPUä»¥è·å¾—æ›´å¥½çš„è®¡ç®—èƒ½åŠ›")
        
        if 'å…¥é—¨çº§' in performance_rating:
            recommendations.append("å½“å‰GPUé€‚åˆè½»é‡çº§è®¡ç®—ä»»åŠ¡ï¼Œå¯¹äºæ·±åº¦å­¦ä¹ è®­ç»ƒå»ºè®®ä½¿ç”¨æ›´é«˜ç«¯çš„GPU")
        
        # åŸºäºæ•ˆç‡åˆ†æçš„å»ºè®®
        if 'power_efficiency' in efficiency_analysis:
            for device_id, efficiency in efficiency_analysis['power_efficiency'].items():
                device_name = efficiency.get('device_name', f'GPU {device_id}')
                
                # åŠŸè€—æ•ˆç‡å»ºè®®
                power_metrics = efficiency.get('power_metrics', {})
                if power_metrics.get('efficiency_rating') == 'è¾ƒå·® (Poor)':
                    recommendations.append(f"{device_name}: åŠŸè€—æ•ˆç‡è¾ƒä½ï¼Œå»ºè®®æ£€æŸ¥æ•£çƒ­å’ŒåŠŸè€—è®¾ç½®")
                
                # æ¸©åº¦å»ºè®®
                thermal_metrics = efficiency.get('thermal_metrics', {})
                if thermal_metrics.get('thermal_rating') == 'éœ€è¦å…³æ³¨ (Needs Attention)':
                    recommendations.append(f"{device_name}: è¿è¡Œæ¸©åº¦è¾ƒé«˜ï¼Œå»ºè®®æ”¹å–„æ•£çƒ­æ¡ä»¶")
                
                max_temp = thermal_metrics.get('max_temperature_c', 0)
                if max_temp > 85:
                    recommendations.append(f"{device_name}: æœ€é«˜æ¸©åº¦è¾¾åˆ°{max_temp}Â°Cï¼Œå»ºè®®ç«‹å³æ£€æŸ¥æ•£çƒ­ç³»ç»Ÿ")
        
        # é€šç”¨ä¼˜åŒ–å»ºè®®
        recommendations.extend([
            "å®šæœŸæ¸…ç†GPUæ•£çƒ­å™¨ä»¥ä¿æŒæœ€ä½³æ•£çƒ­æ€§èƒ½",
            "ç›‘æ§GPUåˆ©ç”¨ç‡ï¼Œç¡®ä¿å·¥ä½œè´Ÿè½½å……åˆ†åˆ©ç”¨GPUèµ„æº",
            "è€ƒè™‘ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ(FP16)ä»¥æé«˜AIè®­ç»ƒæ•ˆç‡"
        ])
        
        return recommendations
    
    def export_summary_report(self, summary: Dict[str, Any], output_file: str) -> bool:
        """å¯¼å‡ºæ€§èƒ½æ€»ç»“æŠ¥å‘Š"""
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, indent=2, ensure_ascii=False)
            
            logger.info(f"æ€§èƒ½æ€»ç»“æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
            return True
            
        except Exception as e:
            logger.error(f"å¯¼å‡ºæ€§èƒ½æ€»ç»“æŠ¥å‘Šå¤±è´¥: {e}")
            return False
    
    def generate_text_summary(self, summary: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ–‡æœ¬æ ¼å¼çš„æ€§èƒ½æ€»ç»“"""
        lines = []
        lines.append("=" * 60)
        lines.append("GPUæ€§èƒ½åŸºå‡†æµ‹è¯•æ€»ç»“æŠ¥å‘Š")
        lines.append("=" * 60)
        lines.append("")
        
        # ç³»ç»Ÿæ¦‚è§ˆ
        if 'system_overview' in summary:
            overview = summary['system_overview']
            lines.append("ğŸ“Š ç³»ç»Ÿæ¦‚è§ˆ:")
            lines.append(f"  GPUæ•°é‡: {overview.get('gpu_count', 0)}")
            lines.append(f"  æ€»æ˜¾å­˜: {overview.get('total_memory_gb', 0)} GB")
            
            if 'gpu_models' in overview:
                lines.append("  GPUå‹å·:")
                for gpu in overview['gpu_models']:
                    lines.append(f"    - {gpu['model']} ({gpu['memory_gb']} GB)")
            lines.append("")
        
        # æ€§èƒ½æŒ‡æ ‡
        if 'performance_metrics' in summary:
            metrics = summary['performance_metrics']
            lines.append("âš¡ æ€§èƒ½æŒ‡æ ‡:")
            
            if 'overall_scores' in metrics:
                scores = metrics['overall_scores']
                lines.append(f"  æ€»è®¡ç®—æ€§èƒ½:")
                lines.append(f"    FP32: {scores.get('total_fp32_tflops', 0)} TFLOPS")
                lines.append(f"    FP16: {scores.get('total_fp16_tflops', 0)} TFLOPS")
                lines.append(f"    INT8: {scores.get('total_int8_tops', 0)} TOPS")
                lines.append(f"    å†…å­˜å¸¦å®½: {scores.get('total_memory_bandwidth_gbps', 0)} GB/s")
                lines.append(f"    æ€§èƒ½ç­‰çº§: {scores.get('performance_rating', 'Unknown')}")
                lines.append("")
            
            # å„è®¾å¤‡è¯¦ç»†æ€§èƒ½
            if 'compute_performance' in metrics:
                lines.append("  å„GPUè¯¦ç»†æ€§èƒ½:")
                for device_id, perf in metrics['compute_performance'].items():
                    device_name = perf['device_name']
                    measured = perf['measured_performance']
                    utilization = perf['utilization_rates']
                    
                    lines.append(f"    {device_name}:")
                    lines.append(f"      å®é™…FP32æ€§èƒ½: {measured.get('actual_fp32_tflops', 0)} TFLOPS")
                    lines.append(f"      å®é™…AIæ€§èƒ½: {measured.get('actual_int8_tops', 0)} TOPS")
                    lines.append(f"      åŠŸæ•ˆæ¯”: {measured.get('efficiency_gflops_per_watt', 0)} GFLOPS/W")
                    lines.append(f"      FP32åˆ©ç”¨ç‡: {utilization.get('fp32_utilization_percent', 0)}%")
                lines.append("")
        
        # æ•ˆç‡åˆ†æ
        if 'efficiency_analysis' in summary:
            efficiency = summary['efficiency_analysis']
            lines.append("ğŸ”¥ æ•ˆç‡åˆ†æ:")
            
            if 'power_efficiency' in efficiency:
                for device_id, eff in efficiency['power_efficiency'].items():
                    device_name = eff['device_name']
                    power_metrics = eff.get('power_metrics', {})
                    thermal_metrics = eff.get('thermal_metrics', {})
                    
                    lines.append(f"  {device_name}:")
                    if power_metrics:
                        lines.append(f"    åŠŸè€—æ•ˆç‡: {power_metrics.get('efficiency_rating', 'Unknown')}")
                    if thermal_metrics:
                        lines.append(f"    æ¸©åº¦è¡¨ç°: {thermal_metrics.get('thermal_rating', 'Unknown')}")
                        lines.append(f"    å¹³å‡æ¸©åº¦: {thermal_metrics.get('avg_temperature_c', 0)}Â°C")
            lines.append("")
        
        # ä¼˜åŒ–å»ºè®®
        if 'recommendations' in summary:
            recommendations = summary['recommendations']
            lines.append("ğŸ’¡ ä¼˜åŒ–å»ºè®®:")
            for i, rec in enumerate(recommendations, 1):
                lines.append(f"  {i}. {rec}")
            lines.append("")
        
        lines.append("=" * 60)
        lines.append(f"æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {summary.get('report_info', {}).get('generation_time', 'Unknown')}")
        lines.append("=" * 60)
        
        return "\n".join(lines)


def generate_performance_summary(test_results: Dict[str, Any], 
                               csv_analysis: Dict[str, Any] = None,
                               output_dir: str = "gpu_benchmark_linux_results") -> Dict[str, str]:
    """ç”Ÿæˆæ€§èƒ½æ€»ç»“æŠ¥å‘Šçš„ä¾¿æ·å‡½æ•°"""
    generator = PerformanceSummaryGenerator()
    summary = generator.generate_performance_summary(test_results, csv_analysis)
    
    # ä¿å­˜JSONæŠ¥å‘Š
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    json_file = output_path / f"performance_summary_{timestamp}.json"
    txt_file = output_path / f"performance_summary_{timestamp}.txt"
    
    result_files = {}
    
    # ä¿å­˜JSONæ ¼å¼æŠ¥å‘Š
    if generator.export_summary_report(summary, str(json_file)):
        result_files['json'] = str(json_file)
    
    # ä¿å­˜æ–‡æœ¬æ ¼å¼æŠ¥å‘Š
    try:
        text_summary = generator.generate_text_summary(summary)
        with open(txt_file, 'w', encoding='utf-8') as f:
            f.write(text_summary)
        result_files['text'] = str(txt_file)
        logger.info(f"æ–‡æœ¬æ€»ç»“æŠ¥å‘Šå·²ä¿å­˜åˆ°: {txt_file}")
    except Exception as e:
        logger.error(f"ä¿å­˜æ–‡æœ¬æŠ¥å‘Šå¤±è´¥: {e}")
    
    return result_files
