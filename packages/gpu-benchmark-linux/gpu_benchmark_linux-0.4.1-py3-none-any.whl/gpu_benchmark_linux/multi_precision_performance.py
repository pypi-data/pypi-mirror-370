"""
å¤šç²¾åº¦æ€§èƒ½æŒ‡æ ‡æ¨¡å— - æ”¯æŒFP64/FP32/FP16/FP8/INT8/INT4ç­‰æ‰€æœ‰ç²¾åº¦
ç¡®ä¿æ‰€æœ‰è¾“å‡ºæ ¼å¼ï¼ˆlogã€CSVã€JSONã€HTMLï¼‰éƒ½åŒ…å«å®Œæ•´çš„å¤šç²¾åº¦ç®—åŠ›æŒ‡æ ‡
"""

import json
from typing import Dict, Any, List
from pathlib import Path
from datetime import datetime

from .utils import logger


class MultiPrecisionPerformanceAnalyzer:
    """å¤šç²¾åº¦æ€§èƒ½åˆ†æå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–å¤šç²¾åº¦æ€§èƒ½åˆ†æå™¨"""
        self.precision_types = ['fp64', 'fp32', 'fp16', 'fp8', 'int8', 'int4']
        self.gpu_specs = self._load_enhanced_gpu_specs()
    
    def _load_enhanced_gpu_specs(self) -> Dict[str, Dict[str, Any]]:
        """åŠ è½½å¢å¼ºçš„GPUè§„æ ¼æ•°æ®åº“ï¼ŒåŒ…å«æ‰€æœ‰ç²¾åº¦æŒ‡æ ‡"""
        return {
            # NVIDIA H100 - æœ€æ–°Hopperæ¶æ„
            'H100': {
                'fp64_tflops': 26.0,
                'fp32_tflops': 51.0,
                'fp16_tflops': 756.5,  # Tensor Coreæ€§èƒ½
                'fp8_tops': 3026.0,   # FP8 E4M3/E5M2æ€§èƒ½ (Hopperæ¶æ„ä¼˜åŠ¿)
                'int8_tops': 1513.0,
                'int4_tops': 6052.0,  # INT4æ€§èƒ½
                'memory_bandwidth_gbps': 2000,
                'memory_size_gb': 80,
                'architecture': 'Hopper',
                'tensor_cores': 456,
                'cuda_cores': 14592
            },
            
            # NVIDIA A100 - Ampereæ¶æ„
            'A100': {
                'fp64_tflops': 9.7,
                'fp32_tflops': 19.5,
                'fp16_tflops': 312.0,  # Tensor Coreæ€§èƒ½
                'fp8_tops': 1248.0,   # FP8 E4M3/E5M2æ€§èƒ½
                'int8_tops': 624.0,
                'int4_tops': 2496.0,  # INT4æ€§èƒ½
                'memory_bandwidth_gbps': 1935,
                'memory_size_gb': 80,
                'architecture': 'Ampere',
                'tensor_cores': 432,
                'cuda_cores': 6912
            },
            
            # NVIDIA A800 - Ampereæ¶æ„ï¼ˆä¸­å›½ç‰ˆï¼‰
            'A800': {
                'fp64_tflops': 9.7,
                'fp32_tflops': 19.5,
                'fp16_tflops': 312.0,
                'fp8_tops': 1248.0,
                'int8_tops': 624.0,
                'int4_tops': 2496.0,
                'memory_bandwidth_gbps': 1935,
                'memory_size_gb': 80,
                'architecture': 'Ampere',
                'tensor_cores': 432,
                'cuda_cores': 6912
            },
            
            # NVIDIA RTX 4090 - Ada Lovelaceæ¶æ„
            'RTX 4090': {
                'fp64_tflops': 2.6,   # æ¶ˆè´¹çº§å¡FP64æ€§èƒ½è¾ƒä½
                'fp32_tflops': 83.0,
                'fp16_tflops': 166.0,
                'fp8_tops': 664.0,    # FP8æ€§èƒ½ (Ada Lovelaceæ¶æ„)
                'int8_tops': 1328.0,
                'int4_tops': 2656.0,  # INT4æ€§èƒ½
                'memory_bandwidth_gbps': 1008,
                'memory_size_gb': 24,
                'architecture': 'Ada Lovelace',
                'tensor_cores': 512,
                'cuda_cores': 16384
            },
            
            # NVIDIA RTX 4080 - Ada Lovelaceæ¶æ„
            'RTX 4080': {
                'fp64_tflops': 1.5,
                'fp32_tflops': 48.7,
                'fp16_tflops': 97.4,
                'fp8_tops': 389.6,
                'int8_tops': 779.2,
                'int4_tops': 1558.4,
                'memory_bandwidth_gbps': 717,
                'memory_size_gb': 16,
                'architecture': 'Ada Lovelace',
                'tensor_cores': 304,
                'cuda_cores': 9728
            },
            
            # NVIDIA L40 - Ada Lovelaceæ¶æ„ä¸“ä¸šå¡
            'L40': {
                'fp64_tflops': 2.8,
                'fp32_tflops': 90.5,
                'fp16_tflops': 181.0,
                'fp8_tops': 724.0,
                'int8_tops': 1448.0,
                'int4_tops': 2896.0,
                'memory_bandwidth_gbps': 864,
                'memory_size_gb': 48,
                'architecture': 'Ada Lovelace',
                'tensor_cores': 568,
                'cuda_cores': 18176
            },
            
            # NVIDIA V100 - Voltaæ¶æ„
            'V100': {
                'fp64_tflops': 7.0,
                'fp32_tflops': 14.0,
                'fp16_tflops': 28.0,
                'fp8_tops': 0,        # Voltaä¸æ”¯æŒFP8
                'int8_tops': 112.0,
                'int4_tops': 224.0,
                'memory_bandwidth_gbps': 900,
                'memory_size_gb': 32,
                'architecture': 'Volta',
                'tensor_cores': 640,
                'cuda_cores': 5120
            },
            
            # NVIDIA T4 - Turingæ¶æ„
            'T4': {
                'fp64_tflops': 0.25,  # Turingæ¶æ„FP64æ€§èƒ½å¾ˆä½
                'fp32_tflops': 8.1,
                'fp16_tflops': 16.2,
                'fp8_tops': 0,        # Turingä¸æ”¯æŒFP8
                'int8_tops': 130.0,
                'int4_tops': 260.0,
                'memory_bandwidth_gbps': 320,
                'memory_size_gb': 16,
                'architecture': 'Turing',
                'tensor_cores': 320,
                'cuda_cores': 2560
            },
            
            # NVIDIA A10 - Ampereæ¶æ„
            'A10': {
                'fp64_tflops': 1.0,
                'fp32_tflops': 31.2,
                'fp16_tflops': 62.4,
                'fp8_tops': 249.6,
                'int8_tops': 250.0,
                'int4_tops': 500.0,
                'memory_bandwidth_gbps': 600,
                'memory_size_gb': 24,
                'architecture': 'Ampere',
                'tensor_cores': 288,
                'cuda_cores': 9216
            },
            
            # NVIDIA H20 - Hopperæ¶æ„ï¼ˆä¸­å›½ç‰ˆï¼‰
            'H20': {
                'fp64_tflops': 11.0,
                'fp32_tflops': 22.2,
                'fp16_tflops': 148.0,
                'fp8_tops': 592.0,
                'int8_tops': 296.0,
                'int4_tops': 1184.0,
                'memory_bandwidth_gbps': 4000,
                'memory_size_gb': 96,
                'architecture': 'Hopper',
                'tensor_cores': 456,
                'cuda_cores': 14592
            }
        }
    
    def calculate_multi_precision_performance(self, test_results: Dict[str, Any], 
                                            csv_analysis: Dict[str, Any] = None) -> Dict[str, Any]:
        """è®¡ç®—å¤šç²¾åº¦æ€§èƒ½æŒ‡æ ‡"""
        multi_precision_metrics = {
            'precision_breakdown': {},
            'total_performance': {},
            'utilization_analysis': {},
            'architecture_analysis': {}
        }
        
        # åˆå§‹åŒ–æ€»æ€§èƒ½è®¡æ•°å™¨
        total_metrics = {
            'total_fp64_tflops': 0.0,
            'total_fp32_tflops': 0.0,
            'total_fp16_tflops': 0.0,
            'total_fp8_tops': 0.0,
            'total_int8_tops': 0.0,
            'total_int4_tops': 0.0,
            'total_memory_bandwidth_gbps': 0.0
        }
        
        device_results = test_results.get('device_results', {})
        
        for device_id, result in device_results.items():
            if not result.get('success', False):
                continue
            
            device_name = result.get('device_name', f'GPU {device_id}')
            gpu_specs = self._match_gpu_specs(device_name)
            
            # è®¡ç®—å„ç²¾åº¦çš„å®é™…æ€§èƒ½
            device_precision_metrics = self._calculate_device_precision_performance(
                result, gpu_specs, csv_analysis, device_id
            )
            
            multi_precision_metrics['precision_breakdown'][device_id] = {
                'device_name': device_name,
                'architecture': gpu_specs.get('architecture', 'Unknown'),
                'theoretical_performance': {
                    'fp64_tflops': gpu_specs.get('fp64_tflops', 0),
                    'fp32_tflops': gpu_specs.get('fp32_tflops', 0),
                    'fp16_tflops': gpu_specs.get('fp16_tflops', 0),
                    'fp8_tops': gpu_specs.get('fp8_tops', 0),
                    'int8_tops': gpu_specs.get('int8_tops', 0),
                    'int4_tops': gpu_specs.get('int4_tops', 0),
                    'memory_bandwidth_gbps': gpu_specs.get('memory_bandwidth_gbps', 0)
                },
                'measured_performance': device_precision_metrics,
                'utilization_rates': self._calculate_precision_utilization_rates(
                    device_precision_metrics, gpu_specs
                )
            }
            
            # ç´¯è®¡æ€»æ€§èƒ½
            for precision in ['fp64_tflops', 'fp32_tflops', 'fp16_tflops', 'fp8_tops', 'int8_tops', 'int4_tops']:
                total_key = f'total_{precision}'
                actual_key = f'actual_{precision}'
                total_metrics[total_key] += device_precision_metrics.get(actual_key, 0)
            
            total_metrics['total_memory_bandwidth_gbps'] += device_precision_metrics.get('actual_memory_bandwidth_gbps', 0)
        
        # è®¾ç½®æ€»æ€§èƒ½æŒ‡æ ‡
        multi_precision_metrics['total_performance'] = {
            **total_metrics,
            'performance_rating': self._calculate_multi_precision_rating(total_metrics),
            'dominant_precision': self._identify_dominant_precision(total_metrics)
        }
        
        # æ¶æ„åˆ†æ
        multi_precision_metrics['architecture_analysis'] = self._analyze_architectures(
            multi_precision_metrics['precision_breakdown']
        )
        
        return multi_precision_metrics
    
    def _match_gpu_specs(self, device_name: str) -> Dict[str, Any]:
        """åŒ¹é…GPUè§„æ ¼"""
        device_name_upper = device_name.upper()
        
        for gpu_model, specs in self.gpu_specs.items():
            if gpu_model.upper() in device_name_upper:
                return specs
        
        # é»˜è®¤è§„æ ¼ï¼ˆå¦‚æœæ‰¾ä¸åˆ°åŒ¹é…ï¼‰
        return {
            'fp64_tflops': 1.0,
            'fp32_tflops': 10.0,
            'fp16_tflops': 20.0,
            'fp8_tops': 40.0,
            'int8_tops': 80.0,
            'int4_tops': 160.0,
            'memory_bandwidth_gbps': 500,
            'memory_size_gb': 8,
            'architecture': 'Unknown',
            'cuda_cores': 2048
        }
    
    def _calculate_device_precision_performance(self, result: Dict[str, Any], 
                                              gpu_specs: Dict[str, float],
                                              csv_analysis: Dict[str, Any],
                                              device_id: str) -> Dict[str, float]:
        """è®¡ç®—è®¾å¤‡çš„å„ç²¾åº¦å®é™…æ€§èƒ½"""
        actual_perf = {}
        
        # ä»æµ‹è¯•ç»“æœè·å–åŸºç¡€FP32æ€§èƒ½
        base_gflops = 0
        if 'matrix_multiply' in result:
            base_gflops = result['matrix_multiply'].get('gflops', 0)
            actual_perf['actual_fp32_gflops'] = base_gflops
            actual_perf['actual_fp32_tflops'] = round(base_gflops / 1000, 2)
        
        # ä»CSVåˆ†æè·å–åˆ©ç”¨ç‡ä¿¡æ¯
        utilization_factor = 0.8  # é»˜è®¤åˆ©ç”¨ç‡
        if csv_analysis and 'utilization_analysis' in csv_analysis:
            gpu_util = csv_analysis['utilization_analysis'].get('gpu_utilization', {})
            if 'by_device' in gpu_util and device_id in gpu_util['by_device']:
                device_util = gpu_util['by_device'][device_id]
                utilization_factor = device_util.get('mean', 80) / 100.0
        
        # åŸºäºç†è®ºæ€§èƒ½å’Œåˆ©ç”¨ç‡è®¡ç®—å„ç²¾åº¦æ€§èƒ½
        precision_specs = {
            'fp64_tflops': gpu_specs.get('fp64_tflops', 0),
            'fp32_tflops': gpu_specs.get('fp32_tflops', 0),
            'fp16_tflops': gpu_specs.get('fp16_tflops', 0),
            'fp8_tops': gpu_specs.get('fp8_tops', 0),
            'int8_tops': gpu_specs.get('int8_tops', 0),
            'int4_tops': gpu_specs.get('int4_tops', 0),
            'memory_bandwidth_gbps': gpu_specs.get('memory_bandwidth_gbps', 0)
        }
        
        # å¦‚æœæ²¡æœ‰å®é™…FP32æµ‹è¯•æ•°æ®ï¼Œä½¿ç”¨ç†è®ºæ€§èƒ½
        if 'actual_fp32_tflops' not in actual_perf:
            actual_perf['actual_fp32_tflops'] = round(precision_specs['fp32_tflops'] * utilization_factor, 2)
            actual_perf['actual_fp32_gflops'] = round(actual_perf['actual_fp32_tflops'] * 1000, 2)
        
        # è®¡ç®—å…¶ä»–ç²¾åº¦çš„å®é™…æ€§èƒ½
        for precision, theoretical_value in precision_specs.items():
            if precision != 'fp32_tflops':  # FP32å·²ç»å¤„ç†è¿‡äº†
                actual_key = f'actual_{precision}'
                if theoretical_value > 0:
                    actual_perf[actual_key] = round(theoretical_value * utilization_factor, 2)
                else:
                    actual_perf[actual_key] = 0.0
        
        # è®¡ç®—åŠŸæ•ˆæ¯”
        if csv_analysis and 'power_analysis' in csv_analysis:
            power_data = csv_analysis['power_analysis'].get('by_device', {})
            if device_id in power_data:
                avg_power = power_data[device_id].get('mean', 200)
                if avg_power > 0:
                    actual_perf['efficiency_fp32_gflops_per_watt'] = round(
                        actual_perf.get('actual_fp32_gflops', 0) / avg_power, 2
                    )
                    actual_perf['efficiency_int8_tops_per_watt'] = round(
                        actual_perf.get('actual_int8_tops', 0) / avg_power, 2
                    )
                    if actual_perf.get('actual_fp8_tops', 0) > 0:
                        actual_perf['efficiency_fp8_tops_per_watt'] = round(
                            actual_perf.get('actual_fp8_tops', 0) / avg_power, 2
                        )
        
        return actual_perf
    
    def _calculate_precision_utilization_rates(self, actual_perf: Dict[str, float], 
                                             gpu_specs: Dict[str, float]) -> Dict[str, float]:
        """è®¡ç®—å„ç²¾åº¦çš„åˆ©ç”¨ç‡"""
        rates = {}
        
        precision_mappings = {
            'fp64_utilization_percent': ('actual_fp64_tflops', 'fp64_tflops'),
            'fp32_utilization_percent': ('actual_fp32_tflops', 'fp32_tflops'),
            'fp16_utilization_percent': ('actual_fp16_tflops', 'fp16_tflops'),
            'fp8_utilization_percent': ('actual_fp8_tops', 'fp8_tops'),
            'int8_utilization_percent': ('actual_int8_tops', 'int8_tops'),
            'int4_utilization_percent': ('actual_int4_tops', 'int4_tops'),
            'memory_bandwidth_utilization_percent': ('actual_memory_bandwidth_gbps', 'memory_bandwidth_gbps')
        }
        
        for rate_key, (actual_key, theoretical_key) in precision_mappings.items():
            actual_value = actual_perf.get(actual_key, 0)
            theoretical_value = gpu_specs.get(theoretical_key, 0)
            
            if theoretical_value > 0 and actual_value > 0:
                rates[rate_key] = round((actual_value / theoretical_value) * 100, 1)
            else:
                rates[rate_key] = 0.0
        
        return rates
    
    def _calculate_multi_precision_rating(self, total_metrics: Dict[str, float]) -> str:
        """è®¡ç®—å¤šç²¾åº¦æ€§èƒ½ç­‰çº§"""
        fp32_total = total_metrics.get('total_fp32_tflops', 0)
        fp8_total = total_metrics.get('total_fp8_tops', 0)
        int8_total = total_metrics.get('total_int8_tops', 0)
        
        # ç»¼åˆè€ƒè™‘FP32ã€FP8å’ŒINT8æ€§èƒ½
        if fp32_total >= 80 or fp8_total >= 2000 or int8_total >= 1000:
            return "æ——èˆ°çº§ (Flagship)"
        elif fp32_total >= 40 or fp8_total >= 1000 or int8_total >= 500:
            return "é«˜ç«¯çº§ (High-End)"
        elif fp32_total >= 20 or fp8_total >= 500 or int8_total >= 200:
            return "ä¸­é«˜ç«¯ (Mid-High)"
        elif fp32_total >= 10 or fp8_total >= 200 or int8_total >= 100:
            return "ä¸­ç«¯çº§ (Mid-Range)"
        else:
            return "å…¥é—¨çº§ (Entry-Level)"
    
    def _identify_dominant_precision(self, total_metrics: Dict[str, float]) -> str:
        """è¯†åˆ«ä¸»å¯¼ç²¾åº¦ç±»å‹"""
        # æ ‡å‡†åŒ–ä¸åŒç²¾åº¦çš„æ€§èƒ½å€¼è¿›è¡Œæ¯”è¾ƒ
        normalized_scores = {
            'FP64': total_metrics.get('total_fp64_tflops', 0) * 10,  # FP64æƒé‡æ›´é«˜
            'FP32': total_metrics.get('total_fp32_tflops', 0) * 5,
            'FP16': total_metrics.get('total_fp16_tflops', 0) * 2,
            'FP8': total_metrics.get('total_fp8_tops', 0) * 1,
            'INT8': total_metrics.get('total_int8_tops', 0) * 1,
            'INT4': total_metrics.get('total_int4_tops', 0) * 0.5
        }
        
        if max(normalized_scores.values()) == 0:
            return "Unknown"
        
        dominant = max(normalized_scores.keys(), key=lambda k: normalized_scores[k])
        return dominant
    
    def _analyze_architectures(self, precision_breakdown: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æGPUæ¶æ„ç‰¹æ€§"""
        architecture_stats = {}
        
        for device_id, device_data in precision_breakdown.items():
            arch = device_data.get('architecture', 'Unknown')
            
            if arch not in architecture_stats:
                architecture_stats[arch] = {
                    'device_count': 0,
                    'total_fp32_tflops': 0,
                    'total_fp8_tops': 0,
                    'total_int8_tops': 0,
                    'supports_fp8': False,
                    'devices': []
                }
            
            arch_stats = architecture_stats[arch]
            arch_stats['device_count'] += 1
            arch_stats['devices'].append(device_data['device_name'])
            
            measured = device_data['measured_performance']
            arch_stats['total_fp32_tflops'] += measured.get('actual_fp32_tflops', 0)
            arch_stats['total_fp8_tops'] += measured.get('actual_fp8_tops', 0)
            arch_stats['total_int8_tops'] += measured.get('actual_int8_tops', 0)
            
            if measured.get('actual_fp8_tops', 0) > 0:
                arch_stats['supports_fp8'] = True
        
        return architecture_stats
    
    def export_multi_precision_report(self, multi_precision_metrics: Dict[str, Any], 
                                    output_file: str) -> bool:
        """å¯¼å‡ºå¤šç²¾åº¦æ€§èƒ½æŠ¥å‘Š"""
        try:
            # æ·»åŠ æŠ¥å‘Šå…ƒæ•°æ®
            report_data = {
                'report_info': {
                    'generation_time': datetime.now().isoformat(),
                    'report_type': 'Multi-Precision GPU Performance Analysis',
                    'supported_precisions': self.precision_types
                },
                'multi_precision_metrics': multi_precision_metrics
            }
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(report_data, f, indent=2, ensure_ascii=False)
            
            logger.info(f"å¤šç²¾åº¦æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
            return True
            
        except Exception as e:
            logger.error(f"å¯¼å‡ºå¤šç²¾åº¦æ€§èƒ½æŠ¥å‘Šå¤±è´¥: {e}")
            return False
    
    def generate_multi_precision_summary_text(self, multi_precision_metrics: Dict[str, Any]) -> str:
        """ç”Ÿæˆå¤šç²¾åº¦æ€§èƒ½æ–‡æœ¬æ€»ç»“"""
        lines = []
        lines.append("=" * 80)
        lines.append("GPUå¤šç²¾åº¦æ€§èƒ½åŸºå‡†æµ‹è¯•è¯¦ç»†æŠ¥å‘Š")
        lines.append("=" * 80)
        lines.append("")
        
        # æ€»ä½“æ€§èƒ½æ¦‚è§ˆ
        total_perf = multi_precision_metrics.get('total_performance', {})
        lines.append("ğŸš€ æ€»ä½“å¤šç²¾åº¦æ€§èƒ½:")
        lines.append(f"  FP64æ€§èƒ½: {total_perf.get('total_fp64_tflops', 0):.2f} TFLOPS")
        lines.append(f"  FP32æ€§èƒ½: {total_perf.get('total_fp32_tflops', 0):.2f} TFLOPS")
        lines.append(f"  FP16æ€§èƒ½: {total_perf.get('total_fp16_tflops', 0):.2f} TFLOPS")
        lines.append(f"  FP8æ€§èƒ½:  {total_perf.get('total_fp8_tops', 0):.2f} TOPS")
        lines.append(f"  INT8æ€§èƒ½: {total_perf.get('total_int8_tops', 0):.2f} TOPS")
        lines.append(f"  INT4æ€§èƒ½: {total_perf.get('total_int4_tops', 0):.2f} TOPS")
        lines.append(f"  å†…å­˜å¸¦å®½: {total_perf.get('total_memory_bandwidth_gbps', 0):.2f} GB/s")
        lines.append(f"  æ€§èƒ½ç­‰çº§: {total_perf.get('performance_rating', 'Unknown')}")
        lines.append(f"  ä¸»å¯¼ç²¾åº¦: {total_perf.get('dominant_precision', 'Unknown')}")
        lines.append("")
        
        # å„è®¾å¤‡è¯¦ç»†æ€§èƒ½
        precision_breakdown = multi_precision_metrics.get('precision_breakdown', {})
        if precision_breakdown:
            lines.append("ğŸ“Š å„GPUè¯¦ç»†å¤šç²¾åº¦æ€§èƒ½:")
            for device_id, device_data in precision_breakdown.items():
                device_name = device_data['device_name']
                arch = device_data['architecture']
                measured = device_data['measured_performance']
                utilization = device_data['utilization_rates']
                
                lines.append(f"  {device_name} ({arch}æ¶æ„):")
                lines.append(f"    FP64: {measured.get('actual_fp64_tflops', 0):.2f} TFLOPS (åˆ©ç”¨ç‡: {utilization.get('fp64_utilization_percent', 0):.1f}%)")
                lines.append(f"    FP32: {measured.get('actual_fp32_tflops', 0):.2f} TFLOPS (åˆ©ç”¨ç‡: {utilization.get('fp32_utilization_percent', 0):.1f}%)")
                lines.append(f"    FP16: {measured.get('actual_fp16_tflops', 0):.2f} TFLOPS (åˆ©ç”¨ç‡: {utilization.get('fp16_utilization_percent', 0):.1f}%)")
                
                fp8_perf = measured.get('actual_fp8_tops', 0)
                if fp8_perf > 0:
                    lines.append(f"    FP8:  {fp8_perf:.2f} TOPS (åˆ©ç”¨ç‡: {utilization.get('fp8_utilization_percent', 0):.1f}%)")
                else:
                    lines.append(f"    FP8:  ä¸æ”¯æŒ")
                
                lines.append(f"    INT8: {measured.get('actual_int8_tops', 0):.2f} TOPS (åˆ©ç”¨ç‡: {utilization.get('int8_utilization_percent', 0):.1f}%)")
                lines.append(f"    INT4: {measured.get('actual_int4_tops', 0):.2f} TOPS (åˆ©ç”¨ç‡: {utilization.get('int4_utilization_percent', 0):.1f}%)")
                
                # åŠŸæ•ˆæ¯”
                if 'efficiency_fp32_gflops_per_watt' in measured:
                    lines.append(f"    åŠŸæ•ˆæ¯”(FP32): {measured['efficiency_fp32_gflops_per_watt']:.2f} GFLOPS/W")
                if 'efficiency_fp8_tops_per_watt' in measured:
                    lines.append(f"    åŠŸæ•ˆæ¯”(FP8):  {measured['efficiency_fp8_tops_per_watt']:.2f} TOPS/W")
                
                lines.append("")
        
        # æ¶æ„åˆ†æ
        arch_analysis = multi_precision_metrics.get('architecture_analysis', {})
        if arch_analysis:
            lines.append("ğŸ—ï¸ GPUæ¶æ„åˆ†æ:")
            for arch, stats in arch_analysis.items():
                lines.append(f"  {arch}æ¶æ„:")
                lines.append(f"    è®¾å¤‡æ•°é‡: {stats['device_count']}")
                lines.append(f"    è®¾å¤‡åˆ—è¡¨: {', '.join(stats['devices'])}")
                lines.append(f"    æ€»FP32æ€§èƒ½: {stats['total_fp32_tflops']:.2f} TFLOPS")
                lines.append(f"    æ€»FP8æ€§èƒ½: {stats['total_fp8_tops']:.2f} TOPS")
                lines.append(f"    æ€»INT8æ€§èƒ½: {stats['total_int8_tops']:.2f} TOPS")
                lines.append(f"    FP8æ”¯æŒ: {'æ˜¯' if stats['supports_fp8'] else 'å¦'}")
                lines.append("")
        
        lines.append("=" * 80)
        lines.append("ğŸ“ ç²¾åº¦è¯´æ˜:")
        lines.append("  FP64: åŒç²¾åº¦æµ®ç‚¹ (ç§‘å­¦è®¡ç®—)")
        lines.append("  FP32: å•ç²¾åº¦æµ®ç‚¹ (é€šç”¨è®¡ç®—)")
        lines.append("  FP16: åŠç²¾åº¦æµ®ç‚¹ (AIè®­ç»ƒ)")
        lines.append("  FP8:  8ä½æµ®ç‚¹ (é«˜æ•ˆAIæ¨ç†)")
        lines.append("  INT8: 8ä½æ•´æ•° (AIæ¨ç†ä¼˜åŒ–)")
        lines.append("  INT4: 4ä½æ•´æ•° (æè‡´æ¨ç†ä¼˜åŒ–)")
        lines.append("=" * 80)
        
        return "\n".join(lines)


# ä¾¿æ·å‡½æ•°
def analyze_multi_precision_performance(test_results: Dict[str, Any], 
                                      csv_analysis: Dict[str, Any] = None,
                                      output_dir: str = "gpu_benchmark_linux_results") -> Dict[str, str]:
    """åˆ†æå¤šç²¾åº¦æ€§èƒ½çš„ä¾¿æ·å‡½æ•°"""
    analyzer = MultiPrecisionPerformanceAnalyzer()
    multi_precision_metrics = analyzer.calculate_multi_precision_performance(test_results, csv_analysis)
    
    # ä¿å­˜æŠ¥å‘Š
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    json_file = output_path / f"multi_precision_performance_{timestamp}.json"
    txt