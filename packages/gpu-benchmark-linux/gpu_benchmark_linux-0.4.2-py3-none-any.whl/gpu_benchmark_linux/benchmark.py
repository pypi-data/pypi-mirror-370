"""
åŸºå‡†æµ‹è¯•æ¨¡å— - æä¾›GPUåŸºå‡†æµ‹è¯•çš„æ ¸å¿ƒåŠŸèƒ½
åŒ…å«å†…å­˜å’Œæ€§èƒ½ä¼˜åŒ–åŠŸèƒ½
"""

import os
import sys
import time
import logging
from pathlib import Path

from .utils import (
    logger, log_section, log_subsection, run_command,
    check_command, install_system_package, install_python_package,
    check_python_package, clone_repository, find_cuda_samples_dir,
    GREEN, RED, YELLOW, BLUE, RESET
)
from .memory_optimizer import ResourceManager, MemoryOptimizer, PerformanceOptimizer

class GPUBenchmark:
    """GPUåŸºå‡†æµ‹è¯•ç±»ï¼Œæä¾›å®Œæ•´çš„æµ‹è¯•æµç¨‹"""
    
    def __init__(self, device_id: int = 0, enable_optimization: bool = True, enable_multi_precision: bool = True):
        """åˆå§‹åŒ–åŸºå‡†æµ‹è¯•ç¯å¢ƒ"""
        self.device_id = device_id
        self.cuda_samples_dir = find_cuda_samples_dir()
        self.enable_optimization = enable_optimization
        self.enable_multi_precision = enable_multi_precision
        
        # åˆå§‹åŒ–å¤šç²¾åº¦åˆ†æå™¨ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
        if self.enable_multi_precision:
            try:
                from .multi_precision_performance import MultiPrecisionPerformanceAnalyzer
                self.multi_precision_analyzer = MultiPrecisionPerformanceAnalyzer()
                logger.info("âœ… å¤šç²¾åº¦æ€§èƒ½åˆ†æå·²å¯ç”¨")
            except ImportError as e:
                logger.warning(f"æ— æ³•å¯¼å…¥å¤šç²¾åº¦åˆ†æå™¨: {e}")
                self.multi_precision_analyzer = None
        else:
            self.multi_precision_analyzer = None
    
    def init(self):
        """åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ"""
        log_section("åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ")
        # è·å–æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼Œä½¿ç”¨ç±»å‹å®‰å…¨çš„æ–¹å¼
        log_file_path = ""
        for handler in logger.handlers:
            # æ£€æŸ¥æ˜¯å¦ä¸ºFileHandlerç±»å‹çš„å¤„ç†å™¨
            if isinstance(handler, logging.FileHandler):
                log_file_path = handler.baseFilename
                break
        
        if log_file_path:
            logger.info(f"æµ‹è¯•ç»“æœå°†ä¿å­˜è‡³ï¼š{log_file_path}")
        else:
            logger.info("æœªæ‰¾åˆ°æ—¥å¿—æ–‡ä»¶è·¯å¾„")
    
    def install_system_deps(self):
        """æ£€æŸ¥å¹¶å®‰è£…ç³»ç»Ÿä¾èµ–"""
        log_section("æ£€æŸ¥ç³»ç»Ÿä¾èµ–")
        
        # æ£€æŸ¥å¹¶å®‰è£…å¿…è¦å·¥å…·
        deps = ["gcc", "make", "git", "python3"]
        for dep in deps:
            if not check_command(dep):
                logger.info(f"å®‰è£…ç¼ºå¤±çš„ç³»ç»Ÿå·¥å…·: {dep}")
                install_system_package(dep)
    
    def check_environment(self):
        """æ£€æŸ¥GPUç¯å¢ƒ"""
        log_section("ç¯å¢ƒæ£€æŸ¥")
        
        # æ£€æŸ¥NVIDIAæ˜¾å¡çŠ¶æ€
        log_subsection("NVIDIAæ˜¾å¡çŠ¶æ€")
        if check_command("nvidia-smi"):
            run_command("nvidia-smi")
        else:
            logger.warning("è­¦å‘Š: æœªæ‰¾åˆ°nvidia-smiï¼Œè¯·å®‰è£…NVIDIAé©±åŠ¨")
            logger.info("åœ¨æ²¡æœ‰NVIDIAç¡¬ä»¶çš„ç¯å¢ƒä¸‹ï¼Œå°†è·³è¿‡ç¡¬ä»¶ç›¸å…³æµ‹è¯•")
        
        # æ£€æŸ¥CUDA
        log_subsection("CUDAç‰ˆæœ¬æ£€æŸ¥")
        if check_command("nvcc"):
            run_command("nvcc --version")
        else:
            logger.warning("è­¦å‘Š: æœªæ‰¾åˆ°nvcc (CUDAç¼–è¯‘å™¨)ï¼ŒæŸäº›æµ‹è¯•å°†å—é™")
            logger.warning("è¯·ç¡®ä¿å·²å®‰è£…CUDA Toolkit: https://developer.nvidia.com/cuda-toolkit")
        
        # æ£€æŸ¥PyTorch
        log_subsection("PyTorch CUDAæ£€æŸ¥")
        if not check_python_package("torch"):
            logger.info("å®‰è£…PyTorch...")
            install_python_package("torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")
        
        # æ£€æŸ¥PyTorch CUDAå¯ç”¨æ€§
        try:
            import torch
            logger.info(f"Torch version: {torch.__version__}")
            logger.info(f"CUDA available: {torch.cuda.is_available()}")
            logger.info(f"GPU count: {torch.cuda.device_count()}")
            if torch.cuda.is_available():
                for i in range(torch.cuda.device_count()):
                    logger.info(f"GPU {i}: {torch.cuda.get_device_name(i)}")
        except ImportError:
            logger.error("æ— æ³•å¯¼å…¥PyTorchï¼Œè¯·æ£€æŸ¥å®‰è£…")
            return False
        
        return True
    
    def install_python_deps(self):
        """å®‰è£…Pythonä¾èµ–"""
        log_section("å®‰è£…Pythonä¾èµ–")
        
        deps = ["transformers", "diffusers", "accelerate", "sentencepiece", "numpy", "tqdm", "colorama", "gitpython"]
        for dep in deps:
            if not check_python_package(dep):
                logger.info(f"å®‰è£…ç¼ºå¤±çš„PythonåŒ…: {dep}")
                install_python_package(dep)
    
    
    def test_cuda_basics(self):
        """åŸºç¡€CUDAèƒ½åŠ›æµ‹è¯•"""
        log_section("åŸºç¡€CUDAèƒ½åŠ›æµ‹è¯•")
        
        # deviceQueryæµ‹è¯•
        log_subsection("deviceQueryï¼ˆè®¾å¤‡ä¿¡æ¯ï¼‰")
        if self.cuda_samples_dir:
            devicequery_dir = Path(self.cuda_samples_dir) / "1_Utilities" / "deviceQuery"
            if devicequery_dir.exists():
                os.chdir(devicequery_dir)
                run_command("make")
                run_command("./deviceQuery")
                os.chdir(os.path.expanduser("~"))  # è¿”å›ä¸»ç›®å½•
            else:
                logger.warning(f"è­¦å‘Š: æœªæ‰¾åˆ°deviceQueryç›®å½•: {devicequery_dir}")
        else:
            logger.warning("è­¦å‘Š: æœªæ‰¾åˆ°CUDA Samplesç›®å½•ï¼Œè·³è¿‡deviceQueryæµ‹è¯•")
        
        # bandwidthTestæµ‹è¯•
        log_subsection("bandwidthTestï¼ˆå†…å­˜å¸¦å®½ï¼‰")
        if self.cuda_samples_dir:
            bandwidth_dir = Path(self.cuda_samples_dir) / "1_Utilities" / "bandwidthTest"
            if bandwidth_dir.exists():
                os.chdir(bandwidth_dir)
                run_command("make")
                run_command("./bandwidthTest")
                os.chdir(os.path.expanduser("~"))  # è¿”å›ä¸»ç›®å½•
            else:
                logger.warning(f"è­¦å‘Š: æœªæ‰¾åˆ°bandwidthTestç›®å½•: {bandwidth_dir}")
        else:
            logger.warning("è­¦å‘Š: æœªæ‰¾åˆ°CUDA Samplesç›®å½•ï¼Œè·³è¿‡bandwidthTestæµ‹è¯•")
        
        # GPUå‹åŠ›æµ‹è¯•ï¼ˆä½¿ç”¨å†…ç½®å®ç°ï¼‰
        log_subsection("GPUå‹åŠ›æµ‹è¯•ï¼ˆè®¡ç®—æ€§èƒ½ä¸ç¨³å®šæ€§ï¼‰")
        try:
            from .stress_test import stress_tester, StressTestConfig
            
            logger.info("å¼€å§‹å†…ç½®GPUå‹åŠ›æµ‹è¯•...")
            
            # é…ç½®å‹åŠ›æµ‹è¯•
            config = StressTestConfig(
                duration=60,  # 60ç§’æµ‹è¯•
                test_types=['matrix_multiply', 'compute_intensive'],
                temperature_limit=85.0,
                auto_stop_on_limit=True
            )
            
            # è¿è¡Œå‹åŠ›æµ‹è¯•
            result = stress_tester.run_stress_test(config)
            
            if result.success:
                logger.info("GPUå‹åŠ›æµ‹è¯•æˆåŠŸå®Œæˆ")
                
                # æ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡
                if result.performance_metrics:
                    metrics = result.performance_metrics
                    if 'total_gflops' in metrics:
                        logger.info(f"æ€»è®¡ç®—æ€§èƒ½: {metrics['total_gflops']:.2f} GFLOPS")
                    if 'temperature_stats' in metrics:
                        temp_stats = metrics['temperature_stats']
                        logger.info(f"æ¸©åº¦èŒƒå›´: {temp_stats['min']:.1f}Â°C - {temp_stats['max']:.1f}Â°C (å¹³å‡: {temp_stats['avg']:.1f}Â°C)")
                    if 'power_stats' in metrics:
                        power_stats = metrics['power_stats']
                        logger.info(f"åŠŸè€—èŒƒå›´: {power_stats['min']:.1f}W - {power_stats['max']:.1f}W (å¹³å‡: {power_stats['avg']:.1f}W)")
                
                # ä¿å­˜è¯¦ç»†ç»“æœ
                from pathlib import Path
                result_file = Path("./gpu_benchmark_linux_results") / f"stress_test_{int(result.start_time)}.json"
                stress_tester.export_result(result, str(result_file))
                logger.info(f"è¯¦ç»†æµ‹è¯•ç»“æœå·²ä¿å­˜è‡³: {result_file}")
                
            else:
                logger.error("GPUå‹åŠ›æµ‹è¯•å¤±è´¥")
                if result.error_message:
                    logger.error(f"é”™è¯¯ä¿¡æ¯: {result.error_message}")
                    
        except ImportError as e:
            logger.error(f"æ— æ³•å¯¼å…¥å‹åŠ›æµ‹è¯•æ¨¡å—: {e}")
            logger.info("GPUåŸºç¡€åŠŸèƒ½å·²é€šè¿‡nvidia-smiå’ŒPyTorch CUDAæµ‹è¯•éªŒè¯")
        except Exception as e:
            logger.error(f"GPUå‹åŠ›æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
            logger.info("GPUåŸºç¡€åŠŸèƒ½å·²é€šè¿‡nvidia-smiå’ŒPyTorch CUDAæµ‹è¯•éªŒè¯")
    
    def test_model_inference(self):
        """å¤§æ¨¡å‹æ¨ç†æµ‹è¯• - ä½¿ç”¨å®‰å…¨ç‰ˆæœ¬"""
        log_section("å¤§æ¨¡å‹æ¨ç†èƒ½åŠ›æµ‹è¯•")
        
        try:
            # ä½¿ç”¨å†…ç½®çš„å®‰å…¨æ¨¡å‹æ¨ç†æµ‹è¯•
            from .safe_model_inference_test import run_safe_model_inference_tests
            
            log_subsection("å¼€å§‹å®‰å…¨çš„æ¨¡å‹æ¨ç†æµ‹è¯•")
            success = run_safe_model_inference_tests()
            
            if success:
                logger.info("æ¨¡å‹æ¨ç†æµ‹è¯•å®Œæˆ")
            else:
                logger.warning("æ¨¡å‹æ¨ç†æµ‹è¯•æœªèƒ½æˆåŠŸè¿è¡Œï¼Œä½†è¿™ä¸å½±å“å…¶ä»–GPUåŸºå‡†æµ‹è¯•")
                
        except ImportError as e:
            logger.warning(f"æ— æ³•å¯¼å…¥å®‰å…¨æ¨¡å‹æ¨ç†æµ‹è¯•æ¨¡å—: {e}")
            logger.info("å°è¯•ä½¿ç”¨åŸå§‹æ¨¡å‹æ¨ç†æµ‹è¯•...")
            
            # å›é€€åˆ°åŸå§‹æµ‹è¯•
            from pathlib import Path
            script_path = Path("model_inference_test.py")
            if script_path.exists():
                log_subsection("è¿è¡ŒåŸå§‹æ¨¡å‹æ¨ç†æµ‹è¯•")
                run_command([sys.executable, str(script_path)])
            else:
                logger.warning("æœªæ‰¾åˆ°æ¨¡å‹æ¨ç†æµ‹è¯•è„šæœ¬ï¼Œè·³è¿‡æ­¤æµ‹è¯•")
                
        except Exception as e:
            logger.warning(f"æ¨¡å‹æ¨ç†æµ‹è¯•é‡åˆ°é—®é¢˜: {e}")
            logger.info("è¿™é€šå¸¸æ˜¯ç”±äºæ¨¡å‹ä¸‹è½½å¤±è´¥æˆ–æ˜¾å­˜ä¸è¶³ï¼Œä¸å½±å“å…¶ä»–GPUæµ‹è¯•")
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯• - åŒ…å«å®Œæ•´çš„å¤šç²¾åº¦æ€§èƒ½åˆ†æ"""
        self.init()
        
        logger.info("=" * 60)
        logger.info("ğŸš€ å¼€å§‹GPUåŸºå‡†æµ‹è¯•å®Œæ•´æµç¨‹")
        logger.info("=" * 60)
        
        # 1. ç¯å¢ƒæ£€æŸ¥å’Œä¾èµ–å®‰è£…
        logger.info("ğŸ“‹ æ­¥éª¤1: ç¯å¢ƒæ£€æŸ¥å’Œä¾èµ–å®‰è£…")
        self.install_system_deps()
        if not self.check_environment():
            logger.error("ç¯å¢ƒæ£€æŸ¥å¤±è´¥ï¼Œæ— æ³•ç»§ç»­æµ‹è¯•")
            return False
        self.install_python_deps()
        
        # 2. åŸºç¡€CUDAæµ‹è¯•
        logger.info("ğŸ§ª æ­¥éª¤2: åŸºç¡€CUDAåŠŸèƒ½æµ‹è¯•")
        self.test_cuda_basics()
        
        # 3. å®Œæ•´GPUå‹åŠ›æµ‹è¯•å’Œå¤šç²¾åº¦åˆ†æ
        logger.info("ğŸ¯ æ­¥éª¤3: å®Œæ•´GPUå‹åŠ›æµ‹è¯•å’Œå¤šç²¾åº¦æ€§èƒ½åˆ†æ")
        try:
            from .stress_test import StressTestConfig, GPUStressTester
            
            # åˆ›å»ºæµ‹è¯•é…ç½® - æ›´é•¿æ—¶é—´çš„æµ‹è¯•ä»¥è·å¾—å‡†ç¡®æ•°æ®
            config = StressTestConfig(
                duration=120,  # 2åˆ†é’Ÿæµ‹è¯•
                device_ids=[],
                matrix_size=4096,
                memory_usage_ratio=0.8,
                temperature_limit=90.0,
                test_types=['matrix_multiply', 'compute_intensive', 'memory_bandwidth']
            )
            
            # è¿è¡Œå‹åŠ›æµ‹è¯•
            logger.info("å¼€å§‹GPUå‹åŠ›æµ‹è¯•...")
            stress_tester = GPUStressTester(enable_csv_logging=True)
            result = stress_tester.run_stress_test(config)
            
            if result.success:
                logger.info("âœ… GPUå‹åŠ›æµ‹è¯•æˆåŠŸå®Œæˆ")
                
                # æ˜¾ç¤ºåŸºæœ¬ç»“æœ
                self._display_stress_test_results(result)
                
                # 4. å¤šç²¾åº¦æ€§èƒ½åˆ†æ
                if self.enable_multi_precision and self.multi_precision_analyzer:
                    logger.info("ğŸ“Š æ­¥éª¤4: å¤šç²¾åº¦æ€§èƒ½åˆ†æ")
                    
                    # åˆ†æCSVæ•°æ®
                    csv_analysis = None
                    if hasattr(stress_tester, 'csv_logger') and stress_tester.csv_logger:
                        csv_file = stress_tester.csv_logger.get_filepath()
                        logger.info(f"åˆ†æCSVæ•°æ®æ–‡ä»¶: {csv_file}")
                        
                        try:
                            from .csv_viewer import analyze_csv_file
                            csv_viewer = analyze_csv_file(str(csv_file), export_summary=False)
                            # è·å–åˆ†ææ•°æ®
                            csv_analysis = {
                                'basic_info': csv_viewer.get_basic_info(),
                                'temperature_analysis': csv_viewer.get_temperature_analysis(),
                                'power_analysis': csv_viewer.get_power_analysis(),
                                'utilization_analysis': csv_viewer.get_utilization_analysis(),
                                'performance_trends': csv_viewer.get_performance_trends()
                            }
                            logger.info("âœ… CSVæ•°æ®åˆ†æå®Œæˆ")
                        except Exception as e:
                            logger.warning(f"CSVæ•°æ®åˆ†æå¤±è´¥: {e}")
                    
                    # æ‰§è¡Œå¤šç²¾åº¦åˆ†æ
                    test_results = {
                        'device_results': result.device_results,
                        'performance_metrics': result.performance_metrics,
                        'success': result.success
                    }
                    
                    multi_precision_metrics = self.multi_precision_analyzer.calculate_multi_precision_performance(
                        test_results, csv_analysis or {}
                    )
                    
                    # 5. ç”Ÿæˆè¯¦ç»†æ€§èƒ½æŠ¥å‘Š
                    logger.info("ğŸ“ æ­¥éª¤5: ç”Ÿæˆè¯¦ç»†æ€§èƒ½æŠ¥å‘Š")
                    
                    # è¾“å‡ºå¤šç²¾åº¦æ€»ç»“åˆ°æ—¥å¿—
                    multi_precision_summary = self.multi_precision_analyzer.generate_multi_precision_summary_text(
                        multi_precision_metrics
                    )
                    
                    # å°†å¤šç²¾åº¦æ€»ç»“å†™å…¥æ—¥å¿—
                    for line in multi_precision_summary.split('\n'):
                        if line.strip():
                            logger.info(line)
                    
                    # 6. ä¿å­˜è¯¦ç»†æŠ¥å‘Šæ–‡ä»¶
                    logger.info("ğŸ’¾ æ­¥éª¤6: ä¿å­˜è¯¦ç»†æŠ¥å‘Š")
                    from datetime import datetime
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    
                    # ä¿å­˜å¤šç²¾åº¦æŠ¥å‘Š
                    multi_precision_file = f"gpu_benchmark_linux_results/multi_precision_analysis_{timestamp}.json"
                    self.multi_precision_analyzer.export_multi_precision_report(
                        multi_precision_metrics, multi_precision_file
                    )
                    logger.info(f"ğŸ“Š å¤šç²¾åº¦åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {multi_precision_file}")
                    
                    # ä¿å­˜æ€§èƒ½æ€»ç»“
                    try:
                        from .performance_summary import PerformanceSummaryGenerator
                        performance_summary = PerformanceSummaryGenerator()
                        summary_metrics = performance_summary.generate_performance_summary(
                            test_results, csv_analysis or {}
                        )
                        
                        summary_file = f"gpu_benchmark_linux_results/performance_summary_{timestamp}.json"
                        performance_summary.export_summary_report(summary_metrics, summary_file)
                        logger.info(f"ğŸ“ˆ æ€§èƒ½æ€»ç»“æŠ¥å‘Šå·²ä¿å­˜: {summary_file}")
                        
                        # è¾“å‡ºæ€§èƒ½æ€»ç»“åˆ°æ—¥å¿—
                        text_summary = performance_summary.generate_text_summary(summary_metrics)
                        for line in text_summary.split('\n'):
                            if line.strip():
                                logger.info(line)
                                
                    except Exception as e:
                        logger.warning(f"ç”Ÿæˆæ€§èƒ½æ€»ç»“å¤±è´¥: {e}")
                
                else:
                    logger.warning("âš ï¸ å¤šç²¾åº¦æ€§èƒ½åˆ†ææœªå¯ç”¨")
                
            else:
                logger.error("âŒ GPUå‹åŠ›æµ‹è¯•å¤±è´¥")
                if result.error_message:
                    logger.error(f"é”™è¯¯ä¿¡æ¯: {result.error_message}")
                
        except Exception as e:
            logger.error(f"GPUå‹åŠ›æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
            logger.info("ç»§ç»­æ‰§è¡Œå…¶ä»–æµ‹è¯•...")
        
        # 7. å¤§æ¨¡å‹æ¨ç†æµ‹è¯•ï¼ˆæœ€åæ‰§è¡Œï¼Œå¯èƒ½å‡ºé”™ä½†ä¸å½±å“å…¶ä»–æµ‹è¯•ï¼‰
        logger.info("ğŸ¤– æ­¥éª¤7: å¤§æ¨¡å‹æ¨ç†æµ‹è¯•ï¼ˆå¦‚é‡é”™è¯¯å°†è·³è¿‡ï¼‰")
        try:
            self.test_model_inference()
        except Exception as e:
            logger.warning(f"å¤§æ¨¡å‹æ¨ç†æµ‹è¯•é‡åˆ°é—®é¢˜ï¼Œå·²è·³è¿‡: {e}")
            logger.info("è¿™é€šå¸¸æ˜¯å› ä¸ºæ¨¡å‹ä¸‹è½½æˆ–æ˜¾å­˜ä¸è¶³å¯¼è‡´çš„ï¼Œä¸å½±å“å…¶ä»–GPUåŸºå‡†æµ‹è¯•")
        
        # 8. æµ‹è¯•å®Œæˆæ€»ç»“
        log_section("ğŸ‰ GPUåŸºå‡†æµ‹è¯•å®Œæ•´æµç¨‹å·²å®Œæˆ")
        
        # è·å–æ—¥å¿—æ–‡ä»¶è·¯å¾„
        log_file_path = ""
        for handler in logger.handlers:
            if isinstance(handler, logging.FileHandler):
                log_file_path = handler.baseFilename
                break
        
        if log_file_path:
            logger.info(f"ğŸ“‹ å®Œæ•´çš„å¤šç²¾åº¦æ€§èƒ½åˆ†æç»“æœè§ï¼š{log_file_path}")
            logger.info("ğŸ“Š æ—¥å¿—åŒ…å«å®Œæ•´çš„FP64/FP32/FP16/FP8/INT8/INT4æ€§èƒ½æŒ‡æ ‡")
        else:
            logger.info("ğŸ“‹ æµ‹è¯•å®Œæˆï¼Œè¯·æŸ¥çœ‹ä¸Šè¿°è¯¦ç»†ç»“æœ")
        
        return True
    
    def test_gpu_stress(self, duration=60, test_types=None):
        """è¿è¡ŒGPUå‹åŠ›æµ‹è¯•"""
        log_section("GPUå‹åŠ›æµ‹è¯•")
        
        try:
            from .stress_test import stress_tester, StressTestConfig
            
            if test_types is None:
                test_types = ['matrix_multiply', 'compute_intensive', 'memory_bandwidth']
            
            logger.info(f"å¼€å§‹GPUå‹åŠ›æµ‹è¯•ï¼ŒæŒç»­æ—¶é—´: {duration}ç§’")
            
            # é…ç½®å‹åŠ›æµ‹è¯•
            config = StressTestConfig(
                duration=duration,
                test_types=test_types,
                temperature_limit=85.0,
                power_limit_ratio=0.95,
                auto_stop_on_limit=True,
                monitor_interval=2.0
            )
            
            # è¿è¡Œå‹åŠ›æµ‹è¯•
            result = stress_tester.run_stress_test(config)
            
            if result.success:
                logger.info("GPUå‹åŠ›æµ‹è¯•æˆåŠŸå®Œæˆ")
                
                # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
                self._display_stress_test_results(result)
                
                # è¾“å‡ºè¯¦ç»†æ€§èƒ½æŒ‡æ ‡åˆ°æ—¥å¿—
                try:
                    from .detailed_logger import log_detailed_performance_metrics, log_performance_comparison_table
                    
                    # æ„é€ æµ‹è¯•ç»“æœæ•°æ®
                    test_results = {
                        'device_results': result.device_results,
                        'system_info': {'gpu_count': len(result.device_results)}
                    }
                    
                    # è¾“å‡ºè¯¦ç»†æ€§èƒ½æŒ‡æ ‡
                    log_detailed_performance_metrics(test_results)
                    
                    # è¾“å‡ºæ€§èƒ½å¯¹æ¯”è¡¨æ ¼
                    from .performance_summary import PerformanceSummaryGenerator
                    generator = PerformanceSummaryGenerator()
                    performance_summary = generator.generate_performance_summary(test_results)
                    log_performance_comparison_table(performance_summary)
                    
                except Exception as e:
                    logger.warning(f"è¾“å‡ºè¯¦ç»†æ€§èƒ½æ—¥å¿—å¤±è´¥: {e}")
                
                # ä¿å­˜ç»“æœ
                self._save_stress_test_results(result)
                
                return True
            else:
                logger.error("GPUå‹åŠ›æµ‹è¯•å¤±è´¥")
                if result.error_message:
                    logger.error(f"é”™è¯¯ä¿¡æ¯: {result.error_message}")
                return False
                
        except Exception as e:
            logger.error(f"GPUå‹åŠ›æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
            return False
    
    def _display_stress_test_results(self, result):
        """æ˜¾ç¤ºå‹åŠ›æµ‹è¯•ç»“æœ"""
        logger.info("=== å‹åŠ›æµ‹è¯•ç»“æœæ‘˜è¦ ===")
        
        # åŸºæœ¬ä¿¡æ¯
        logger.info(f"æµ‹è¯•æŒç»­æ—¶é—´: {result.duration:.1f}ç§’")
        logger.info(f"æµ‹è¯•è®¾å¤‡æ•°é‡: {len(result.device_results)}")
        
        # æ€§èƒ½æŒ‡æ ‡
        if result.performance_metrics:
            metrics = result.performance_metrics
            
            if 'total_gflops' in metrics:
                logger.info(f"æ€»è®¡ç®—æ€§èƒ½: {metrics['total_gflops']:.2f} GFLOPS")
                if 'avg_gflops_per_device' in metrics:
                    logger.info(f"å¹³å‡æ¯è®¾å¤‡æ€§èƒ½: {metrics['avg_gflops_per_device']:.2f} GFLOPS")
            
            if 'temperature_stats' in metrics:
                temp_stats = metrics['temperature_stats']
                logger.info(f"æ¸©åº¦ç»Ÿè®¡: æœ€ä½{temp_stats['min']:.1f}Â°C, æœ€é«˜{temp_stats['max']:.1f}Â°C, å¹³å‡{temp_stats['avg']:.1f}Â°C")
            
            if 'power_stats' in metrics:
                power_stats = metrics['power_stats']
                logger.info(f"åŠŸè€—ç»Ÿè®¡: æœ€ä½{power_stats['min']:.1f}W, æœ€é«˜{power_stats['max']:.1f}W, å¹³å‡{power_stats['avg']:.1f}W")
            
            if 'gpu_utilization_stats' in metrics:
                util_stats = metrics['gpu_utilization_stats']
                logger.info(f"GPUåˆ©ç”¨ç‡ç»Ÿè®¡: æœ€ä½{util_stats['min']:.1f}%, æœ€é«˜{util_stats['max']:.1f}%, å¹³å‡{util_stats['avg']:.1f}%")
        
        # å„è®¾å¤‡è¯¦ç»†ç»“æœ
        for device_id, device_result in result.device_results.items():
            logger.info(f"--- GPU {device_id} è¯¦ç»†ç»“æœ ---")
            
            if 'matrix_multiply' in device_result:
                mm_result = device_result['matrix_multiply']
                if 'gflops' in mm_result:
                    logger.info(f"  çŸ©é˜µä¹˜æ³•æ€§èƒ½: {mm_result['gflops']:.2f} GFLOPS")
            
            if 'compute_intensive' in device_result:
                ci_result = device_result['compute_intensive']
                if 'iterations_per_second' in ci_result:
                    logger.info(f"  è®¡ç®—å¯†é›†å‹æ€§èƒ½: {ci_result['iterations_per_second']:.2f} iter/s")
            
            if 'memory_bandwidth' in device_result:
                mb_result = device_result['memory_bandwidth']
                if 'h2d_bandwidth_gbps' in mb_result:
                    logger.info(f"  å†…å­˜å¸¦å®½ (Host->Device): {mb_result['h2d_bandwidth_gbps']:.2f} GB/s")
                if 'd2h_bandwidth_gbps' in mb_result:
                    logger.info(f"  å†…å­˜å¸¦å®½ (Device->Host): {mb_result['d2h_bandwidth_gbps']:.2f} GB/s")
    
    def _save_stress_test_results(self, result):
        """ä¿å­˜å‹åŠ›æµ‹è¯•ç»“æœ"""
        try:
            from pathlib import Path
            from .stress_test import stress_tester
            
            # ç¡®ä¿ç»“æœç›®å½•å­˜åœ¨
            result_dir = Path("./gpu_benchmark_linux_results")
            result_dir.mkdir(exist_ok=True)
            
            # ç”Ÿæˆæ–‡ä»¶å
            timestamp = int(result.start_time)
            result_file = result_dir / f"stress_test_{timestamp}.json"
            
            # ä¿å­˜ç»“æœ
            if stress_tester.export_result(result, str(result_file)):
                logger.info(f"è¯¦ç»†æµ‹è¯•ç»“æœå·²ä¿å­˜è‡³: {result_file}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜å‹åŠ›æµ‹è¯•ç»“æœå¤±è´¥: {e}")
    
    def run_specific_test(self, test_name):
        """è¿è¡Œç‰¹å®šæµ‹è¯•"""
        self.init()
        
        if test_name == "env":
            self.check_environment()
        elif test_name == "cuda":
            self.test_cuda_basics()
        elif test_name == "stress":
            self.check_environment()
            self.install_python_deps()
            self.test_gpu_stress()
        elif test_name == "model":
            self.check_environment()
            self.install_python_deps()
            self.test_model_inference()
        else:
            logger.error(f"æœªçŸ¥çš„æµ‹è¯•ç±»å‹: {test_name}")
            return False
        
        log_section(f"{test_name}æµ‹è¯•å®Œæˆ")
        # è·å–æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼Œä½¿ç”¨ç±»å‹å®‰å…¨çš„æ–¹å¼
        log_file_path = ""
        for handler in logger.handlers:
            if isinstance(handler, logging.FileHandler):
                log_file_path = handler.baseFilename
                break
        
        if log_file_path:
            logger.info(f"å®Œæ•´ç»“æœè§ï¼š{log_file_path}")
        else:
            logger.info("æµ‹è¯•å®Œæˆ")
        return True
