/*! 
ç®€åŒ–çš„å› å­ä¸­æ€§åŒ–å›é€€ç‰ˆæœ¬
========================

ä½¿ç”¨æœ€ç®€å•ç¨³å®šçš„OLSå›å½’ï¼Œé¿å…å¤æ‚çš„QRåˆ†è§£é—®é¢˜
*/

use pyo3::prelude::*;
use pyo3::exceptions::PyRuntimeError;
use nalgebra::{DMatrix, DVector};
use rayon::prelude::*;
use std::collections::HashMap;
use std::fs::File;
use std::path::{Path, PathBuf};
use std::sync::Arc;
use std::time::Instant;
use arrow::array::*;
use arrow::record_batch::RecordBatch;
use parquet::arrow::arrow_reader::ParquetRecordBatchReaderBuilder;
use arrow::datatypes::{DataType, Field, Schema};

/// ä»æ–‡ä»¶åæå–æ—¥æœŸä¿¡æ¯
fn extract_date_from_filename(filename: &str) -> Option<i64> {
    // å¯»æ‰¾8ä½è¿ç»­æ•°å­—ï¼ˆYYYYMMDDæ ¼å¼ï¼‰
    for i in 0..filename.len().saturating_sub(7) {
        let slice = &filename[i..i+8];
        if slice.chars().all(|c| c.is_ascii_digit()) {
            if let Ok(date) = slice.parse::<i64>() {
                // éªŒè¯æ˜¯å¦æ˜¯åˆç†çš„æ—¥æœŸæ ¼å¼
                if date >= 19900101 && date <= 20991231 {
                    return Some(date);
                }
            }
        }
    }
    
    // å¦‚æœæ‰¾ä¸åˆ°æ—¥æœŸï¼Œè¿”å›None
    None
}

/// ç®€åŒ–çš„é£æ ¼æ•°æ®ç»“æ„
pub struct SimpleFallbackStyleData {
    pub data_by_date: HashMap<i64, SimpleFallbackStyleDayData>,
}

/// ç®€åŒ–çš„å•æ—¥é£æ ¼æ•°æ®
pub struct SimpleFallbackStyleDayData {
    pub stocks: Vec<String>,
    pub style_matrix: DMatrix<f64>,
}

/// ç®€åŒ–çš„å› å­æ•°æ®ç»“æ„
pub struct SimpleFallbackFactorData {
    pub dates: Vec<i64>,
    pub stocks: Vec<String>,
    pub values: DMatrix<f64>,
}

/// ç®€åŒ–çš„ä¸­æ€§åŒ–ç»“æœ
pub struct SimpleFallbackNeutralizationResult {
    pub dates: Vec<i64>,
    pub stocks: Vec<String>,
    pub neutralized_values: DMatrix<f64>,
}

impl SimpleFallbackStyleData {
    /// åŠ è½½é£æ ¼æ•°æ®
    pub fn load_from_parquet_simple_fallback(path: &str) -> PyResult<Self> {
        let load_start = Instant::now();
        
        let file = File::open(path)
            .map_err(|e| PyRuntimeError::new_err(format!("æ— æ³•æ‰“å¼€é£æ ¼æ•°æ®æ–‡ä»¶ {}: {}", path, e)))?;

        let record_batch_reader = ParquetRecordBatchReaderBuilder::try_new(file)
            .map_err(|e| PyRuntimeError::new_err(format!("æ— æ³•åˆ›å»ºè®°å½•æ‰¹é˜…è¯»å™¨: {}", e)))?
            .with_batch_size(8192)
            .build()
            .map_err(|e| PyRuntimeError::new_err(format!("æ— æ³•åˆ›å»ºè®°å½•æ‰¹é˜…è¯»å™¨: {}", e)))?;

        let mut data_by_date = HashMap::new();
        let mut total_rows = 0;

        println!("ğŸ”§ å¼€å§‹ç®€åŒ–å›é€€ç‰ˆæœ¬é£æ ¼æ•°æ®åŠ è½½...");

        for batch_result in record_batch_reader {
            let batch = batch_result
                .map_err(|e| PyRuntimeError::new_err(format!("è¯»å–è®°å½•æ‰¹å¤±è´¥: {}", e)))?;
            
            total_rows += batch.num_rows();
            
            // æå–åˆ—æ•°æ®
            let date_array = batch.column(0)
                .as_any().downcast_ref::<Int64Array>()
                .ok_or_else(|| PyRuntimeError::new_err("æ—¥æœŸåˆ—ç±»å‹è½¬æ¢å¤±è´¥"))?;
            
            let stock_array = batch.column(1)
                .as_any().downcast_ref::<StringArray>()
                .ok_or_else(|| PyRuntimeError::new_err("è‚¡ç¥¨åˆ—ç±»å‹è½¬æ¢å¤±è´¥"))?;

            let mut style_arrays = Vec::with_capacity(11);
            for i in 2..13 {
                let style_array = batch.column(i)
                    .as_any().downcast_ref::<Float64Array>()
                    .ok_or_else(|| PyRuntimeError::new_err(format!("é£æ ¼å› å­åˆ—{}è½¬æ¢å¤±è´¥", i-2)))?;
                style_arrays.push(style_array);
            }

            // æŒ‰æ—¥æœŸåˆ†ç»„
            let mut temp_data_by_date: HashMap<i64, HashMap<String, Vec<f64>>> = HashMap::new();
            
            for row_idx in 0..batch.num_rows() {
                let date = date_array.value(row_idx);
                let stock = stock_array.value(row_idx).to_string();
                
                let mut style_values = Vec::with_capacity(11);
                for style_array in &style_arrays {
                    style_values.push(style_array.value(row_idx));
                }
                
                temp_data_by_date
                    .entry(date)
                    .or_insert_with(HashMap::new)
                    .insert(stock, style_values);
            }

            // è½¬æ¢ä¸ºä¼˜åŒ–æ•°æ®ç»“æ„
            for (date, stock_data) in temp_data_by_date {
                if stock_data.len() >= 12 {
                    if let Ok(day_data) = Self::convert_date_data_simple_fallback(date, stock_data) {
                        data_by_date.insert(date, day_data);
                    }
                }
            }
        }

        let load_time = load_start.elapsed();
        println!("âœ… ç®€åŒ–å›é€€ç‰ˆæœ¬é£æ ¼æ•°æ®åŠ è½½å®Œæˆ:");
        println!("   ğŸ“… å¤„ç†æ—¥æœŸæ•°: {}", data_by_date.len());
        println!("   ğŸ“Š æ€»è¡Œæ•°: {}", total_rows);
        println!("   â±ï¸  åŠ è½½ç”¨æ—¶: {:.3}s", load_time.as_secs_f64());

        Ok(SimpleFallbackStyleData { data_by_date })
    }

    /// è½¬æ¢æ—¥æœŸæ•°æ®
    fn convert_date_data_simple_fallback(
        _date: i64, 
        stock_data: HashMap<String, Vec<f64>>
    ) -> PyResult<SimpleFallbackStyleDayData> {
        
        let n_stocks = stock_data.len();
        let mut stocks = Vec::with_capacity(n_stocks);
        let mut style_matrix = DMatrix::zeros(n_stocks, 12);

        // æŒ‰è‚¡ç¥¨ä»£ç æ’åºç¡®ä¿ä¸€è‡´æ€§
        let mut sorted_stocks: Vec<_> = stock_data.into_iter().collect();
        sorted_stocks.sort_by(|a, b| a.0.cmp(&b.0));

        for (i, (stock, style_values)) in sorted_stocks.into_iter().enumerate() {
            stocks.push(stock);
            
            // å¡«å……é£æ ¼å› å­çŸ©é˜µ
            for j in 0..11 {
                style_matrix[(i, j)] = style_values[j];
            }
            style_matrix[(i, 11)] = 1.0; // å¸¸æ•°é¡¹
        }

        Ok(SimpleFallbackStyleDayData {
            stocks,
            style_matrix,
        })
    }
}

impl SimpleFallbackFactorData {
    /// åŠ è½½å› å­æ•°æ®
    pub fn load_from_parquet_simple_fallback(path: &str) -> PyResult<Self> {
        let load_start = Instant::now();
        
        let file = File::open(path)
            .map_err(|e| PyRuntimeError::new_err(format!("æ— æ³•æ‰“å¼€å› å­æ–‡ä»¶ {}: {}", path, e)))?;

        let record_batch_reader = ParquetRecordBatchReaderBuilder::try_new(file)
            .map_err(|e| PyRuntimeError::new_err(format!("æ— æ³•åˆ›å»ºè®°å½•æ‰¹é˜…è¯»å™¨: {}", e)))?
            .with_batch_size(8192)
            .build()
            .map_err(|e| PyRuntimeError::new_err(format!("æ— æ³•åˆ›å»ºè®°å½•æ‰¹é˜…è¯»å™¨: {}", e)))?;

        let mut all_data = HashMap::new();

        // æ£€æŸ¥æ–‡ä»¶ç»“æ„ï¼šæ˜¯å¦åŒ…å«æ—¥æœŸåˆ—
        let mut first_batch = true;
        let mut has_date_column = false;
        let mut stocks = Vec::new();
        
        for batch_result in record_batch_reader {
            let batch = batch_result
                .map_err(|e| PyRuntimeError::new_err(format!("è¯»å–è®°å½•æ‰¹å¤±è´¥: {}", e)))?;

            if first_batch {
                let schema = batch.schema();
                let total_columns = schema.fields().len();
                
                // æ£€æŸ¥æ˜¯å¦å­˜åœ¨dateåˆ—
                let has_first_date = schema.fields()[0].name() == "date";
                let has_last_date = schema.fields()[total_columns - 1].name() == "date";
                
                if has_first_date {
                    // ä¼ ç»Ÿæ ¼å¼ï¼šç¬¬ä¸€åˆ—æ˜¯date
                    has_date_column = true;
                    stocks = schema.fields()
                        .iter()
                        .skip(1)
                        .map(|f| f.name().clone())
                        .collect();
                } else if has_last_date {
                    // pandas indexæ ¼å¼ï¼šæœ€åä¸€åˆ—æ˜¯date
                    has_date_column = true;
                    stocks = schema.fields()
                        .iter()
                        .take(total_columns - 1)
                        .map(|f| f.name().clone())
                        .collect();
                } else {
                    // æ²¡æœ‰æ—¥æœŸåˆ—ï¼šæ‰€æœ‰åˆ—éƒ½æ˜¯è‚¡ç¥¨ï¼Œéœ€è¦ä»æ–‡ä»¶åæ¨æ–­æ—¥æœŸ
                    has_date_column = false;
                    stocks = schema.fields()
                        .iter()
                        .map(|f| f.name().clone())
                        .collect();
                }
                first_batch = false;
                
                println!("   ğŸ“Š æ–‡ä»¶ç»“æ„åˆ†æ: {} ({}åˆ—è‚¡ç¥¨æ•°æ®)", 
                    if has_date_column { "åŒ…å«æ—¥æœŸåˆ—" } else { "çº¯è‚¡ç¥¨æ•°æ®" }, 
                    stocks.len());
            }

            if has_date_column {
                // æœ‰æ—¥æœŸåˆ—çš„å¤„ç†é€»è¾‘ï¼ˆç•¥ï¼‰
                return Err(PyRuntimeError::new_err("å›é€€ç‰ˆæœ¬æš‚æ—¶åªæ”¯æŒçº¯è‚¡ç¥¨æ•°æ®æ ¼å¼"));
            } else {
                // æ²¡æœ‰æ—¥æœŸåˆ—ï¼šä»æ–‡ä»¶åæ¨æ–­æ—¥æœŸï¼Œæ¯è¡Œä»£è¡¨ä¸€ä¸ªæ—¥æœŸ
                let file_name = Path::new(path).file_stem()
                    .and_then(|s| s.to_str())
                    .unwrap_or("unknown");
                
                // å°è¯•ä»æ–‡ä»¶åæå–æ—¥æœŸä¿¡æ¯
                let inferred_date = extract_date_from_filename(file_name).unwrap_or(20230101);
                
                for row_idx in 0..batch.num_rows() {
                    // ä¸ºæ¯ä¸€è¡Œåˆ†é…ä¸€ä¸ªå”¯ä¸€çš„æ—¥æœŸï¼ˆåŸºäºè¡Œç´¢å¼•ï¼‰
                    let row_date = inferred_date + row_idx as i64;
                    let mut row_values = Vec::new();
                    
                    // è¯»å–æ‰€æœ‰åˆ—ï¼ˆéƒ½æ˜¯è‚¡ç¥¨æ•°æ®ï¼‰
                    for col_idx in 0..batch.num_columns() {
                        let value = match batch.column(col_idx).as_any().downcast_ref::<Float64Array>() {
                            Some(array) => {
                                if array.is_null(row_idx) {
                                    f64::NAN
                                } else {
                                    array.value(row_idx)
                                }
                            }
                            None => f64::NAN,
                        };
                        row_values.push(value);
                    }
                    
                    all_data.insert(row_date, row_values);
                }
            }
        }

        // è½¬æ¢ä¸ºçŸ©é˜µæ ¼å¼
        let mut dates: Vec<i64> = all_data.keys().cloned().collect();
        dates.sort();
        
        let n_dates = dates.len();
        let n_stocks = all_data.values().next().map_or(0, |v| v.len());
        
        let mut values = DMatrix::zeros(n_dates, n_stocks);
        
        for (date_idx, &date) in dates.iter().enumerate() {
            if let Some(row_values) = all_data.get(&date) {
                for (stock_idx, &value) in row_values.iter().enumerate() {
                    values[(date_idx, stock_idx)] = value;
                }
            }
        }

        let load_time = load_start.elapsed();
        println!("âœ… ç®€åŒ–å›é€€ç‰ˆæœ¬å› å­æ•°æ®åŠ è½½å®Œæˆ: {:.3}s", load_time.as_secs_f64());

        Ok(SimpleFallbackFactorData {
            dates,
            stocks,
            values,
        })
    }
}

/// æ‰§è¡Œç®€åŒ–çš„å›é€€ç‰ˆæœ¬å› å­ä¸­æ€§åŒ–
pub fn neutralize_factor_simple_fallback(
    factor_data: &SimpleFallbackFactorData,
    style_data: &SimpleFallbackStyleData,
) -> PyResult<SimpleFallbackNeutralizationResult> {
    
    let neutralization_start = Instant::now();
    
    let union_stocks = &factor_data.stocks;
    let n_dates = factor_data.dates.len();
    let n_union_stocks = union_stocks.len();
    
    let mut neutralized_values = DMatrix::from_element(n_dates, n_union_stocks, f64::NAN);
    
    println!("ğŸ”§ å¼€å§‹ç®€åŒ–å›é€€ç‰ˆæœ¬çš„å› å­ä¸­æ€§åŒ–å¤„ç†...");
    println!("   ğŸ“Š å¤„ç†ç»´åº¦: {}å¤© Ã— {}è‚¡ç¥¨", n_dates, n_union_stocks);
    
    let mut processed_dates = 0;
    
    // å¹¶è¡Œå¤„ç†æ¯ä¸ªæ—¥æœŸçš„ä¸­æ€§åŒ–
    let date_results: Vec<_> = factor_data.dates
        .par_iter()
        .enumerate()
        .filter_map(|(date_idx, &date)| {
            if let Some(day_data) = style_data.data_by_date.get(&date) {
                
                // è·å–å› å­å€¼å¹¶è®¡ç®—æ’å
                let mut factor_values = Vec::new();
                for stock_idx in 0..n_union_stocks {
                    factor_values.push(factor_data.values[(date_idx, stock_idx)]);
                }
                
                let ranked_values = rank_with_nan_handling_fallback(&factor_values);
                
                // æ‰§è¡Œç®€åŒ–å›å½’è®¡ç®—
                match perform_simple_regression_fallback(&ranked_values, day_data, union_stocks) {
                    Ok(neutralized_row) => Some((date_idx, neutralized_row)),
                    Err(_) => None
                }
            } else {
                None
            }
        })
        .collect();
    
    // æ”¶é›†ç»“æœ
    for (date_idx, neutralized_row) in date_results {
        for (stock_idx, value) in neutralized_row.into_iter().enumerate() {
            neutralized_values[(date_idx, stock_idx)] = value;
        }
        processed_dates += 1;
    }
    
    let neutralization_time = neutralization_start.elapsed();
    
    println!("âœ… ç®€åŒ–å›é€€ç‰ˆæœ¬ä¸­æ€§åŒ–å®Œæˆ:");
    println!("   ğŸ“… æˆåŠŸå¤„ç†æ—¥æœŸ: {}/{}", processed_dates, n_dates);
    println!("   â±ï¸  å¤„ç†ç”¨æ—¶: {:.3}s", neutralization_time.as_secs_f64());
    println!("   ğŸ“ˆ å¤„ç†é€Ÿåº¦: {:.1}å¤©/ç§’", processed_dates as f64 / neutralization_time.as_secs_f64());

    Ok(SimpleFallbackNeutralizationResult {
        dates: factor_data.dates.clone(),
        stocks: factor_data.stocks.clone(),
        neutralized_values,
    })
}

/// æ‰§è¡Œç®€åŒ–çš„å›å½’è®¡ç®—
fn perform_simple_regression_fallback(
    ranked_values: &[f64],
    day_data: &SimpleFallbackStyleDayData,
    union_stocks: &[String],
) -> PyResult<Vec<f64>> {
    
    // æ„å»ºæœ‰æ•ˆçš„å›å½’æ•°æ®
    let mut regression_y = Vec::new();
    let mut regression_x_indices = Vec::new();
    let mut valid_union_indices = Vec::new();
    
    for (union_idx, union_stock) in union_stocks.iter().enumerate() {
        if !ranked_values[union_idx].is_nan() {
            if let Some(style_idx) = day_data.stocks.iter().position(|s| s == union_stock) {
                regression_y.push(ranked_values[union_idx]);
                regression_x_indices.push(style_idx);
                valid_union_indices.push(union_idx);
            }
        }
    }
    
    if regression_y.len() < 12 {
        return Err(PyRuntimeError::new_err("æœ‰æ•ˆæ ·æœ¬æ•°é‡ä¸è¶³"));
    }
    
    // ä½¿ç”¨æœ€ç®€å•çš„OLSå›å½’
    let n_valid = regression_y.len();
    
    // æ„å»ºå›å½’çŸ©é˜µX (n_valid Ã— 12)
    let mut x_matrix = DMatrix::zeros(n_valid, 12);
    for (i, &style_idx) in regression_x_indices.iter().enumerate() {
        for j in 0..12 {
            x_matrix[(i, j)] = day_data.style_matrix[(style_idx, j)];
        }
    }
    
    // æ„å»ºå› å˜é‡å‘é‡y (n_valid Ã— 1)
    let y_vector = DVector::from_vec(regression_y.clone());
    
    // ä½¿ç”¨æ­£è§„æ–¹ç¨‹æ±‚è§£: beta = (X'X)^(-1) X'y
    let xt = x_matrix.transpose();
    let xtx = &xt * &x_matrix;
    
    match xtx.try_inverse() {
        Some(xtx_inv) => {
            let xty = &xt * &y_vector;
            let beta = &xtx_inv * &xty;
            
            // è®¡ç®—é¢„æµ‹å€¼å’Œæ®‹å·®
            let predicted = &x_matrix * &beta;
            let residuals = &y_vector - &predicted;
            
            // æ„å»ºä¸­æ€§åŒ–ç»“æœ
            let mut neutralized_row = vec![f64::NAN; union_stocks.len()];
            for (i, &union_idx) in valid_union_indices.iter().enumerate() {
                if i < residuals.len() {
                    neutralized_row[union_idx] = residuals[i];
                }
            }
            
            Ok(neutralized_row)
        },
        None => {
            Err(PyRuntimeError::new_err("å›å½’çŸ©é˜µä¸å¯é€†ï¼Œå¯èƒ½å­˜åœ¨å¤šé‡å…±çº¿æ€§"))
        }
    }
}

/// ç®€åŒ–çš„æ’åå‡½æ•°
fn rank_with_nan_handling_fallback(values: &[f64]) -> Vec<f64> {
    let n = values.len();
    let mut indexed_values: Vec<(usize, f64)> = values.iter()
        .enumerate()
        .filter(|(_, &val)| !val.is_nan())
        .map(|(idx, &val)| (idx, val))
        .collect();
    
    indexed_values.sort_by(|a, b| a.1.partial_cmp(&b.1).unwrap());
    
    let mut ranks = vec![f64::NAN; n];
    let valid_count = indexed_values.len();
    
    if valid_count > 0 {
        for (rank, &(original_idx, _)) in indexed_values.iter().enumerate() {
            ranks[original_idx] = (rank as f64) / (valid_count - 1) as f64;
        }
    }
    
    ranks
}

/// ä¿å­˜ç®€åŒ–çš„ç»“æœ
fn save_simple_fallback_result(
    result: &SimpleFallbackNeutralizationResult,
    output_path: &str,
) -> PyResult<()> {
    
    use parquet::arrow::ArrowWriter;
    use parquet::file::properties::WriterProperties;
    
    // åˆ›å»ºæ•°æ®
    let mut data = Vec::new();
    
    for (date_idx, &date) in result.dates.iter().enumerate() {
        for (stock_idx, stock) in result.stocks.iter().enumerate() {
            let value = result.neutralized_values[(date_idx, stock_idx)];
            if !value.is_nan() {
                data.push((date, stock.clone(), value));
            }
        }
    }
    
    if data.is_empty() {
        return Err(PyRuntimeError::new_err("æ²¡æœ‰æœ‰æ•ˆçš„ä¸­æ€§åŒ–ç»“æœ"));
    }
    
    // æ„å»ºArrowè®°å½•
    let dates: Vec<i64> = data.iter().map(|(d, _, _)| *d).collect();
    let stocks: Vec<String> = data.iter().map(|(_, s, _)| s.clone()).collect();
    let values: Vec<f64> = data.iter().map(|(_, _, v)| *v).collect();
    
    let date_array = Int64Array::from(dates);
    let stock_array = StringArray::from(stocks);
    let value_array = Float64Array::from(values);
    
    let schema = Arc::new(Schema::new(vec![
        Field::new("date", DataType::Int64, false),
        Field::new("stock", DataType::Utf8, false),
        Field::new("neutralized_value", DataType::Float64, false),
    ]));
    
    let batch = RecordBatch::try_new(
        schema.clone(),
        vec![
            Arc::new(date_array),
            Arc::new(stock_array), 
            Arc::new(value_array),
        ]
    ).map_err(|e| PyRuntimeError::new_err(format!("åˆ›å»ºè®°å½•æ‰¹å¤±è´¥: {}", e)))?;
    
    // å†™å…¥æ–‡ä»¶
    let file = File::create(output_path)
        .map_err(|e| PyRuntimeError::new_err(format!("åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤±è´¥: {}", e)))?;
    
    let props = WriterProperties::builder()
        .set_compression(parquet::basic::Compression::SNAPPY)
        .build();
    
    let mut writer = ArrowWriter::try_new(file, schema, Some(props))
        .map_err(|e| PyRuntimeError::new_err(format!("åˆ›å»ºParquetå†™å…¥å™¨å¤±è´¥: {}", e)))?;
    
    writer.write(&batch)
        .map_err(|e| PyRuntimeError::new_err(format!("å†™å…¥æ•°æ®å¤±è´¥: {}", e)))?;
    
    writer.close()
        .map_err(|e| PyRuntimeError::new_err(format!("å…³é—­å†™å…¥å™¨å¤±è´¥: {}", e)))?;
    
    Ok(())
}

/// ç®€åŒ–å›é€€ç‰ˆæœ¬æ‰¹é‡å› å­ä¸­æ€§åŒ–ä¸»å‡½æ•°
#[pyfunction]
pub fn batch_factor_neutralization_simple_fallback(
    style_data_path: &str,
    factor_files_dir: &str,
    output_dir: &str,
    num_threads: Option<usize>,
) -> PyResult<()> {
    // è®¾ç½®çº¿ç¨‹æ•°
    if let Some(threads) = num_threads {
        rayon::ThreadPoolBuilder::new()
            .num_threads(threads)
            .build_global()
            .map_err(|e| PyRuntimeError::new_err(format!("è®¾ç½®çº¿ç¨‹æ± å¤±è´¥: {}", e)))?;
    }
    
    let total_start = Instant::now();
    println!("ğŸš€ å¼€å§‹ç®€åŒ–å›é€€ç‰ˆæœ¬æ‰¹é‡å› å­ä¸­æ€§åŒ–å¤„ç†");
    println!("   ğŸ”§ ä¼˜åŒ–ç‰¹æ€§: æœ€ç®€OLSå›å½’, ç¨³å®šå¯é , æ”¯æŒçº¯è‚¡ç¥¨æ•°æ®æ ¼å¼");
    println!("   ğŸ§µ ä½¿ç”¨çº¿ç¨‹æ•°: {}", num_threads.unwrap_or_else(num_cpus::get));
    
    // 1. åŠ è½½é£æ ¼æ•°æ®
    let style_data = SimpleFallbackStyleData::load_from_parquet_simple_fallback(style_data_path)?;
    
    // 2. æ‰«æå› å­æ–‡ä»¶
    let factor_dir = Path::new(factor_files_dir);
    let mut factor_files = Vec::new();
    
    for entry in factor_dir.read_dir()
        .map_err(|e| PyRuntimeError::new_err(format!("è¯»å–å› å­ç›®å½•å¤±è´¥: {}", e)))? {
        let entry = entry
            .map_err(|e| PyRuntimeError::new_err(format!("è¯»å–ç›®å½•é¡¹å¤±è´¥: {}", e)))?;
        
        if let Some(ext) = entry.path().extension() {
            if ext == "parquet" {
                factor_files.push(entry.path());
            }
        }
    }
    
    println!("ğŸ“ æ‰¾åˆ°å› å­æ–‡ä»¶: {} ä¸ª", factor_files.len());
    
    // 3. å¹¶è¡Œå¤„ç†æ‰€æœ‰å› å­æ–‡ä»¶
    let processing_results: Vec<_> = factor_files
        .par_iter()
        .map(|factor_file| {
            process_single_factor_simple_fallback(factor_file, &style_data, output_dir)
        })
        .collect();
    
    // 4. ç»Ÿè®¡ç»“æœ
    let mut successful = 0;
    let mut failed = 0;
    
    for result in processing_results {
        match result {
            Ok(_) => successful += 1,
            Err(e) => {
                failed += 1;
                eprintln!("âŒ å¤„ç†å¤±è´¥: {}", e);
            }
        }
    }
    
    let total_time = total_start.elapsed();
    
    println!("\nğŸ‰ ç®€åŒ–å›é€€ç‰ˆæœ¬æ‰¹é‡å› å­ä¸­æ€§åŒ–å®Œæˆ!");
    println!("   âœ… æˆåŠŸå¤„ç†: {} ä¸ªæ–‡ä»¶", successful);
    println!("   âŒ å¤„ç†å¤±è´¥: {} ä¸ªæ–‡ä»¶", failed);
    println!("   â±ï¸  æ€»ç”¨æ—¶: {:.3}s", total_time.as_secs_f64());
    println!("   ğŸ“ˆ å¹³å‡é€Ÿåº¦: {:.2} æ–‡ä»¶/ç§’", successful as f64 / total_time.as_secs_f64());
    
    Ok(())
}

/// å¤„ç†å•ä¸ªå› å­æ–‡ä»¶ï¼ˆç®€åŒ–å›é€€ç‰ˆæœ¬ï¼‰
fn process_single_factor_simple_fallback(
    factor_file: &PathBuf,
    style_data: &SimpleFallbackStyleData,
    output_dir: &str,
) -> PyResult<()> {
    let file_start = Instant::now();
    
    // åŠ è½½å› å­æ•°æ®
    let factor_data = SimpleFallbackFactorData::load_from_parquet_simple_fallback(
        factor_file.to_str().unwrap()
    )?;
    
    // æ‰§è¡Œä¸­æ€§åŒ–
    let result = neutralize_factor_simple_fallback(&factor_data, style_data)?;
    
    // ä¿å­˜ç»“æœ
    let output_file = Path::new(output_dir).join(
        factor_file.file_name().unwrap()
    );
    
    save_simple_fallback_result(&result, output_file.to_str().unwrap())?;
    
    let file_time = file_start.elapsed();
    println!("âœ… å¤„ç†å®Œæˆ: {} ({:.3}s)", 
             factor_file.file_name().unwrap().to_str().unwrap(),
             file_time.as_secs_f64());
    
    Ok(())
}