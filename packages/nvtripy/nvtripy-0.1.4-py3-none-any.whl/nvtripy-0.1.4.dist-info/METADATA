Metadata-Version: 2.1
Name: nvtripy
Version: 0.1.4
Summary: Tripy: A Python Programming Model For TensorRT
Author-email: NVIDIA <svc_tensorrt@nvidia.com>
License: Apache 2.0
Project-URL: Repository, https://github.com/NVIDIA/tensorrt-incubator/tripy/
Project-URL: Issues, https://github.com/NVIDIA/tensorrt-incubator/issues
Project-URL: Documentation, https://nvidia.github.io/TensorRT-Incubator/
Requires-Python: >=3.9
Description-Content-Type: text/markdown
License-File: LICENSE
License-File: NOTICE
Requires-Dist: tensorrt<=10.13.0.35,>=10.11
Requires-Dist: mlir-tensorrt-compiler==0.1.43+cuda12.trt109
Requires-Dist: mlir-tensorrt-runtime==0.1.43+cuda12.trt109
Requires-Dist: colored==2.2.3
Provides-Extra: build
Requires-Dist: setuptools==75.3.0; extra == "build"
Requires-Dist: wheel==0.44.0; extra == "build"
Requires-Dist: mypy==1.11.0; extra == "build"
Provides-Extra: dev
Requires-Dist: pre-commit==3.6.0; extra == "dev"
Provides-Extra: doc_test_common
Requires-Dist: black==24.10.0; extra == "doc-test-common"
Requires-Dist: torch==2.4.0+cu121; extra == "doc-test-common"
Requires-Dist: numpy==1.25.0; extra == "doc-test-common"
Requires-Dist: nvidia-cuda-nvrtc-cu12; extra == "doc-test-common"
Requires-Dist: cupy-cuda12x; extra == "doc-test-common"
Provides-Extra: docs
Requires-Dist: sphinx==7.2.6; extra == "docs"
Requires-Dist: furo==2024.8.6; extra == "docs"
Requires-Dist: sphinx-copybutton==0.5.2; extra == "docs"
Requires-Dist: sphinx-toolbox==3.5.0; extra == "docs"
Requires-Dist: docutils==0.20.1; extra == "docs"
Requires-Dist: myst-parser==2.0.0; extra == "docs"
Requires-Dist: sphinxcontrib-mermaid==0.9.2; extra == "docs"
Requires-Dist: nvtripy[doc_test_common]; extra == "docs"
Requires-Dist: nvidia-modelopt==0.11.1; extra == "docs"
Requires-Dist: transformers==4.44.2; extra == "docs"
Requires-Dist: datasets==2.21.0; extra == "docs"
Provides-Extra: test
Requires-Dist: pytest==7.1.3; extra == "test"
Requires-Dist: pytest-virtualenv==1.8.0; extra == "test"
Requires-Dist: pytest-profiling==1.7.0; extra == "test"
Requires-Dist: pytest-cov==4.1.0; extra == "test"
Requires-Dist: pytest-xdist==3.6.1; extra == "test"
Requires-Dist: pytest-benchmark==4.0.0; extra == "test"
Requires-Dist: pytest-lazy-fixture==0.6.3; extra == "test"
Requires-Dist: pytest-mock==3.14.0; extra == "test"
Requires-Dist: path.py==12.5.0; extra == "test"
Requires-Dist: triton==3.0.0; extra == "test"
Requires-Dist: snakeviz==2.2.0; extra == "test"
Requires-Dist: coverage==7.4.1; extra == "test"
Requires-Dist: vulture==2.11; extra == "test"
Requires-Dist: nvtripy[doc_test_common]; extra == "test"
Requires-Dist: pytest-notebook==0.10.0; extra == "test"
Requires-Dist: notebook==7.2.2; extra == "test"
Requires-Dist: polygraphy==0.49.20; extra == "test"


# Tripy: A Python Programming Model For TensorRT

[**Quick Start**](#quick-start)
| [**Installation**](#installation)
| [**Examples**](https://github.com/NVIDIA/TensorRT-Incubator/tree/main/tripy/examples)
| [**Notebooks**](https://github.com/NVIDIA/TensorRT-Incubator/tree/main/tripy/notebooks)
| [**Contributing**](https://github.com/NVIDIA/TensorRT-Incubator/blob/main/tripy/CONTRIBUTING.md)
| [**Documentation**](https://nvidia.github.io/TensorRT-Incubator/)

<!-- Tripy: DOC: OMIT Start -->
[![Tripy L1](https://github.com/NVIDIA/TensorRT-Incubator/actions/workflows/tripy-l1.yml/badge.svg)](https://github.com/NVIDIA/TensorRT-Incubator/actions/workflows/tripy-l1.yml)
<!-- Tripy: DOC: OMIT End -->

**Tripy** is a debuggable, Pythonic frontend for [TensorRT](https://developer.nvidia.com/tensorrt),
a deep learning inference compiler.

What you can expect:

- **High performance** by leveraging [TensorRT](https://developer.nvidia.com/tensorrt)'s optimization capabilties.
- An **intuitive API** that follows conventions of the ecosystem.
- **Debuggability** with features like **eager mode** to interactively debug mistakes.
- **Excellent error messages** that are informative and actionable.
- **Friendly documentation** that is comprehensive but concise, with code examples.


## Installation

```bash
python3 -m pip install nvtripy -f https://nvidia.github.io/TensorRT-Incubator/packages.html
```


## Quick Start

See the
[Introduction To Tripy](https://nvidia.github.io/TensorRT-Incubator/pre0_user_guides/00-introduction-to-tripy.html)
guide for details:

<!-- Tripy: DOC: NO_PRINT_LOCALS Start -->
- **Defining** a model:

    ```py
    class Model(tp.Module):
        def __init__(self):
            self.conv = tp.Conv(in_channels=1, out_channels=1, kernel_dims=[3, 3])

        def forward(self, x):
            x = self.conv(x)
            x = tp.relu(x)
            return x
    ```

- **Initializing** it:

    ```py
    model = Model()
    model.load_state_dict(
        {
            "conv.weight": tp.ones((1, 1, 3, 3)),
            "conv.bias": tp.ones((1,)),
        }
    )

    dummy_input = tp.ones((1, 1, 4, 4)).eval()
    ```

- Executing in **eager mode**:

    ```py
    eager_out = model(dummy_input)
    ```

- **Compiling** and executing:

    ```py
    compiled_model = tp.compile(
        model,
        args=[tp.InputInfo(shape=(1, 1, 4, 4), dtype=tp.float32)],
    )

    compiled_out = compiled_model(dummy_input)
    ```
<!-- Tripy: DOC: NO_PRINT_LOCALS End -->


<!-- Tripy: DOC: OMIT Start -->
## Building Wheels From Source

For the latest changes, build Tripy wheels from source:

1. Install `build`:

    ```bash
    python3 -m pip install build
    ```

2. Build a wheel from the [`tripy` root directory](.):

    ```bash
    python3 -m build . -w
    ```

3. Install the wheel from the [`tripy` root directory](.):

    ```bash
    python3 -m pip install -f https://nvidia.github.io/TensorRT-Incubator/packages.html dist/nvtripy-*.whl
    ```

4. **[Optional]** Sanity check:

    ```bash
    python3 -c "import nvtripy as tp; x = tp.ones((5,), dtype=tp.int32); assert x.tolist() == [1] * 5"
    ```
<!-- Tripy: DOC: OMIT End -->
