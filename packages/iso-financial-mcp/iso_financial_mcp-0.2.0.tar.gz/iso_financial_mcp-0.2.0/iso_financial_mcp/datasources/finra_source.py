"""
FINRA Short Volume data client
Handles daily short volume CSV parsing with caching and error handling
"""

import asyncio
import aiohttp
import pandas as pd
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Any
from cachetools import TTLCache
from asyncio_throttle import Throttler
import logging
import io

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Cache with 24-hour TTL as per requirements
finra_cache = TTLCache(maxsize=500, ttl=86400)  # 24 hours = 86400 seconds

# Rate limiter for FINRA API (5 requests per second to be conservative)
finra_throttler = Throttler(rate_limit=5, period=1.0)

class FINRAError(Exception):
    """Custom exception for FINRA API errors"""
    pass

async def get_finra_short_volume(
    ticker: str,
    start_date: str = None,
    end_date: str = None
) -> List[Dict[str, Any]]:
    """
    Retrieve FINRA daily short volume data with caching and rate limiting.
    
    Args:
        ticker: Stock ticker symbol
        start_date: Start date in YYYY-MM-DD format (default: 30 days ago)
        end_date: End date in YYYY-MM-DD format (default: today)
    
    Returns:
        List of short volume dictionaries with date, short_volume, total_volume, and ratio
    """
    # Set default date range if not provided
    if not end_date:
        end_date = datetime.now().strftime("%Y-%m-%d")
    if not start_date:
        start_date = (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")
    
    # Create cache key
    cache_key = f"finra_short_{ticker}_{start_date}_{end_date}"
    
    # Check cache first
    if cache_key in finra_cache:
        logger.info(f"FINRA short volume cache hit for {ticker}")
        return finra_cache[cache_key]
    
    try:
        # Apply rate limiting
        async with finra_throttler:
            short_data = await _fetch_finra_short_volume(ticker, start_date, end_date)
            
        # Cache the results
        finra_cache[cache_key] = short_data
        logger.info(f"FINRA short volume fetched and cached for {ticker}: {len(short_data)} records")
        
        return short_data
        
    except Exception as e:
        logger.error(f"Error fetching FINRA short volume for {ticker}: {e}")
        # Return empty list on error for graceful degradation
        return []

async def _fetch_finra_short_volume(
    ticker: str,
    start_date: str,
    end_date: str
) -> List[Dict[str, Any]]:
    """
    Internal function to fetch FINRA short volume data.
    """
    # Parse date range
    start_dt = datetime.strptime(start_date, "%Y-%m-%d")
    end_dt = datetime.strptime(end_date, "%Y-%m-%d")
    
    short_data = []
    
    headers = {
        "User-Agent": "IsoFinancial-MCP/1.0 (contact@example.com)",
        "Accept": "text/csv"
    }
    
    async with aiohttp.ClientSession(headers=headers) as session:
        # FINRA publishes daily short volume data
        # We need to fetch data for each date in the range
        current_date = start_dt
        
        while current_date <= end_dt:
            date_str = current_date.strftime("%Y%m%d")
            
            # FINRA short volume data URL format
            # Note: This is a simplified approach - actual FINRA data might require different URLs
            url = f"https://cdn.finra.org/equity/regsho/daily/CNMSshvol{date_str}.txt"
            
            try:
                async with session.get(url) as response:
                    if response.status == 200:
                        content = await response.text()
                        daily_data = _parse_finra_csv(content, ticker, current_date.strftime("%Y-%m-%d"))
                        if daily_data:
                            short_data.extend(daily_data)
                    else:
                        logger.debug(f"No FINRA data available for {date_str} (status: {response.status})")
                        
            except Exception as e:
                logger.debug(f"Error fetching FINRA data for {date_str}: {e}")
                continue
            
            current_date += timedelta(days=1)
            
            # Add small delay to avoid overwhelming the server
            await asyncio.sleep(0.1)
    
    # Sort by date (most recent first)
    short_data.sort(key=lambda x: x["date"], reverse=True)
    
    return short_data

def _parse_finra_csv(content: str, ticker: str, date: str) -> List[Dict[str, Any]]:
    """
    Parse FINRA CSV content and extract data for specific ticker.
    """
    try:
        # FINRA CSV format typically has columns: Date|Symbol|ShortVolume|ShortExemptVolume|TotalVolume|Market
        lines = content.strip().split('\n')
        
        results = []
        
        for line in lines:
            if not line or line.startswith('#'):  # Skip comments and empty lines
                continue
                
            parts = line.split('|')
            if len(parts) < 5:
                continue
            
            # Extract fields (adjust indices based on actual FINRA format)
            symbol = parts[1].strip()
            
            if symbol.upper() != ticker.upper():
                continue
            
            try:
                short_volume = int(parts[2])
                short_exempt_volume = int(parts[3]) if len(parts) > 3 else 0
                total_volume = int(parts[4])
                
                # Calculate short ratio
                short_ratio = (short_volume / total_volume) if total_volume > 0 else 0.0
                
                result = {
                    "date": date,
                    "symbol": symbol,
                    "short_volume": short_volume,
                    "short_exempt_volume": short_exempt_volume,
                    "total_volume": total_volume,
                    "short_ratio": round(short_ratio, 4),
                    "short_percentage": round(short_ratio * 100, 2)
                }
                
                results.append(result)
                
            except (ValueError, IndexError) as e:
                logger.debug(f"Error parsing FINRA line '{line}': {e}")
                continue
        
        return results
        
    except Exception as e:
        logger.error(f"Error parsing FINRA CSV content: {e}")
        return []

# Alternative implementation using a proxy/aggregator service
async def _fetch_finra_short_volume_alternative(
    ticker: str,
    start_date: str,
    end_date: str
) -> List[Dict[str, Any]]:
    """
    Alternative implementation using a financial data aggregator.
    This is a fallback when direct FINRA access is not available.
    """
    # This could use services like:
    # - Yahoo Finance (limited short interest data)
    # - Alpha Vantage
    # - Financial Modeling Prep
    # - Or other financial data providers
    
    # For now, return mock data structure to demonstrate the expected format
    logger.warning(f"Using alternative FINRA data source for {ticker}")
    
    # Generate mock data for demonstration
    start_dt = datetime.strptime(start_date, "%Y-%m-%d")
    end_dt = datetime.strptime(end_date, "%Y-%m-%d")
    
    mock_data = []
    current_date = start_dt
    
    while current_date <= end_dt:
        # Skip weekends
        if current_date.weekday() < 5:  # Monday = 0, Friday = 4
            mock_data.append({
                "date": current_date.strftime("%Y-%m-%d"),
                "symbol": ticker.upper(),
                "short_volume": 100000,  # Mock data
                "short_exempt_volume": 5000,
                "total_volume": 500000,
                "short_ratio": 0.2,
                "short_percentage": 20.0
            })
        
        current_date += timedelta(days=1)
    
    return mock_data

# Utility functions
def clear_finra_cache():
    """Clear the FINRA short volume cache"""
    finra_cache.clear()
    logger.info("FINRA short volume cache cleared")

def get_cache_stats() -> Dict[str, Any]:
    """Get FINRA cache statistics"""
    return {
        "cache_size": len(finra_cache),
        "max_size": finra_cache.maxsize,
        "ttl": finra_cache.ttl,
        "hits": getattr(finra_cache, 'hits', 0),
        "misses": getattr(finra_cache, 'misses', 0)
    }

def calculate_short_metrics(short_data: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    Calculate aggregate short volume metrics from daily data.
    """
    if not short_data:
        return {}
    
    # Calculate averages and trends
    total_short = sum(d["short_volume"] for d in short_data)
    total_volume = sum(d["total_volume"] for d in short_data)
    avg_short_ratio = sum(d["short_ratio"] for d in short_data) / len(short_data)
    
    # Calculate recent vs historical comparison
    recent_data = short_data[:5]  # Last 5 days
    historical_data = short_data[5:] if len(short_data) > 5 else []
    
    recent_avg_ratio = sum(d["short_ratio"] for d in recent_data) / len(recent_data) if recent_data else 0
    historical_avg_ratio = sum(d["short_ratio"] for d in historical_data) / len(historical_data) if historical_data else recent_avg_ratio
    
    return {
        "total_short_volume": total_short,
        "total_volume": total_volume,
        "overall_short_ratio": round(total_short / total_volume if total_volume > 0 else 0, 4),
        "average_daily_short_ratio": round(avg_short_ratio, 4),
        "recent_short_ratio": round(recent_avg_ratio, 4),
        "historical_short_ratio": round(historical_avg_ratio, 4),
        "short_ratio_trend": "increasing" if recent_avg_ratio > historical_avg_ratio else "decreasing",
        "days_analyzed": len(short_data)
    }