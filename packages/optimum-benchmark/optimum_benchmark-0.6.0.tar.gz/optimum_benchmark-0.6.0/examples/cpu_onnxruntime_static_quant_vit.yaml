defaults:
  - benchmark
  - backend: onnxruntime
  - scenario: inference
  - launcher: process
  - _base_
  - _self_

name: cpu_onnxruntime_static_quant_vit

backend:
  device: cpu
  export: true
  no_weights: true
  model: google/vit-base-patch16-224
  quantization: true
  quantization_config:
    is_static: true
    per_channel: false
  calibration: true

scenario:
  memory: true
  latency: true
  input_shapes:
    batch_size: 2
