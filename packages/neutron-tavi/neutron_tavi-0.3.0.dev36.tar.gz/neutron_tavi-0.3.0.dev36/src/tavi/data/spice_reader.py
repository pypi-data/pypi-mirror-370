# -*- coding: utf-8 -*-
import os
import warnings
import xml.etree.ElementTree as ET
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple, Union

import numpy as np


def parse_countfile(countfile: str):
    """Pasre the countfile for HB1 in polarized mode."""
    norm_vals = []
    norm_channels = []
    labels = []
    label_p = ""
    label_sf = ""
    num_of_channel = 1

    for line in countfile.split(","):
        line = line.strip()
        # determin the directio of polarization
        if "parq" in line:
            label_p = "Px"
        elif "perpqh" in line:
            label_p = "Py"
        elif "perpq" in line:
            label_p = "Pz"

        # detemine SF or NSF
        if any(s in line for s in ["drive hguide off vguide off", "floff", "drive hguide 0 vguide 0"]):
            label_sf = "NSF"
        elif any(s in line for s in ["drive hguide on vguide on", "flon", "drive"]):
            label_sf = "SF"

        # extract preset channel and value
        if "count preset" in line:
            (*_, norm_channel, norm_val) = line.split()
            norm_vals.append(float(norm_val))
            norm_channels.append(norm_channel + f"_{num_of_channel}")
            labels.append(f"{label_p} {label_sf}")
            num_of_channel += 1

    return norm_vals, norm_channels, labels


def metadata_to_dict(metadata_list: List[str]) -> Tuple[Dict[str, str], Optional[List[str]]]:
    """Format metadata to a dict. Return error message if existing."""
    metadata = {}
    unrecognized = []

    for line in metadata_list:
        line = line.lstrip("#").strip()

        if "completed" in line or "stopped" in line:  # last line
            try:
                time, meridiem, date, *_ = [p.strip() for p in line.split()]
                metadata["end_time"] = f"{date} {time} {meridiem}"
            except ValueError:
                print(f"Incomplete datetime information in: {line}")

        elif "=" in line:
            key, *vals = [p.strip() for p in line.split("=")]
            # use "=".join in case "=" is in title or other user input
            if key in metadata:
                metadata[key] += ", " + "=".join(vals)
            else:
                metadata[key] = "=".join(vals)

        else:
            unrecognized.append(line)

    # HB1 in polarization mode
    if metadata.get("preset_type") == "countfile":
        norm_vals, norm_channels, labels = parse_countfile(metadata["countfile"])
        metadata.update({"norm_vals": norm_vals})
        metadata.update({"norm_channels": norm_channels})
        metadata.update({"labels": labels})

    return (metadata, None if not unrecognized else unrecognized)


def read_spice_datafile(
    file_name: Union[str, Path],
) -> Tuple[
    Dict[str, str],
    Optional[Dict[str, np.ndarray]],
    Optional[List[str]],
    Optional[List[str]],
]:
    """Reads an ASCII data file generated by SPICE and extracts structured information.

    Args:
        file_name (str | Path): Path to the SPICE ASCII file.

    Returns:
        metadata (dict): Metadata extracted from comment lines.
        data (dict | None): Data column names and values.
        others (list | None): Unrecognized comment lines.
        error_msg (list | None): Lines indicating errors (e.g., unreachable motor positions).

    """

    file_path = Path(file_name)

    # --- Enforce file is valid ---
    if not file_path.exists():
        raise FileNotFoundError(f"File does not exist: {file_name}")

    if not file_path.is_file():
        raise ValueError(f"Provided path is not a file: {file_name}")

    if file_path.suffix != ".dat":
        raise ValueError(f"Unrecognized file extension: {file_path.suffix}")

    # --- Proceed with reading ---
    with open(file_name, encoding="utf-8") as f:
        all_content = f.readlines()

    headers = [line.strip() for line in all_content if line.strip().startswith("#")]

    try:
        index_col_headers = headers.index("# col_headers =")
        col_names = headers[index_col_headers + 1].lstrip("#").split()
        # remove the dot before it causes problem
        # index_of_pt = col_names.index("Pt.")
        # col_names[index_of_pt] = "Pt"
    except ValueError:
        # should not reach here, "# col_headers =" always exsits
        raise ValueError("Missing '# col_headers =' in header")

    metadata_list = headers[:index_col_headers]
    error_and_summary = headers[index_col_headers + 2 :]

    # add summary at the end of file to metadata
    try:
        index_sum_count = next(i for i, h in enumerate(error_and_summary) if h.startswith("# Sum of Counts ="))
        error_msg, summary = error_and_summary[:index_sum_count], error_and_summary[index_sum_count:]
        metadata_list += summary

    except StopIteration:
        # "Sum of Counts" doesn't exist, happens to the last scan after beam is down
        error_msg = None

    metadata, unrecognized = metadata_to_dict(metadata_list)

    # --- Read numerical data ---
    with warnings.catch_warnings():
        warnings.simplefilter("ignore", category=UserWarning)
        data_array = np.genfromtxt(file_name, comments="#")

    if data_array.size == 0:
        data = None
    else:
        data = {k: np.atleast_1d(v) for k, v in zip(col_names, data_array.T)}

    return metadata, data, unrecognized, error_msg


def parse_ini(contents: List[str]) -> dict[str, Any]:
    ubconf: dict[str, Any] = {}
    for idx, line in enumerate(contents):
        line = line.strip()
        if not line:
            continue  # skip if '\n'
        elif line.startswith("[") and line.endswith("]"):
            continue  # skip lines like "[xx]"
        if "=" not in line:
            continue

        key, val = line.split("=", maxsplit=1)
        key = key.strip()
        val = val.strip()

        if key == "Mode":
            mode_name = contents[idx - 1].strip()
            if mode_name == "[UBMode]":
                ubconf["UBMode"] = int(val)
            elif mode_name == "[AngleMode]":
                ubconf["AngleMode"] = int(val)
        elif "," in val:  # string of vector to array
            ubconf[key] = np.array([float(v) for v in val.strip('"').split(",")])
        elif val == '""':
            continue  # empty value
        else:
            try:
                ubconf[key] = float(val)
            except ValueError:
                ubconf[key] = val  # fallback to string
    return ubconf


def parse_xml(contents: str) -> dict[str, Any]:
    ubconf: dict[str, Any] = {}
    try:
        root = ET.fromstring(contents)
    except ET.ParseError as e:
        raise ValueError(f"Failed to parse XML-style UB file: {e}") from e

    matrix_element = root.find("matrix")
    if matrix_element is None:
        raise ValueError("No <matrix> element found in XML content")

    raw_values = matrix_element.attrib.get("matrix", "").split()
    values = [float(s) for s in raw_values if s]

    if len(values) != 9:
        raise ValueError(f"Expected 9 elements for UBMatrix, got {len(values)}")

    ubconf["UBMatrix"] = values
    return ubconf


def read_spice_ubconf(ub_file_name: Union[str, Path]) -> dict[str, Any]:
    """Reads UB information from a UBConf .ini or XML-style configuration file.

    Supports old SPICE-style .ini UBMode files and XML-style files produced by C# .

    Args:
        ub_file_name (str | Path): Path to the UB configuration file (.ini)

    Returns:
        dict[str, Any]: Dictionary of UB configuration values, including UB matrix and modes.
    """

    file_path = Path(ub_file_name)
    # --- Enforce file is valid ---
    if not file_path.exists():
        raise FileNotFoundError(f"UB File does not exist: {ub_file_name}")

    if not file_path.is_file():
        raise ValueError(f"Provided path is not a file: {ub_file_name}")

    if file_path.suffix not in (".ini", ".dat"):
        raise ValueError(f"Unrecognized file extension: {file_path.suffix}")

    with open(ub_file_name, "r", encoding="utf-8") as f:
        all_content = f.readlines()

    first_line = all_content[0]
    if "[UBMode]" in first_line:
        ubconf = parse_ini(all_content)
    elif "xml" in first_line:
        ubconf = parse_xml("\n".join(all_content))

    return ubconf


def _create_spicelogs(path_to_scan_file: str) -> dict:
    """read in SPICE data, return a dictionary containing metadata and data columns"""

    (data, col_names, metadata, others, error_messages) = read_spice_datafile(path_to_scan_file)
    *_, file_name = path_to_scan_file.split("/")
    instrument_str, *_ = file_name.split("_")
    # write SPICElogs attributes
    attrs_dict = {"instrument": instrument_str}
    for k, v in metadata.items():
        attrs_dict.update({k: v})
    if len(error_messages) != 0:
        attrs_dict.update({"Error Messages": error_messages})
    if len(others) != 0:
        attrs_dict.update({"Others": others})

    # write SPICElogs datasets
    dataset_dict = {}
    spice_data_shape = data.shape
    if len(spice_data_shape) == 1:  # 1 row only
        if spice_data_shape[0] != 0:
            for idx, col_header in enumerate(col_names):
                # convert to ndarray if one point only
                dataset_dict.update({col_header: np.array([data[idx]])})
        else:  # ignore if empty
            pass
    elif len(spice_data_shape) == 2:  # nomarl data with multiple rows
        # print(scan_num)
        # print(spice_data.shape)
        for idx, col_header in enumerate(col_names):
            dataset_dict.update({col_header: data[:, idx]})
    spicelogs = {"metadata": attrs_dict}
    spicelogs.update(dataset_dict)

    scan_path = os.path.abspath(path_to_scan_file)
    folder_path = os.path.dirname(os.path.split(scan_path)[0])

    ub_file_name = metadata["ubconf"]
    # clean up the mess DAC made
    if "\\" in ub_file_name:  # ubconf can be a Windows path in some scans
        ub_file = ub_file_name.split("\\")[-1]
    elif "/" in ub_file_name:  # ubconf can be a Windows path in some scans
        ub_file = ub_file_name.split("/")[-1]
    else:
        ub_file = ub_file_name

    ub_file_path = os.path.join("/", folder_path, "UBConf", ub_file)
    ub_temp_file_path = os.path.join("/", folder_path, "UBConf", "temp", ub_file)

    if os.path.isfile(ub_file_path):
        ub_conf_dict = {"file_path": ub_file_path}
    elif os.path.isfile(ub_temp_file_path):
        ub_conf_dict = {"file_path": ub_temp_file_path}
    else:
        # ub_conf_dict = {"file_path": ""}
        ub_conf_dict = {}
        print(f"Cannot find UB file {metadata['ubconf']}")

    if not ub_conf_dict:
        pass
    else:
        ubconf = read_spice_ubconf(ub_file_path)
        for k, v in ubconf.items():
            ub_conf_dict.update({k: v})

        spicelogs.update({"ub_conf": ub_conf_dict})

    return spicelogs


def _create_spicelogs(path_to_scan_file: str) -> dict:
    """read in SPICE data, return a dictionary containing metadata and data columns"""

    metadata, data, unrecognized, error_msg = read_spice_datafile(path_to_scan_file)

    *_, file_name = path_to_scan_file.split("/")
    instrument_str, *_ = file_name.split("_")
    # write SPICElogs attributes
    attrs_dict = {"instrument": instrument_str}
    for k, v in metadata.items():
        attrs_dict.update({k: v})
    if not error_msg:
        attrs_dict.update({"Error Messages": error_msg})
    if unrecognized is not None:
        attrs_dict.update({"Others": unrecognized})

    # write SPICElogs datasets
    # dataset_dict = {}
    # spice_data_shape = data.shape
    # if len(spice_data_shape) == 1:  # 1 row only
    #     if spice_data_shape[0] != 0:
    #         for idx, col_header in enumerate(data):
    #             # convert to ndarray if one point only
    #             dataset_dict.update({col_header: np.array([data[idx]])})
    #     else:  # ignore if empty
    #         pass
    # elif len(spice_data_shape) == 2:  # nomarl data with multiple rows
    #     # print(scan_num)
    #     # print(spice_data.shape)
    #     for idx, col_header in enumerate(col_names):
    #         dataset_dict.update({col_header: data[:, idx]})

    spicelogs = {"metadata": attrs_dict}
    if data is not None:
        spicelogs.update(data)

    scan_path = os.path.abspath(path_to_scan_file)
    folder_path = os.path.dirname(os.path.split(scan_path)[0])

    ub_file_name = metadata["ubconf"]
    # clean up the mess DAC made
    if "\\" in ub_file_name:  # ubconf can be a Windows path in some scans
        ub_file = ub_file_name.split("\\")[-1]
    elif "/" in ub_file_name:  # ubconf can be a Windows path in some scans
        ub_file = ub_file_name.split("/")[-1]
    else:
        ub_file = ub_file_name

    ub_file_path = os.path.join("/", folder_path, "UBConf", ub_file)
    ub_temp_file_path = os.path.join("/", folder_path, "UBConf", "temp", ub_file)

    if os.path.isfile(ub_file_path):
        ub_conf_dict = {"file_path": ub_file_path}
    elif os.path.isfile(ub_temp_file_path):
        ub_conf_dict = {"file_path": ub_temp_file_path}
    else:
        # ub_conf_dict = {"file_path": ""}
        ub_conf_dict = {}
        print(f"Cannot find UB file {metadata['ubconf']}")

    if not ub_conf_dict:
        pass
    else:
        ubconf = read_spice_ubconf(ub_file_path)
        for k, v in ubconf.items():
            ub_conf_dict.update({k: v})

        spicelogs.update({"ub_conf": ub_conf_dict})

    return spicelogs
