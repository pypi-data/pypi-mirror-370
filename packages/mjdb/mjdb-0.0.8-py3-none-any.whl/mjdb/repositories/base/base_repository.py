# from src.db.interfaces.base_repository import BaseRepository
import logging

from mjdb.repositories.abstract.abstract_repository import AbstractRepository
# from src.db.session import get_session_context
from sqlalchemy.sql import text
import os
from dotenv import load_dotenv

from typing import Any, List, Optional, Type, TypeVar
from mjdb.session.sql_alchemy_db_session import SQLAlchemyDbSession
from mjdb.session.types.session_context import SessionContext
from mjdb.session.types.session_config import SessionConfig

from typing import Generator, Dict
from tqdm import tqdm
from sqlalchemy.dialects.mysql import insert
import pandas as pd
# from overrides import override
from sqlalchemy.exc import SQLAlchemyError
import math

EntityType = TypeVar("EntityType")
load_dotenv()

os.environ["STOCK_DATABASE_URL"] = "mysql+pymysql://root:root@192.168.1.3:3307/stock"


class BaseSQLAlchemyRepository(AbstractRepository[EntityType]):
    """
     SQLAlchemy ê¸°ë°˜ì˜ ë²”ìš©(generic) ì €ì¥ì†Œ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.

     ì´ í´ë˜ìŠ¤ëŠ” íŠ¹ì • SQLAlchemy ëª¨ë¸(EntityType)ì„ ë°›ì•„,
     ë°ì´í„°ë² ì´ìŠ¤ì— ëŒ€í•œ ê¸°ë³¸ì ì¸ CRUD ì‘ì—…(Create, Read, Update, Delete)ê³¼
     Raw SQL ì‹¤í–‰ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

     ì‚¬ìš© ì˜ˆì‹œ:
         >>> repo = BaseSQLAlchemyRepository(DailyStockRiseReasonKeywords)
         >>> all_items = repo.get_all()
         >>> item = repo.get_by_column('2025-05-14', column_name='base_dt')
         >>> repo.add(new_item)
         >>> repo.update(updated_item)
         >>> repo.delete(item)
         >>> result = repo.execute_raw_query("SELECT * FROM table_name")

     ì£¼ìš” ë©”ì„œë“œ:
         - get_by_column: íŠ¹ì • ì»¬ëŸ¼ ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ë‹¨ì¼ ì—”í‹°í‹° ì¡°íšŒ
         - get_all: ì „ì²´ ì—”í‹°í‹° ì¡°íšŒ
         - add: ì—”í‹°í‹° ì¶”ê°€
         - update: ì—”í‹°í‹° ìˆ˜ì •
         - delete: ì—”í‹°í‹° ì‚­ì œ
         - execute_raw_query: Raw SQL ì¿¼ë¦¬ ì‹¤í–‰
         - close: ì„¸ì…˜ ê°•ì œ ì¢…ë£Œ (ë³´í†µ í•„ìš” ì—†ìŒ)
     """
    def __init__(
            self,
            model: Type[EntityType],
            context: Optional[SessionContext] = None,
            log_level: int = logging.INFO
    ):
        """
        SQLAlchemyRepository ìƒì„±ì

        Args:
            model (Type[EntityType]): ë‹¤ë£¨ê³ ì í•˜ëŠ” SQLAlchemy ëª¨ë¸ í´ë˜ìŠ¤
            db_url (str): ë°ì´í„°ë² ì´ìŠ¤ ì ‘ì† URL (ê¸°ë³¸ê°’ì€ í™˜ê²½ ë³€ìˆ˜ë¡œë¶€í„° ê°€ì ¸ì˜´)

        ì‘ë™ ë°©ì‹:
            - get_session_context í•¨ìˆ˜ë¥¼ í†µí•´ ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ìƒì„±
            - ì „ë‹¬ë°›ì€ ëª¨ë¸ í´ë˜ìŠ¤ë¥¼ ì €ì¥ì†Œì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •
        """

        ctx = context or SessionContext(
            db_url=os.getenv("DB_URL"),
            session_config=SessionConfig(expire_on_commit=False)
        )

        self.sql_alchemy_db_session = SQLAlchemyDbSession(context=ctx, log_level=log_level)
        self.session_scope = self.sql_alchemy_db_session.get_session_context()
        self.model = model
        super().__init__(log_level=log_level)
        self.print_public_attributes()

    def get_by_column(self, value: Any, column_name: str = "id") -> Optional[EntityType]:
        """
        ì»¬ëŸ¼ëª…ì„ ìœ ë™ì ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì¡°íšŒí•˜ëŠ” í•¨ìˆ˜.
        :param column_name: ì¡°íšŒí•  ì»¬ëŸ¼ëª… (ì˜ˆ: 'ticker', 'base_dt' ë“±)
        :param value: í•´ë‹¹ ì»¬ëŸ¼ì—ì„œ ì°¾ì„ ê°’
        :return: í•´ë‹¹ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì²« ë²ˆì§¸ ì—”í‹°í‹°
        """

        with self.session_scope() as session:
            v = session.query(self.model).filter(getattr(self.model, column_name) == value).first()
            return v

    def get_all_by_filters(self, **filters: Any) -> List[EntityType]:
        """
        ì—¬ëŸ¬ ì»¬ëŸ¼ ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ì¡°ê±´ì— ë§ëŠ” ëª¨ë“  ë ˆì½”ë“œë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.

        Args:
            **filters: ì»¬ëŸ¼ëª…=ê°’ í˜•íƒœì˜ í‚¤ì›Œë“œ ì¸ìë“¤

        Example:
            # base_dtì™€ marketì´ ëª¨ë‘ ì¼ì¹˜í•˜ëŠ” ë ˆì½”ë“œë“¤ì„ ê°€ì ¸ì˜´
            results = repo.get_all_by_filters(base_dt="2025-06-02", market="KOSPI")
            ..
            for row in results:
                print(row.ticker, row.name, row.keywords)

        Returns:
            List[EntityType]: ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ëª¨ë“  ë ˆì½”ë“œ ë¦¬ìŠ¤íŠ¸
        """
        with self.session_scope() as session:
            query = session.query(self.model)
            for column, value in filters.items():
                query = query.filter(getattr(self.model, column) == value)
            return query.all()

    def get_all(self) -> List[Any]:
        """
        ì „ì²´ ë ˆì½”ë“œë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
        """
        with self.session_scope() as session:
            return session.query(self.model).all()

    def add(self, entity: Any) -> None:
        """
        í•˜ë‚˜ì˜ ì—”í‹°í‹°ë¥¼ DBì— ì¶”ê°€í•©ë‹ˆë‹¤.
        """
        with self.session_scope() as session:
            session.add(entity)

    def update(self, entity: Any) -> None:
        """
        ì—”í‹°í‹°ë¥¼ ë³‘í•©(ì—…ë°ì´íŠ¸)í•©ë‹ˆë‹¤.
        """
        with self.session_scope() as session:
            session.merge(entity)

    def delete(self, entity: Any) -> None:
        """
        ì—”í‹°í‹°ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.
        """
        with self.session_scope() as session:
            session.delete(entity)

    def execute_raw_query(self, query: str) -> Any:
        """
        Raw SQL ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
        """
        with self.session_scope() as session:
            return session.execute(text(query)).fetchall()

    def close(self) -> None:
        """
        ì„¸ì…˜ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.
        """
        with self.session_scope() as session:
            session.close()

    def _get_in_chunks(self, chunk_size: int = 1000) -> Generator[List[Any], None, None]:
        """
        ë°ì´í„° ì „ì²´ë¥¼ chunk_size ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ ê°€ì ¸ì˜µë‹ˆë‹¤.
        ì§„í–‰ ìƒí™©ì„ tqdmìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.
        """
        with self.session_scope() as session:
            total = session.query(self.model).count()
            for offset in tqdm(range(0, total, chunk_size), total=(total // chunk_size) + 1, desc="Fetching in chunks"):
                chunk = (
                    session.query(self.model)
                    .offset(offset)
                    .limit(chunk_size)
                    .all()
                )
                yield chunk  # ì œë„ˆë ˆì´í„°ë¡œ ë°˜í™˜ (í•„ìš”í•  ë•Œë§Œ ë©”ëª¨ë¦¬ì— ë¡œë“œ)

    def get_all_in_chunks(self, chunk_size: int = 1000) -> List[Any]:
        """
        ì „ì²´ ë°ì´í„°ë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ê°€ì ¸ì™€ì„œ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ í•©ì¹©ë‹ˆë‹¤.
        (ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì»¤ì§ˆ ìˆ˜ ìˆìŒ)
        """
        results = []
        for chunk in self._get_in_chunks(chunk_size):
            results.extend(chunk)
        return results

    def serial_upsert_entities(self, entities: List[EntityType]) -> None:
        """
        ì—¬ëŸ¬ê°œì˜ ì—”í‹°í‹°ë¥¼ í•œ ë²ˆì— ì¶”ê°€ ë˜ëŠ” ê°±ì‹ í•©ë‹ˆë‹¤.

        Args:
            entities (List[EntityType]): ì¶”ê°€ ë˜ëŠ” ì—…ë°ì´íŠ¸í•  ETF OHLCV ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        if not entities:
            self.logger.info("[add_list] ì…ë ¥ëœ ë°ì´í„°ê°€ ë¹„ì–´ìˆì–´ ì²˜ë¦¬ë¥¼ ìƒëµí•©ë‹ˆë‹¤.")
            return

        try:
            with self.session_scope() as session:
                for entity in tqdm(entities, desc="Serial upserting entities", unit="entity"):
                    try:
                        self.update(entity)
                    except Exception as inner_e:
                        self.logger.warning(f"[add_list] ë‹¨ì¼ ì—”í‹°í‹° ì²˜ë¦¬ ì‹¤íŒ¨: {entity} - {inner_e}", exc_info=True)
                session.commit()

        except Exception as e:
            self.logger.exception(f"[add_list] ì „ì²´ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ {e}")
            raise

    def _entity_to_mapping(self, entity: EntityType) -> Dict[str, Any]:
        """
        SQLAlchemy ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ DB insert/updateìš© dict í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

        - SQLAlchemy ëª¨ë¸ì˜ ì»¬ëŸ¼ ì´ë¦„ì„ keyë¡œ ì‚¬ìš©
        - ê° ì»¬ëŸ¼ì˜ ê°’ì„ entityì—ì„œ êº¼ë‚´ dictì— ë‹´ìŒ
        - NaN(float), NaT(datetime) ë“± Pandasì—ì„œ ì˜¤ëŠ” ê²°ì¸¡ê°’ì€ Noneìœ¼ë¡œ ë³€í™˜

        Args:
            entity (EntityType): SQLAlchemy ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤

        Returns:
            Dict[str, EntityType]: {"ì»¬ëŸ¼ëª…": ê°’} í˜•íƒœì˜ dict
        """
        mapping: Dict[str, EntityType] = {}

        # ëª¨ë¸ì´ ê°€ì§„ ëª¨ë“  ì»¬ëŸ¼ ë°˜ë³µ
        for column in self.model.__table__.columns:
            column_name: str = column.name

            # entityì—ì„œ í•´ë‹¹ ì»¬ëŸ¼ ê°’ ê°€ì ¸ì˜¤ê¸°
            value: EntityType = getattr(entity, column_name)

            # Pandas NaN, NaT ê°™ì€ ê²°ì¸¡ì¹˜ëŠ” Noneìœ¼ë¡œ ì¹˜í™˜
            if pd.isna(value):
                value = None

            # dictì— ì €ì¥
            mapping[column_name] = value

        return mapping

    def _chunk_entities(
        self,
        entities: List[EntityType],
        chunk_size: int
    ) -> Generator[List[EntityType], None, None]:
        """
        ì—”í‹°í‹° ë¦¬ìŠ¤íŠ¸ë¥¼ chunk_size ë‹¨ìœ„ë¡œ ì˜ë¼ ì œë„ˆë ˆì´í„°ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        for i in range(0, len(entities), chunk_size):
            yield entities[i:i + chunk_size]

    def _build_upsert_stmt(self, chunk: List[EntityType]):
        """
        ì£¼ì–´ì§„ ì—”í‹°í‹° ì²­í¬ì— ëŒ€í•´ MySQL upsert(insert ... on duplicate key update) êµ¬ë¬¸ ìƒì„±
        """
        mappings = [self._entity_to_mapping(e) for e in chunk]
        stmt = insert(self.model).values(mappings)
        update_cols = {
            c.name: stmt.inserted[c.name]
            for c in self.model.__table__.columns
            if not c.primary_key
        }
        return stmt.on_duplicate_key_update(**update_cols)

    def add_list(self, entities: List[EntityType], chunk_size: int = 2000) -> None:
        """
        ì—”í‹°í‹° ë¦¬ìŠ¤íŠ¸ë¥¼ ì²­í¬ ë‹¨ìœ„ë¡œ ì˜ë¼ ìˆœì°¨ì ìœ¼ë¡œ Bulk Upsert í•©ë‹ˆë‹¤.

        Args:
            entities (List[Any]): ì¶”ê°€/ì—…ë°ì´íŠ¸í•  ì—”í‹°í‹° ë¦¬ìŠ¤íŠ¸
            chunk_size (int): í•œ ë²ˆì— ì²˜ë¦¬í•  ë°ì´í„° í¬ê¸°
        """
        if not entities:
            self.logger.info("[bulk_upsert] ì…ë ¥ëœ ë°ì´í„°ê°€ ë¹„ì–´ìˆì–´ ì²˜ë¦¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return

        total_chunks = math.ceil(len(entities) / chunk_size)

        try:
            with self.session_scope() as session:
                for chunk in tqdm(
                    self._chunk_entities(entities, chunk_size),
                    total=total_chunks,
                    desc="Bulk upserting", unit="chunk"
                ):
                    stmt = self._build_upsert_stmt(chunk)
                    session.execute(stmt)
                session.commit()

                # ğŸ”¹ DB ì €ì¥ ì™„ë£Œ í›„ ìµœì¢… ë¡œê·¸
                self.logger.info(
                    f"[bulk_upsert] DB ì €ì¥ ì™„ë£Œ: ì´ {len(entities):,}ê°œ ì—”í‹°í‹°ë¥¼ "
                    f"{total_chunks:,}ê°œì˜ ì²­í¬ë¡œ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤."
                )

        except SQLAlchemyError:
            self.logger.exception("[bulk_upsert] ì „ì²´ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ", exc_info=True)
            raise


if __name__ == "__main__":
    from mjdb.model.daily_stock_rise_reason_keywords import DailyStockRiseReasonKeywords
    import pandas as pd
    import uuid
    from dotenv import load_dotenv
    load_dotenv()

    db_url = os.getenv("STOCK_DATABASE_LOCALHOST_URL")

    # Repository ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ëª¨ë¸ í´ë˜ìŠ¤ ì£¼ì…)
    session_conf = SessionConfig(expire_on_commit=False)
    context = SessionContext(db_url=db_url, session_config=session_conf)
    repo = BaseSQLAlchemyRepository(DailyStockRiseReasonKeywords, context=context)

    # 1. ë°ì´í„° ì¶”ê°€ (Create)
    ticker = str(uuid.uuid4())[:5]
    new_stock = DailyStockRiseReasonKeywords(
        # base_dt='2025-05-14',  # ì˜ˆì‹œ ë‚ ì§œ
        base_dt=pd.to_datetime("2025-05-14", format="%Y-%m-%d"),
        ticker=ticker,  # ì˜ˆì‹œ ì¢…ëª© ì½”ë“œ
        open=1000,
        high=1050,
        low=950,
        close=1020,
        volume=100000,
        trading_amount=102000000,
        change=2.0,
        market="KOSPI",
        market_cap=5000000000,
        outstanding_shares=100000000,
        name="Example Corp",
        filter_type="Type A",
        industry_kind="Technology",
        main_product="Software",
        industry="Software",
        keywords="growth, innovation, technology"
    )
    # repo.add(new_stock)
    # print("âœ… ì¶”ê°€ ì™„ë£Œ")
    #
    # # 2. ë‹¨ì¼ ì¡°íšŒ (Read by ID)
    # stock = repo.get_by_column(column_name="base_dt", value="2025-05-14")
    # print(f"ğŸ” ID 1 ì¡°íšŒ ê²°ê³¼: {stock}")
    # print(f"ticker: {ticker}")
    #
    # # 3. ì „ì²´ ì¡°íšŒ (Read all)
    # stocks = repo.get_all()
    # print(f"ğŸ“‹ ì „ì²´ ì¢…ëª© ë¦¬ìŠ¤íŠ¸: {stocks}")
    #
    # # 4. ë°ì´í„° ìˆ˜ì • (Update)
    # if stock:
    #     stock.name = "ì¹´ì¹´ì˜¤(ìˆ˜ì •)"
    #     repo.update(stock)
    #     print(f"âœï¸ ìˆ˜ì • ì™„ë£Œ: {stock}")
    #
    # # 5. ì‚­ì œ (Delete)
    # if stock:
    #     repo.delete(stock)
    #     print(f"ğŸ—‘ï¸ ì‚­ì œ ì™„ë£Œ: {stock}")
    #
    # # 6. Raw SQL ì‹¤í–‰
    # results = repo.execute_raw_query("SELECT * FROM daily_stock_rise_reason_keywords limit 50;")
    # print("ğŸ§¾ Raw Query ê²°ê³¼:")
    # for row in results:
    #     print(row)

    repo.add_list([new_stock])