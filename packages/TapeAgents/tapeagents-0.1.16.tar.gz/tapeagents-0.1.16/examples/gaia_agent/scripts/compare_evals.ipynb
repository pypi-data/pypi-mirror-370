{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oleh.shliazhko/TapeAgents/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 165, B: 164\n",
      "Correct tapes in A: 44\n",
      "Correct tapes in B: 47\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from examples.gaia_agent.eval import tape_correct\n",
    "from examples.gaia_agent.tape import GaiaTape\n",
    "from tapeagents.io import load_tapes\n",
    "\n",
    "tapes_a = load_tapes(\n",
    "    GaiaTape, \"../../../outputs/gaia/runs/gpt4o_mini_val_simplebrowser_fromconf1/tapes\", file_extension=\".json\"\n",
    ")\n",
    "tapes_b = load_tapes(\n",
    "    GaiaTape, \"../../../outputs/gaia/runs/gpt4o_mini_val_browsergym_fromconf2/tapes\", file_extension=\".json\"\n",
    ")\n",
    "print(f\"A: {len(tapes_a)}, B: {len(tapes_b)}\")\n",
    "# Count the total number of correct tapes\n",
    "correct_a = sum(1 for tape in tapes_a if tape_correct(tape))\n",
    "correct_b = sum(1 for tape in tapes_b if tape_correct(tape))\n",
    "\n",
    "print(f\"Correct tapes in A: {correct_a}\")\n",
    "print(f\"Correct tapes in B: {correct_b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19 matching tape pairs with different result.\n",
      "Found 36 both correct tape pairs.\n",
      "Found 109 both incorrect tape pairs.\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store paired tapes\n",
    "tape_pairs = {}\n",
    "incorrect_pairs = []\n",
    "correct_pairs = []\n",
    "\n",
    "# Iterate through tapes_a and tapes_b to find matching task_ids\n",
    "for tape_a in tapes_a:\n",
    "    task_id_a = tape_a.metadata.task[\"task_id\"]\n",
    "    for tape_b in tapes_b:\n",
    "        task_id_b = tape_b.metadata.task[\"task_id\"]\n",
    "        if task_id_a == task_id_b:\n",
    "            # Check if one tape is correct and the other is not\n",
    "            if tape_correct(tape_a) != tape_correct(tape_b):\n",
    "                tape_pairs[task_id_a] = {\"tape_a\": tape_a, \"tape_b\": tape_b}\n",
    "            elif tape_correct(tape_a) and tape_correct(tape_b):\n",
    "                correct_pairs.append((tape_a, tape_b))\n",
    "            else:\n",
    "                incorrect_pairs.append((tape_a, tape_b))\n",
    "            break\n",
    "\n",
    "print(f\"Found {len(tape_pairs)} matching tape pairs with different result.\")\n",
    "print(f\"Found {len(correct_pairs)} both correct tape pairs.\")\n",
    "print(f\"Found {len(incorrect_pairs)} both incorrect tape pairs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different pairs, correct tapes in A: 8\n",
      "Different pairs, correct tapes in B: 11\n"
     ]
    }
   ],
   "source": [
    "# Count correct tapes in tape_pairs\n",
    "correct_a = sum(1 for _, pair in tape_pairs.items() if tape_correct(pair[\"tape_a\"]))\n",
    "correct_b = sum(1 for _, pair in tape_pairs.items() if tape_correct(pair[\"tape_b\"]))\n",
    "\n",
    "print(f\"Different pairs, correct tapes in A: {correct_a}\")\n",
    "print(f\"Different pairs, correct tapes in B: {correct_b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tapeagents.core import Observation\n",
    "\n",
    "\n",
    "def render_tape(tape, name):\n",
    "    lines = [f\"Trace {name}\"]\n",
    "    views = []\n",
    "    for i, step in enumerate(tape.steps):\n",
    "        if isinstance(step, Observation):\n",
    "            view = step.short_view()\n",
    "        else:\n",
    "            view = step.llm_view()\n",
    "        views.append(f\"Step {i}. {view}\")\n",
    "    lines.append(\"\\n\".join(views))\n",
    "    lines.append(\"-\" * 20)\n",
    "    lines.append(\"This answer is correct\" if tape_correct(tape) else \"This answer is incorrect!\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def render_task(task_dict):\n",
    "    lines = []\n",
    "    lines.append(f\"Task: {task_dict['Question']}\")\n",
    "    lines.append(f\"Human solution steps:\\n{task_dict['Annotator Metadata']['Steps']}\")\n",
    "    lines.append(f\"Correct Answer: {task_dict['Final answer']}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "rendered_pairs = {}\n",
    "for task_id, pair in tape_pairs.items():\n",
    "    rendered_pairs[task_id] = {\n",
    "        \"task\": render_task(pair[\"tape_a\"].metadata.task),\n",
    "        \"tape_a\": render_tape(pair[\"tape_a\"], \"SimpleB\"),\n",
    "        \"tape_b\": render_tape(pair[\"tape_b\"], \"Browsergym\"),\n",
    "        \"correct\": \"A\" if tape_correct(pair[\"tape_a\"]) else \"B\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tapeagents.llms import LiteLLM\n",
    "\n",
    "key = \"sk-...\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = key\n",
    "llm = LiteLLM(model_name=\"o3-mini-2025-01-31\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "name_a = \"SimpleB\"\n",
    "name_b = \"BrowserGym\"\n",
    "difference = f\"The agent {name_a} uses simple text browser to access the web, while agent {name_b} uses a more advanced browser with additional capabilities.\"\n",
    "focus = \"Pay attention to the differences in the web browsing capabilities of the agents as it is the main focus of the analysis.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [04:25<00:00, 13.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparisons collected. Agent B is better in 11 tasks and worse in 8 tasks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "prompt_prefix = f\"\"\"You are the expert in analysing solutions of the complex information processing tasks. \n",
    "You are given the task description, its solution and the steps used by human to arrive at the solution.\n",
    "You are also given traces of two solutions generated by two different AI agents {name_a} and {name_b}.\n",
    "{difference}\n",
    "Each trace annotated with the correctness of the solution in the end.\n",
    "Your task is to analyse the two traces and the task description and answer the following questions:\n",
    "- Which agent is correct?\n",
    "- Why is the other agent incorrect?\n",
    "- What are the main differences between the correct and incorrect traces?\n",
    "- Which differences can be attributed to the web browsing capabilities of the agents?\n",
    "- Which steps in the incorrect trace marks the beginning of the incorrect reasoning?\n",
    "Base your answers on the traces and the task description only, do not guess or hypothesize anything about the agents thoughts which are not visible in the traces.\n",
    "\"\"\"\n",
    "prompt_postfix = \"\"\"Thoroughly analyze the traces and answer the questions in detail. \n",
    "Do not assume or guess anything about agent decisions, only use the information provided in the traces.\n",
    "Do not not use markdown formatting, answer in plain text.\"\"\"\n",
    "b_better = []\n",
    "b_worse = []\n",
    "for task_id, pair in tqdm(rendered_pairs.items()):\n",
    "    prompt = f\"{prompt_prefix}\\n\\n{pair['task']}\\n\\n{pair['tape_a']}\\n\\n{pair['tape_b']}\\n\\n{prompt_postfix}\"\n",
    "    result = llm.quick_response(prompt)\n",
    "    if pair[\"correct\"] == \"A\":\n",
    "        b_worse.append({\"task_id\": task_id, \"result\": result})\n",
    "    else:\n",
    "        b_better.append({\"task_id\": task_id, \"result\": result})\n",
    "print(f\"Comparisons collected. Agent B is better in {len(b_better)} tasks and worse in {len(b_worse)} tasks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_results = {\n",
    "    \"b_better\": b_better,\n",
    "    \"b_worse\": b_worse,\n",
    "}\n",
    "with open(f\"{name_a}_{name_b}_comparison_results.json\", \"w\") as f:\n",
    "    json.dump(comparison_results, f, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"{name_a}_{name_b}_comparison_results.json\") as f:\n",
    "#     comparison_results = json.load(f)\n",
    "# b_better = comparison_results[\"b_better\"]\n",
    "# b_worse = comparison_results[\"b_worse\"]\n",
    "# print(f\"Agent B is better in {len(b_better)} tasks and worse in {len(b_worse)} tasks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report on BrowserGym Drawbacks and Limitations\n",
      "\n",
      "1. Overview  \n",
      "An analysis of the provided cases reveals that, despite BrowserGym’s advanced web browsing features, its performance is consistently inferior to SimpleB. The evidence across all cases highlights that BrowserGym’s errors stem from misinterpretation of extracted data, deviation from prescribed methods, and unnecessary extra steps. These issues consistently compromise its final answer accuracy.\n",
      "\n",
      "2. Misinterpretation and Incomplete Data Extraction  \n",
      "Multiple cases (a1e91b78, 0ff53813, 544b7f0c) show that BrowserGym does not reliably extract all necessary details. In case a1e91b78, BrowserGym miscounted visible bird species by omitting one detail that SimpleB correctly captured. Similarly, in case 0ff53813, BrowserGym overlooked a critical textual reference in a document and incorrectly generalized “beta geometric” to “predictive model.” In the horror film task (544b7f0c), BrowserGym’s failure to locate the specific reference led to an incorrect movie title. These examples, backed by more than one case, indicate that BrowserGym’s advanced browsing does not translate into better or more accurate data extraction.\n",
      "\n",
      "3. Deviation from Prescribed Procedures  \n",
      "Evidence from cases 4b650a35 and b7f857e4 shows that BrowserGym’s performance suffers when it departs from the given instructions. In case 4b650a35, BrowserGym ignored the critical instruction to respond with “Guava” and instead executed unnecessary searches for subquestions. In case b7f857e4, it combined array elements incorrectly by randomly selecting data, contrary to the established procedure. These deviations indicate that BrowserGym’s additional capabilities lead it to engage in extra computations or searches rather than strictly following the prescribed steps.\n",
      "\n",
      "4. Overcomplicated Browsing Behavior  \n",
      "Cases e8cb5b03 and b7f857e4 illustrate that BrowserGym’s extra navigation and search functionalities can become detrimental. In case e8cb5b03, instead of directly accessing the required archived menu snapshots, BrowserGym went down multiple irrelevant paths and ultimately extracted an incorrect dining option. Similarly, in case b7f857e4, BrowserGym’s advanced navigation allowed it to access more pages but ultimately caused it to generate a wrong URL by misapplying extra browsing functions. In both instances, the enhanced browser features led to unnecessary, distracting extra steps that derailed the correct reasoning process.\n",
      "\n",
      "5. Faulty Logical Progression  \n",
      "Several cases (a1e91b78, the ISBN transposition case 56db2318, da52d699) demonstrate that BrowserGym’s final reasoning steps are where errors crystallize. For example, in the ISBN case, BrowserGym failed to simulate the required swap—even though it accessed the same content as SimpleB—and instead used a different approach which produced unrelated output. In da52d699, improper assumption of word counts early on led to miscalculations in reading time. These examples underscore a pattern: BrowserGym’s initial browsing may be adequate, but its logical processing or synthesis of information is flawed, resulting in errors during the final answer derivation.\n",
      "\n",
      "6. Conclusions  \n",
      "The common pattern across all cases is that BrowserGym’s advanced web browsing capabilities come at the cost of focused and accurate data interpretation. SimpleB, with its straightforward and systematic approach—evident in repeated, targeted page observations and adherence to specified procedures—consistently arrives at the correct answer. In contrast, BrowserGym’s reliance on extensive extra searches, random selections, and deviations from given instructions leads to premature or incorrect conclusions. Though BrowserGym’s advanced features allow it to access a broader set of pages or documents, this advantage dissipates if the information is not integrated correctly into the final reasoning process.\n",
      "\n",
      "Overall, the evidence points to a need for BrowserGym to prioritize disciplined adherence to problem-specific directives and ensure that enhanced browsing features do not spur extraneous, off-track exploration that compromises accuracy.\n"
     ]
    }
   ],
   "source": [
    "prompt_prefix = f\"\"\"You are the expert in indcuctive reasoning and analysis of complex information processing tasks.\n",
    "You are given the cases where two different AI agents {name_a} and {name_b} solved the same task and their solutions were compared by an expert.\n",
    "For all given cases, the agent {name_a} was better than {name_b}.\n",
    "You task is to analyze all provided cases, find the common patterns of {name_b} errors and capabilities.\n",
    "Based on your analysis, write a detailed report about the drawbacks and limitations of the agent {name_b}.\n",
    "{focus}\n",
    "\"\"\"\n",
    "prompt_postfix = \"\"\"Thoroughly analyze the cases and write a detailed report. \n",
    "It should contain practical generalizations and conclusions about the differences between the two agents.\n",
    "Every statement in the report should be supported by the evidence from more than one case.\n",
    "Do not assume or guess anything about agent decisions, only use the information provided in the comparisons.\n",
    "Be consice and do not repeat yourself, limit the report to 600 words, make report structured and easy to read.\n",
    "\"\"\"\n",
    "cases = [f\"Case {case['task_id'].split('-', maxsplit=1)[0]}:\\n{case['result']}\" for case in b_worse]\n",
    "cases_str = \"\\n\\n\".join(cases)\n",
    "prompt = f\"{prompt_prefix}\\n<CASES START>\\n\\n{cases_str}\\n\\n<CASES END>\\n\\n{prompt_postfix}\"\n",
    "b_worse_conclusions = llm.quick_response(prompt)\n",
    "print(b_worse_conclusions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: Comparative Analysis of BrowserGym and SimpleB\n",
      "\n",
      "Overview\n",
      "This report reviews multiple cases where BrowserGym and SimpleB attempted the same tasks, consistently showing BrowserGym’s superiority. The analysis highlights common errors and limitations in SimpleB’s approach, particularly regarding its web browsing and data extraction capabilities.\n",
      "\n",
      "Key Issues with SimpleB\n",
      "\n",
      "1. Data Extraction and Conversion Errors  \n",
      "Across several cases (e1fc63a2, e0c10771, 99c9cc74), SimpleB repeatedly made mistakes while processing data. For example, it incorrectly converted a pace value—treating seconds as minutes—leading to catastrophic numeric errors. Similarly, SimpleB failed to capture full ingredient details by dropping qualifiers (e.g., “freshly squeezed” in a recipe ingredient). These errors are not isolated but reflect a broader limitation in handling nuanced data extraction and transformation correctly.\n",
      "\n",
      "2. Inadequate File Processing and Limited Parsing  \n",
      "In cases like 5cfb274c and de9887f5, SimpleB was unable to process complex file formats. It misinterpreted spreadsheet content as empty or simply could not bypass error messages like “Error 403.” The agent’s reliance on plain text reading, rather than executing code to parse structured documents, led to incomplete or incorrect data outcomes. This pattern of insufficient file handling appears repeatedly where dynamic or coded extraction would have resolved ambiguities.\n",
      "\n",
      "3. Faulty Navigation and Contextual Misinterpretation  \n",
      "SimpleB also displayed limitations in handling web navigation. In case 33d8ea3b, it failed to identify and count navigation link clicks correctly, instead relying on scrolling actions that do not capture actual browsing interactions. Similarly, in case 305ac316 and 23dd907f, SimpleB misidentified critical information (e.g., role names or stanza structures) by not engaging in targeted searches or by misinterpreting the displayed text. This indicates a deficiency in constructing sequential browsing strategies and in interpreting page layout and context effectively.\n",
      "\n",
      "4. Reliance on Predefined Reasoning without Adaptive Tool Integration  \n",
      "SimpleB’s method of reasoning—often purely textual—lacks adaptive code execution. In cases such as b9763138 and de9887f5, while BrowserGym used code to recalculate check digits and reattempt searches after encountering an access error, SimpleB’s static process led to perpetuated inaccuracies. In every instance, inaccurate transformations or missing data were not adjusted by verifying or re-querying the source content, emphasizing a rigid approach to problem-solving.\n",
      "\n",
      "Advantages of BrowserGym\n",
      "\n",
      "1. Advanced Tool Integration and Code Execution  \n",
      "BrowserGym’s ability to execute code (seen in cases e1fc63a2, 5cfb274c, 99c9cc74) allowed it to perform precise unit conversions, extract data from spreadsheets, and accurately parse web pages. Its capacity to dynamically adjust—for example, reattempting queries after encountering errors (de9887f5)—contrasts sharply with SimpleB’s simpler, often static, text-based browsing.\n",
      "\n",
      "2. Targeted and Context-Aware Navigation  \n",
      "BrowserGym consistently employed targeted actions such as direct URL openings, clickable navigation, and integration with external sources like IMDb. This precise navigation ensured that relevant details were extracted correctly (cases 305ac316 and 33d8ea3b) and that the retrieved information aligned closely with the task requirements.\n",
      "\n",
      "Conclusion  \n",
      "The comparative evidence shows that SimpleB’s drawbacks stem largely from its reliance on basic, text-only browsing techniques, which limit its capability to execute code, handle errors, and extract nuanced or structured data. In contrast, BrowserGym’s advanced browser environment provides enhanced contextual interpretation, navigation, and dynamic tool integration, leading to consistently accurate outcomes across diverse tasks. The limitations seen in SimpleB are evident in its misinterpretation of units, data omission, and navigation errors, making it less suitable for tasks requiring precise web data extraction and manipulation.\n"
     ]
    }
   ],
   "source": [
    "prompt_prefix = f\"\"\"You are the expert in indcuctive reasoning and analysis of complex information processing tasks.\n",
    "You are given the cases where two different AI agents {name_a} and {name_b} solved the same task and their solutions were compared by an expert.\n",
    "For all given cases, the agent {name_a} was worse than {name_b}.\n",
    "You task is to analyze all provided cases, find the common patterns of {name_a} errors and capabilities.\n",
    "Based on your analysis, write a detailed report about the drawbacks and limitations of the agent {name_a}.\n",
    "{focus}\n",
    "\"\"\"\n",
    "prompt_postfix = \"\"\"Thoroughly analyze the cases and write a detailed report. \n",
    "It should contain practical generalizations and conclusions about the differences between the two agents.\n",
    "Every statement in the report should be supported by the evidence from more than one case.\n",
    "Do not assume or guess anything about agent decisions, only use the information provided in the comparisons.\n",
    "Be consice and do not repeat yourself, limit the report to 600 words, make report structured and easy to read.\n",
    "\"\"\"\n",
    "cases = [f\"Case {case['task_id'].split('-', maxsplit=1)[0]}:\\n{case['result']}\" for case in b_better]\n",
    "cases_str = \"\\n\\n\".join(cases)\n",
    "prompt = f\"{prompt_prefix}\\n<CASES START>\\n\\n{cases_str}\\n\\n<CASES END>\\n\\n{prompt_postfix}\"\n",
    "b_better_conclusions = llm.quick_response(prompt)\n",
    "print(b_better_conclusions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled mix contains 19 comparisons\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Create a shuffled list with both b_better and b_worse results\n",
    "b_all_shuffled = b_worse + b_better\n",
    "random.shuffle(b_all_shuffled)\n",
    "print(f\"Shuffled mix contains {len(b_all_shuffled)} comparisons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: Analysis of Differences in Web Browsing and Information Extraction Between SimpleB and BrowserGym\n",
      "\n",
      "1. Overview  \n",
      "The comparison of multiple cases reveals systematic differences in how the two agents navigate documents, execute code, and extract details from web sources. Both agents start with similar search steps; however, the manner in which they process content and follow prescribed procedures leads to clear differences in final outcomes.\n",
      "\n",
      "2. Navigation and Data Extraction  \n",
      "• SimpleB typically follows a straightforward, step‐by‐step navigation strategy. In cases such as 544b7f0c and 0ff53813, its repeated page_down and page_observation actions allowed it to extract the precise textual details (e.g., “A Nightmare on Elm Street” or “beta geometric”) required for the task. This method consistently led to correct answers when the task depended on careful scrolling and repeated reading of document pages.  \n",
      "• In contrast, BrowserGym often leverages an advanced browser to perform multiple search queries, clicking through results and even attempting code execution. While this capability can be advantageous (as seen in cases 5cfb274c and e1fc63a2), it sometimes results in extraneous steps that lead to misinterpretation of the content. For example, in tasks requiring precise extraction of specific language or step‐by‐step validation (cases 544b7f0c and 23dd907f), advanced browsing features were not sufficient to overcome misinterpretation or distraction from irrelevant data.\n",
      "\n",
      "3. Code Execution and Unit Conversion  \n",
      "• BrowserGym’s stronger ability to execute Python code or follow scripted actions notably benefits tasks where numerical calculations or data parsing are required. In case 5cfb274c, its Python code action correctly processed spreadsheet data, while SimpleB’s reliance on a simple text view caused it to incorrectly conclude missing information. Similarly, in case e1fc63a2, BrowserGym accurately computed pace conversion whereas SimpleB erred by misinterpreting the conversion formula.  \n",
      "• However, BrowserGym’s advanced processing sometimes leads to overcomplication. For instance, in case b7f857e4, BrowserGym’s deviation from the prescribed URL-generation method—using a random element selection instead—resulted in an incorrect outcome.\n",
      "\n",
      "4. Procedural Adherence and Result Interpretation  \n",
      "• SimpleB generally adheres more closely to the task’s prescribed procedures. This is evident in cases such as 4b650a35 and 56db2318 where it directly implements the required steps (e.g., returning “Guava” or simulating the adjacent-column swap) and thereby avoids overcomplication.  \n",
      "• BrowserGym’s advanced capabilities, while potentially expansive, sometimes lead it to perform additional searches or extra actions (e.g., multiple archived page lookups in case e8cb5b03) that divert it from the core requirement. Its additional steps occasionally dilute focus, as seen by misinterpreting linked navigation (case 33d8ea3b) or miscounting information when the action requires a simple chain of clicks (case a1e91b78).\n",
      "\n",
      "5. General Conclusions  \n",
      "• Simplicity vs. Complexity: The evidence shows that when tasks require faithful reproduction of specific document features or adherence to a rigid procedure, SimpleB’s simple text-based browsing and systematic scanning often yield correct results.  \n",
      "• Advanced Tools have Limitations: Even with advanced browser functions and code execution, BrowserGym’s additional capabilities do not always guarantee correct data extraction or interpretation. In several cases, the extra functionality led to diverging from the prescribed process, resulting in errors.\n",
      "• Context-Specific Strengths: BrowserGym performs best when tasks benefit from automated code processing or require dynamic page interaction. SimpleB excels in tasks where a systematic, sequential document navigation strategy must be followed.\n",
      "\n",
      "This analysis concludes that, while each agent has strengths based on its web browsing capability, effective problem-solving hinges on aligning those capabilities with the task requirements. Consistent and focused execution—demonstrated by SimpleB in many cases—often trumps advanced but overcomplicated approaches observed in BrowserGym.\n"
     ]
    }
   ],
   "source": [
    "prompt_prefix = f\"\"\"You are the expert in indcuctive reasoning and analysis of complex information processing tasks.\n",
    "You are given the cases where two different AI agents {name_a} and {name_b} solved the same task and their solutions were compared by an expert.\n",
    "In some cases, the agent {name_a} was worse than {name_b}, in some cases it was better.\n",
    "You task is to analyze all provided cases, find the common patterns of agent errors and capabilities.\n",
    "Based on your analysis, write a detailed report about the differences between the two agents.\n",
    "{focus}\n",
    "\"\"\"\n",
    "prompt_postfix = \"\"\"Thoroughly analyze the cases and write a detailed report. \n",
    "It should contain practical generalizations and conclusions about the differences between the two agents.\n",
    "Every statement in the report should be supported by the evidence from more than one case.\n",
    "Do not assume or guess anything about agent decisions, only use the information provided in the comparisons.\n",
    "Be consice and do not repeat yourself, limit the report to 600 words, make report structured and easy to read.\n",
    "\"\"\"\n",
    "cases = [f\"Case {case['task_id'].split('-', maxsplit=1)[0]}:\\n{case['result']}\" for case in b_all_shuffled]\n",
    "cases_str = \"\\n\\n\".join(cases)\n",
    "prompt = f\"{prompt_prefix}\\n<CASES START>\\n\\n{cases_str}\\n\\n<CASES END>\\n\\n{prompt_postfix}\"\n",
    "b_all_conclusions = llm.quick_response(prompt)\n",
    "print(b_all_conclusions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conclusions = {\n",
    "    \"b_better\": b_better_conclusions,\n",
    "    \"b_worse\": b_worse_conclusions,\n",
    "    \"all\": b_all_conclusions,\n",
    "}\n",
    "with open(f\"{name_a}_{name_b}_conclusions.json\", \"w\") as f:\n",
    "    json.dump(conclusions, f, indent=2, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
