Metadata-Version: 2.4
Name: swarmcode
Version: 0.1.1
Summary: Open-source AI coding assistant powered by Cerebras - fast inference for Llama 3.3 70B and Qwen3 Coder 480B
Project-URL: Homepage, https://github.com/rinadelph/swarmcode
Project-URL: Repository, https://github.com/rinadelph/swarmcode.git
Project-URL: Documentation, https://github.com/rinadelph/swarmcode#readme
Project-URL: Bug Tracker, https://github.com/rinadelph/swarmcode/issues
Project-URL: Changelog, https://github.com/rinadelph/swarmcode/releases
Author: Michael Pfaffenberger
Author-email: Luis Alejandro Rincon <alejandro@rinconnect.org>
Maintainer-email: Luis Alejandro Rincon <alejandro@rinconnect.org>
License: MIT
License-File: LICENSE
Keywords: ai,assistant,cerebras,code-generation,coding,development-tools,llama,qwen
Classifier: Development Status :: 4 - Beta
Classifier: Environment :: Console
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Natural Language :: English
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development :: Code Generators
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: >=3.10
Requires-Dist: bs4>=0.0.2
Requires-Dist: httpx-limiter>=0.3.0
Requires-Dist: httpx>=0.24.1
Requires-Dist: json-repair>=0.46.2
Requires-Dist: logfire>=0.7.1
Requires-Dist: pathspec>=0.11.0
Requires-Dist: prompt-toolkit>=3.0.38
Requires-Dist: pydantic-ai>=0.4.8
Requires-Dist: pydantic>=2.4.0
Requires-Dist: pytest-cov>=6.1.1
Requires-Dist: python-dotenv>=1.0.0
Requires-Dist: rapidfuzz>=3.13.0
Requires-Dist: rich>=13.4.2
Requires-Dist: ruff>=0.11.11
Requires-Dist: tree-sitter-language-pack>=0.8.0
Requires-Dist: tree-sitter-typescript>=0.23.2
Provides-Extra: dev
Requires-Dist: pytest-asyncio>=0.23.1; extra == 'dev'
Requires-Dist: pytest-cov>=6.1.1; extra == 'dev'
Requires-Dist: pytest>=8.3.4; extra == 'dev'
Requires-Dist: ruff>=0.11.11; extra == 'dev'
Provides-Extra: embeddings
Requires-Dist: numpy>=1.24.0; extra == 'embeddings'
Requires-Dist: qdrant-client>=1.7.0; extra == 'embeddings'
Requires-Dist: torch>=2.0.0; extra == 'embeddings'
Requires-Dist: transformers>=4.36.0; extra == 'embeddings'
Requires-Dist: watchdog>=3.0.0; extra == 'embeddings'
Description-Content-Type: text/markdown

# üöÄ SwarmCode üöÄ

*The open-source AI coding assistant that actually works with Cerebras and other providers*

![Build Status](https://img.shields.io/badge/build-passing-brightgreen)
![Coverage](https://img.shields.io/badge/coverage-95%25-brightgreen)
![Python](https://img.shields.io/badge/python-3.10%2B-blue)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

*"Who needs expensive AI IDEs when you have SwarmCode?"* 

## Overview

SwarmCode is a powerful AI-powered code generation agent that works with **Cerebras**, OpenAI, Gemini, and other providers. Built as a response to expensive proprietary tools, SwarmCode gives you complete control over your AI coding assistant.

## ‚ú® Features

- **üß† Cerebras Integration**: Fast inference with Cerebras models (Llama 3.3 70B, Qwen3 Coder 480B)
- **üåê Multi-Provider Support**: Works with OpenAI, Gemini, Anthropic, Together AI, and custom endpoints
- **üíª Interactive CLI**: Beautiful command-line interface with rich formatting
- **üìö RAG Support**: Built-in embeddings and vector search for context-aware coding
- **üîß MCP Server Support**: Extensible with Model Context Protocol servers
- **üö´ No Vendor Lock-in**: Use any model provider you want

## üé¨ Demo

![SwarmCode Demo](code_puppy.gif)

## üöÄ Quick Start

### Option 1: One-Line Install (Recommended) üéØ

```bash
curl -sSL https://raw.githubusercontent.com/rinadelph/swarmcode/main/install.sh | bash
```

That's it! The installer will:
- ‚úÖ Check your Python version
- ‚úÖ Install SwarmCode and all dependencies
- ‚úÖ Prompt for your Cerebras API key
- ‚úÖ Configure your preferred model
- ‚úÖ Set up the `swm` command globally

### Option 2: Install from PyPI (Coming Soon)

```bash
pip install swarmcode
swm --interactive
```

### Option 3: Install from Source

```bash
# Clone and install
git clone https://github.com/rinadelph/swarmcode.git
cd swarmcode
python3 install.py

# Start coding!
swm --interactive
```

## üìã Requirements

- **Python 3.10+**
- **API Keys** (at least one):
  - Cerebras API key (recommended) - [Get it here](https://cerebras.ai)
  - OpenAI API key
  - Gemini API key
  - Anthropic API key
  - Or any custom endpoint

## üéØ Usage Examples

### Interactive Mode
```bash
# Start interactive session with Cerebras
swarmcode --interactive

# Or use a specific model
export MODEL_NAME=Cerebras-Qwen3-Coder-480b
swarmcode --interactive
```

### Direct Task Execution
```bash
# Execute a task directly
swarmcode "write a Python FastAPI server with user authentication"

# Generate and run code
swarmcode "create a React component for a todo list and set up the project"
```

### Using Different Providers

#### Cerebras (Recommended)
```bash
export CEREBRAS_API_KEY='your-key'
export MODEL_NAME='Cerebras-Llama-3.3-70b'
swarmcode --interactive
```

#### OpenAI
```bash
export OPENAI_API_KEY='your-key'
export MODEL_NAME='gpt-4.1'
swarmcode --interactive
```

#### Gemini
```bash
export GEMINI_API_KEY='your-key'
export MODEL_NAME='gemini-2.5-flash-preview-05-20'
swarmcode --interactive
```

#### Custom Endpoints
```bash
export MODEL_NAME='my-custom-model'
export MODELS_JSON_PATH='/path/to/custom/models.json'
swarmcode --interactive
```

## üîß Configuration

### Environment Variables
Create a `.env` file in your project root:

```bash
# Primary configuration
MODEL_NAME=Cerebras-Llama-3.3-70b
CEREBRAS_API_KEY=your_cerebras_api_key

# Optional providers
OPENAI_API_KEY=your_openai_key
GEMINI_API_KEY=your_gemini_key
ANTHROPIC_API_KEY=your_anthropic_key

# Behavior
YOLO_MODE=true  # Skip confirmation prompts for commands
```

### Available Cerebras Models
- `Cerebras-Llama-3.3-70b` - Fast, general purpose (default)
- `Cerebras-Qwen3-Coder-480b` - Specialized for coding
- `Cerebras-Qwen3-235b-a22b-instruct-2507` - Large instruction model
- `Cerebras-gpt-oss-120b` - Open source GPT variant

See `cerebras_models.json` for full list.

## üõ†Ô∏è Advanced Features

### RAG (Retrieval Augmented Generation)
SwarmCode includes built-in RAG support for better context awareness:

```bash
# Index your codebase
python index_code_puppy.py

# Use with embeddings
swarmcode --interactive --use-rag
```

### MCP Server Integration
Connect to external tools and services:

## Puppy Rules
Puppy rules allow you to define and enforce coding standards and styles that your code should comply with. These rules can cover various aspects such as formatting, naming conventions, and even design guidelines.

### Example of a Puppy Rule
For instance, if you want to ensure that your application follows a specific design guideline, like using a dark mode theme with teal accents, you can define a puppy rule like this:

```plaintext
# Puppy Rule: Dark Mode with Teal Accents

  - theme: dark
  - accent-color: teal
  - background-color: #121212
  - text-color: #e0e0e0

Ensure that all components follow these color schemes to promote consistency in design.
```

## Using MCP Servers for External Tools

Code Puppy supports **MCP (Model Context Protocol) servers** to give you access to external code tools and advanced features like code search, documentation lookups, and more‚Äîincluding Context7 (https://context7.com/) integration for deep docs and search!

### What is an MCP Server?
An MCP server is a standalone process (can be local or remote) that offers specialized functionality (plugins, doc search, code analysis, etc.). Code Puppy can connect to one or more MCP servers at startup, unlocking these extra commands inside your coding agent.

### Configuration
Create a config file at `~/.code_puppy/mcp_servers.json`. Here‚Äôs an example that connects to a local Context7 MCP server:

```json
{
  "mcp_servers": {
     "context7": { 
        "url": "https://mcp.context7.com/sse"
     }
  }
}
```

You can list multiple objects (one per server).

### How to Use
- Drop the config file in `~/.code_puppy/mcp_servers.json`.
- Start your MCP (like context7, or anything compatible).
- Run Code Puppy as usual. It‚Äôll discover and use all configured MCP servers.

#### Example usage
```bash
code-puppy --interactive
# Then ask: Use context7 to look up FastAPI docs!
```

That‚Äôs it!
If you need to run more exotic setups or connect to remote MCPs, just update your `mcp_servers.json` accordingly.

**NOTE:** Want to add your own server or tool? Just follow the config pattern above‚Äîno code changes needed!

---

## Conclusion
By using Code Puppy, you can maintain code quality and adhere to design guidelines with ease.
