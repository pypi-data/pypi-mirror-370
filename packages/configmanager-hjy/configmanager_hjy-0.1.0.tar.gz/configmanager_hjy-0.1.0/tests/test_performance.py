#!/usr/bin/env python3
"""
æ€§èƒ½æµ‹è¯•
"""

import time
import pytest
import threading
from configmanager_hjy.cache import CacheManager, CacheStrategy
from configmanager_hjy.validators import SchemaValidator, TypeValidator, ValueValidator


class TestCachePerformance:
    """ç¼“å­˜æ€§èƒ½æµ‹è¯•ç±»"""
    
    @pytest.fixture
    def cache_manager(self):
        """ç¼“å­˜ç®¡ç†å™¨å®ä¾‹"""
        redis_config = {
            'host': 'localhost',
            'port': 6379,
            'db': 0,
            'decode_responses': True
        }
        
        memory_config = {
            'max_size': 10000,
            'default_ttl': 300
        }
        
        return CacheManager(
            redis_config=redis_config,
            memory_config=memory_config,
            strategy=CacheStrategy.MEMORY_ONLY
        )
    
    def test_set_performance(self, cache_manager):
        """æµ‹è¯•è®¾ç½®æ€§èƒ½"""
        print("\nğŸ§ª æµ‹è¯•ç¼“å­˜è®¾ç½®æ€§èƒ½...")
        
        # æµ‹è¯•å•æ¬¡è®¾ç½®æ€§èƒ½
        start_time = time.time()
        cache_manager.set("test_key", "test_value")
        end_time = time.time()
        
        single_set_time = (end_time - start_time) * 1000  # æ¯«ç§’
        print(f"  å•æ¬¡è®¾ç½®è€—æ—¶: {single_set_time:.3f}ms")
        
        # æµ‹è¯•æ‰¹é‡è®¾ç½®æ€§èƒ½
        batch_size = 1000
        start_time = time.time()
        
        for i in range(batch_size):
            cache_manager.set(f"key_{i}", f"value_{i}")
        
        end_time = time.time()
        batch_time = (end_time - start_time) * 1000
        ops_per_second = batch_size / (batch_time / 1000)
        
        print(f"  æ‰¹é‡è®¾ç½® {batch_size} é¡¹è€—æ—¶: {batch_time:.3f}ms")
        print(f"  è®¾ç½®æ€§èƒ½: {ops_per_second:.0f} ops/s")
        
        # æ€§èƒ½è¦æ±‚ï¼šå•æ¬¡è®¾ç½® < 1msï¼Œæ‰¹é‡è®¾ç½® > 1000 ops/s
        assert single_set_time < 1.0, f"å•æ¬¡è®¾ç½®æ€§èƒ½ä¸è¾¾æ ‡: {single_set_time:.3f}ms"
        assert ops_per_second > 1000, f"æ‰¹é‡è®¾ç½®æ€§èƒ½ä¸è¾¾æ ‡: {ops_per_second:.0f} ops/s"
    
    def test_get_performance(self, cache_manager):
        """æµ‹è¯•è·å–æ€§èƒ½"""
        print("\nğŸ§ª æµ‹è¯•ç¼“å­˜è·å–æ€§èƒ½...")
        
        # é¢„å…ˆè®¾ç½®ä¸€äº›æ•°æ®
        for i in range(1000):
            cache_manager.set(f"key_{i}", f"value_{i}")
        
        # æµ‹è¯•å•æ¬¡è·å–æ€§èƒ½
        start_time = time.time()
        value = cache_manager.get("key_0")
        end_time = time.time()
        
        single_get_time = (end_time - start_time) * 1000
        print(f"  å•æ¬¡è·å–è€—æ—¶: {single_get_time:.3f}ms")
        
        # æµ‹è¯•æ‰¹é‡è·å–æ€§èƒ½
        batch_size = 1000
        start_time = time.time()
        
        for i in range(batch_size):
            cache_manager.get(f"key_{i % 1000}")
        
        end_time = time.time()
        batch_time = (end_time - start_time) * 1000
        ops_per_second = batch_size / (batch_time / 1000)
        
        print(f"  æ‰¹é‡è·å– {batch_size} é¡¹è€—æ—¶: {batch_time:.3f}ms")
        print(f"  è·å–æ€§èƒ½: {ops_per_second:.0f} ops/s")
        
        # æ€§èƒ½è¦æ±‚ï¼šå•æ¬¡è·å– < 0.1msï¼Œæ‰¹é‡è·å– > 10000 ops/s
        assert single_get_time < 0.1, f"å•æ¬¡è·å–æ€§èƒ½ä¸è¾¾æ ‡: {single_get_time:.3f}ms"
        assert ops_per_second > 10000, f"æ‰¹é‡è·å–æ€§èƒ½ä¸è¾¾æ ‡: {ops_per_second:.0f} ops/s"
    
    def test_concurrent_performance(self, cache_manager):
        """æµ‹è¯•å¹¶å‘æ€§èƒ½"""
        print("\nğŸ§ª æµ‹è¯•å¹¶å‘æ€§èƒ½...")
        
        def worker(thread_id, operations):
            """å·¥ä½œçº¿ç¨‹"""
            for i in range(operations):
                key = f"thread_{thread_id}_key_{i}"
                value = f"thread_{thread_id}_value_{i}"
                
                # è®¾ç½®ç¼“å­˜
                cache_manager.set(key, value, ttl=10)
                
                # è·å–ç¼“å­˜
                retrieved = cache_manager.get(key)
                
                # éªŒè¯æ•°æ®ä¸€è‡´æ€§
                if retrieved != value:
                    raise ValueError(f"æ•°æ®ä¸ä¸€è‡´: {retrieved} != {value}")
        
        # å¹¶å‘æµ‹è¯•å‚æ•°
        num_threads = 10
        operations_per_thread = 100
        
        start_time = time.time()
        
        # åˆ›å»ºå¹¶å¯åŠ¨çº¿ç¨‹
        threads = []
        for i in range(num_threads):
            thread = threading.Thread(
                target=worker, 
                args=(i, operations_per_thread)
            )
            threads.append(thread)
            thread.start()
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()
        
        end_time = time.time()
        
        total_time = (end_time - start_time) * 1000
        total_operations = num_threads * operations_per_thread * 2  # è®¾ç½® + è·å–
        ops_per_second = total_operations / (total_time / 1000)
        
        print(f"  å¹¶å‘çº¿ç¨‹æ•°: {num_threads}")
        print(f"  æ¯çº¿ç¨‹æ“ä½œæ•°: {operations_per_thread}")
        print(f"  æ€»æ“ä½œæ•°: {total_operations}")
        print(f"  æ€»è€—æ—¶: {total_time:.3f}ms")
        print(f"  å¹¶å‘æ€§èƒ½: {ops_per_second:.0f} ops/s")
        
        # æ€§èƒ½è¦æ±‚ï¼šå¹¶å‘æ€§èƒ½ > 5000 ops/s
        assert ops_per_second > 5000, f"å¹¶å‘æ€§èƒ½ä¸è¾¾æ ‡: {ops_per_second:.0f} ops/s"
    
    def test_memory_usage(self, cache_manager):
        """æµ‹è¯•å†…å­˜ä½¿ç”¨"""
        print("\nğŸ§ª æµ‹è¯•å†…å­˜ä½¿ç”¨...")
        
        import psutil
        import os
        
        # è·å–åˆå§‹å†…å­˜ä½¿ç”¨
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # æ·»åŠ å¤§é‡æ•°æ®
        for i in range(10000):
            cache_manager.set(f"large_key_{i}", f"large_value_{i}" * 100)  # è¾ƒå¤§çš„å€¼
        
        # è·å–æœ€ç»ˆå†…å­˜ä½¿ç”¨
        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_increase = final_memory - initial_memory
        
        print(f"  åˆå§‹å†…å­˜: {initial_memory:.2f}MB")
        print(f"  æœ€ç»ˆå†…å­˜: {final_memory:.2f}MB")
        print(f"  å†…å­˜å¢é•¿: {memory_increase:.2f}MB")
        
        # è·å–ç¼“å­˜ç»Ÿè®¡
        stats = cache_manager.get_stats()
        cache_size = stats['memory_cache_stats']['total_size_bytes'] / 1024 / 1024  # MB
        
        print(f"  ç¼“å­˜æ•°æ®å¤§å°: {cache_size:.2f}MB")
        print(f"  å†…å­˜æ•ˆç‡: {cache_size/memory_increase*100:.1f}%" if memory_increase > 0 else "å†…å­˜æ•ˆç‡: N/A")
        
        # æ€§èƒ½è¦æ±‚ï¼šå†…å­˜å¢é•¿ < 100MB
        assert memory_increase < 100, f"å†…å­˜ä½¿ç”¨è¿‡é«˜: {memory_increase:.2f}MB"


class TestValidatorPerformance:
    """éªŒè¯å™¨æ€§èƒ½æµ‹è¯•ç±»"""
    
    @pytest.fixture
    def schema_validator(self):
        """SchemaValidatorå®ä¾‹"""
        return SchemaValidator()
    
    @pytest.fixture
    def type_validator(self):
        """TypeValidatorå®ä¾‹"""
        return TypeValidator()
    
    @pytest.fixture
    def value_validator(self):
        """ValueValidatorå®ä¾‹"""
        return ValueValidator()
    
    def test_schema_validation_performance(self, schema_validator):
        """æµ‹è¯•æ¨¡å¼éªŒè¯æ€§èƒ½"""
        print("\nğŸ§ª æµ‹è¯•æ¨¡å¼éªŒè¯æ€§èƒ½...")
        
        # å¤æ‚æ¨¡å¼
        schema = {
            "type": "object",
            "properties": {
                "user": {
                    "type": "object",
                    "properties": {
                        "id": {"type": "integer"},
                        "name": {"type": "string", "minLength": 1},
                        "email": {"type": "string", "format": "email"},
                        "age": {"type": "integer", "minimum": 0, "maximum": 150}
                    },
                    "required": ["id", "name", "email"]
                },
                "settings": {
                    "type": "object",
                    "properties": {
                        "theme": {"type": "string", "enum": ["light", "dark"]},
                        "language": {"type": "string"},
                        "notifications": {"type": "boolean"}
                    }
                }
            }
        }
        
        # æœ‰æ•ˆæ•°æ®
        valid_data = {
            "user": {
                "id": 1,
                "name": "å¼ ä¸‰",
                "email": "zhangsan@example.com",
                "age": 25
            },
            "settings": {
                "theme": "dark",
                "language": "zh-CN",
                "notifications": True
            }
        }
        
        # æµ‹è¯•å•æ¬¡éªŒè¯æ€§èƒ½
        start_time = time.time()
        result = schema_validator.validate(valid_data, schema)
        end_time = time.time()
        
        single_validation_time = (end_time - start_time) * 1000
        print(f"  å•æ¬¡éªŒè¯è€—æ—¶: {single_validation_time:.3f}ms")
        assert result.is_valid is True
        
        # æµ‹è¯•æ‰¹é‡éªŒè¯æ€§èƒ½
        batch_size = 1000
        start_time = time.time()
        
        for i in range(batch_size):
            data = valid_data.copy()
            data["user"]["id"] = i
            result = schema_validator.validate(data, schema)
            assert result.is_valid is True
        
        end_time = time.time()
        batch_time = (end_time - start_time) * 1000
        ops_per_second = batch_size / (batch_time / 1000)
        
        print(f"  æ‰¹é‡éªŒè¯ {batch_size} é¡¹è€—æ—¶: {batch_time:.3f}ms")
        print(f"  éªŒè¯æ€§èƒ½: {ops_per_second:.0f} ops/s")
        
        # æ€§èƒ½è¦æ±‚ï¼šå•æ¬¡éªŒè¯ < 10msï¼Œæ‰¹é‡éªŒè¯ > 100 ops/s
        assert single_validation_time < 10, f"å•æ¬¡éªŒè¯æ€§èƒ½ä¸è¾¾æ ‡: {single_validation_time:.3f}ms"
        assert ops_per_second > 100, f"æ‰¹é‡éªŒè¯æ€§èƒ½ä¸è¾¾æ ‡: {ops_per_second:.0f} ops/s"
    
    def test_type_validation_performance(self, type_validator):
        """æµ‹è¯•ç±»å‹éªŒè¯æ€§èƒ½"""
        print("\nğŸ§ª æµ‹è¯•ç±»å‹éªŒè¯æ€§èƒ½...")
        
        # æµ‹è¯•åŸºæœ¬ç±»å‹éªŒè¯æ€§èƒ½
        test_cases = [
            ("test_string", str),
            (123, int),
            (3.14, float),
            (True, bool),
            ([1, 2, 3], list),
            ({"key": "value"}, dict)
        ]
        
        batch_size = 1000
        start_time = time.time()
        
        for i in range(batch_size):
            for value, expected_type in test_cases:
                result = type_validator.validate(value, expected_type)
                assert result.is_valid is True
        
        end_time = time.time()
        batch_time = (end_time - start_time) * 1000
        total_operations = batch_size * len(test_cases)
        ops_per_second = total_operations / (batch_time / 1000)
        
        print(f"  æ‰¹é‡ç±»å‹éªŒè¯ {total_operations} é¡¹è€—æ—¶: {batch_time:.3f}ms")
        print(f"  ç±»å‹éªŒè¯æ€§èƒ½: {ops_per_second:.0f} ops/s")
        
        # æ€§èƒ½è¦æ±‚ï¼šç±»å‹éªŒè¯ > 1000 ops/s
        assert ops_per_second > 1000, f"ç±»å‹éªŒè¯æ€§èƒ½ä¸è¾¾æ ‡: {ops_per_second:.0f} ops/s"
    
    def test_value_validation_performance(self, value_validator):
        """æµ‹è¯•å€¼éªŒè¯æ€§èƒ½"""
        print("\nğŸ§ª æµ‹è¯•å€¼éªŒè¯æ€§èƒ½...")
        
        # æµ‹è¯•èŒƒå›´éªŒè¯æ€§èƒ½
        batch_size = 1000
        start_time = time.time()
        
        for i in range(batch_size):
            # æ•°å€¼èŒƒå›´éªŒè¯
            result = value_validator.validate_range(i, 0, batch_size)
            assert result.is_valid is True
            
            # å­—ç¬¦ä¸²é•¿åº¦éªŒè¯
            test_string = "test" * (i % 10 + 1)
            result = value_validator.validate_range(test_string, 1, 50)
            assert result.is_valid is True
        
        end_time = time.time()
        batch_time = (end_time - start_time) * 1000
        total_operations = batch_size * 2  # æ•°å€¼ + å­—ç¬¦ä¸²éªŒè¯
        ops_per_second = total_operations / (batch_time / 1000)
        
        print(f"  æ‰¹é‡å€¼éªŒè¯ {total_operations} é¡¹è€—æ—¶: {batch_time:.3f}ms")
        print(f"  å€¼éªŒè¯æ€§èƒ½: {ops_per_second:.0f} ops/s")
        
        # æ€§èƒ½è¦æ±‚ï¼šå€¼éªŒè¯ > 2000 ops/s
        assert ops_per_second > 2000, f"å€¼éªŒè¯æ€§èƒ½ä¸è¾¾æ ‡: {ops_per_second:.0f} ops/s"


class TestIntegrationPerformance:
    """é›†æˆæ€§èƒ½æµ‹è¯•ç±»"""
    
    def test_end_to_end_performance(self):
        """æµ‹è¯•ç«¯åˆ°ç«¯æ€§èƒ½"""
        print("\nğŸ§ª æµ‹è¯•ç«¯åˆ°ç«¯æ€§èƒ½...")
        
        # åˆ›å»ºç¼“å­˜ç®¡ç†å™¨
        redis_config = {
            'host': 'localhost',
            'port': 6379,
            'db': 0,
            'decode_responses': True
        }
        
        memory_config = {
            'max_size': 1000,
            'default_ttl': 300
        }
        
        cache = CacheManager(
            redis_config=redis_config,
            memory_config=memory_config,
            strategy=CacheStrategy.MEMORY_ONLY
        )
        
        # åˆ›å»ºéªŒè¯å™¨
        schema_validator = SchemaValidator()
        type_validator = TypeValidator()
        value_validator = ValueValidator()
        
        # å®šä¹‰éªŒè¯æ¨¡å¼
        schema = {
            "type": "object",
            "properties": {
                "id": {"type": "integer"},
                "name": {"type": "string", "minLength": 1},
                "email": {"type": "string", "format": "email"},
                "age": {"type": "integer", "minimum": 0, "maximum": 150}
            },
            "required": ["id", "name", "email"]
        }
        
        # ç«¯åˆ°ç«¯æµ‹è¯•
        batch_size = 100
        start_time = time.time()
        
        for i in range(batch_size):
            # 1. åˆ›å»ºæ•°æ®
            data = {
                "id": i,
                "name": f"User_{i}",
                "email": f"user{i}@example.com",
                "age": 20 + (i % 50)
            }
            
            # 2. éªŒè¯æ•°æ®
            schema_result = schema_validator.validate(data, schema)
            assert schema_result.is_valid is True
            
            type_result = type_validator.validate(data["id"], int)
            assert type_result.is_valid is True
            
            value_result = value_validator.validate_range(data["age"], 0, 150)
            assert value_result.is_valid is True
            
            # 3. ç¼“å­˜æ•°æ®
            cache.set(f"user_{i}", data, ttl=300)
            
            # 4. è·å–å¹¶éªŒè¯ç¼“å­˜æ•°æ®
            cached_data = cache.get(f"user_{i}")
            assert cached_data == data
        
        end_time = time.time()
        total_time = (end_time - start_time) * 1000
        total_operations = batch_size * 6  # éªŒè¯ + ç¼“å­˜ + è·å–
        ops_per_second = total_operations / (total_time / 1000)
        
        print(f"  ç«¯åˆ°ç«¯æµ‹è¯• {batch_size} é¡¹è€—æ—¶: {total_time:.3f}ms")
        print(f"  æ€»æ“ä½œæ•°: {total_operations}")
        print(f"  ç«¯åˆ°ç«¯æ€§èƒ½: {ops_per_second:.0f} ops/s")
        
        # æ€§èƒ½è¦æ±‚ï¼šç«¯åˆ°ç«¯æ€§èƒ½ > 500 ops/s
        assert ops_per_second > 500, f"ç«¯åˆ°ç«¯æ€§èƒ½ä¸è¾¾æ ‡: {ops_per_second:.0f} ops/s"


if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s"])
