{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b9560b0",
   "metadata": {},
   "source": [
    "# PolicyEngine survey weight calibration guide\n",
    "\n",
    "This notebook demonstrates how to use the two main calibration routines available in PolicyEngine Data:\n",
    "\n",
    "1. **Geographic level iteration**: Calibrating one geographic level at a time from lowest to highest in hierarchy\n",
    "2. **All levels at once**: Stacking datasets at the lowest level and calibrating for all geographic levels simultaneously\n",
    "\n",
    "Both methods adjust household weights to match official statistics (targets) while maintaining data representativeness with a gradient descent algorithm implemented in PolicyEngine's [`microcalibrate`](https://policyengine.github.io/microcalibrate/) package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25555d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from policyengine_data.calibration.calibrate import (\n",
    "    calibrate_single_geography_level,\n",
    "    calibrate_all_levels,\n",
    ")\n",
    "from policyengine_data.calibration.target_rescaling import (\n",
    "    download_database,\n",
    "    rescale_calibration_targets,\n",
    ")\n",
    "from policyengine_data.calibration.target_uprating import (\n",
    "    uprate_calibration_targets,\n",
    ")\n",
    "from policyengine_data.tools.legacy_class_conversions import (\n",
    "    SingleYearDataset_to_Dataset,\n",
    ")\n",
    "from policyengine_data.calibration.target_rescaling import download_database\n",
    "\n",
    "from policyengine_us import Microsimulation\n",
    "from policyengine_us.system import system\n",
    "\n",
    "# Set up logging to see calibration progress\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "calibration_logger = logging.getLogger(\"microcalibrate.calibration\")\n",
    "calibration_logger.setLevel(logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a58bd2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e0dcf3dd8741d7910119daae1dc240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "policy_data.db:   0%|          | 0.00/8.52M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare targets in database\n",
    "\n",
    "# Connect to database storing targets\n",
    "db_uri = download_database(\n",
    "    filename=\"policy_data.db\",\n",
    "    repo_id=\"policyengine/policyengine-us-data\",\n",
    ")\n",
    "\n",
    "# Rescale targets for consistency across geography areas\n",
    "rescaling_results = rescale_calibration_targets(\n",
    "    db_uri=db_uri, update_database=True\n",
    ")\n",
    "\n",
    "# Uprate targets for consistency across definition year (disabled until IRS SOI variables are renamed to avoid errors)\n",
    "# uprating_results = uprate_calibration_targets(\n",
    "#     system=system, db_uri=db_uri, \n",
    "#     from_period=2022, to_period=2023, \n",
    "#     update_database=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e9ace5",
   "metadata": {},
   "source": [
    "## Method 1: geographic level iteration\n",
    "\n",
    "This approach calibrates one geographic level at a time, moving from the lowest (e.g., state) to highest (e.g., national) in the hierarchy. It uses sparsity regularization with an L0 penalty at lower levels to reduce computational costs, then refines weights at higher levels.\n",
    "\n",
    "### Key features:\n",
    "- **Sequential calibration**: From the lowest level to the highest (Eg. in the US, first congressional districts, then states, the national)\n",
    "- **Sparsity regularization**: L0 regularization reduces the number of non-zero weights, then the dataset is minimized to store only the records whose weights are non-zero\n",
    "- **Weight preservation**: Each calibration starts from the previous level's calibrated weights\n",
    "- **Computational efficiency**: Datasets are regularized at each step except for final calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c75954d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Step 1: State level calibration ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reweighting progress: 100%|██████████| 600/600 [00:00<00:00, 1313.85epoch/s, loss=1.23e-15, weights_mean=1.56e+3, weights_std=1.19e+3, weights_min=91.3]\n",
      "Sparse reweighting progress: 100%|██████████| 1200/1200 [00:02<00:00, 414.86epoch/s, loss=0.013, loss_rel_change=-0.988] \n",
      "Reweighting progress: 100%|██████████| 600/600 [00:00<00:00, 1610.73epoch/s, loss=2.12e-15, weights_mean=1.17e+3, weights_std=835, weights_min=43.5]\n",
      "Sparse reweighting progress: 100%|██████████| 1200/1200 [00:03<00:00, 303.38epoch/s, loss=0.0134, loss_rel_change=-0.987]\n",
      "Reweighting progress: 100%|██████████| 600/600 [00:00<00:00, 1388.52epoch/s, loss=6.95e-22, weights_mean=801, weights_std=667, weights_min=47.4]\n",
      "Sparse reweighting progress: 100%|██████████| 1200/1200 [00:02<00:00, 437.60epoch/s, loss=0.013, loss_rel_change=-0.988] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State calibration completed:\n",
      "  - Number of households: 7858\n",
      "  - Non-zero weights: 7858\n",
      "  - Sparsity ratio: 0.00%\n",
      "  - Weight range: [2.13, 21091.89]\n",
      "\n",
      "=== Step 2: National level calibration ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reweighting progress: 100%|██████████| 600/600 [00:00<00:00, 1660.45epoch/s, loss=6.86e-15, weights_mean=1.41e+4, weights_std=7.86e+3, weights_min=7.35]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "National calibration completed:\n",
      "  - Number of households: 7858\n",
      "  - Weight range: [7.35, 87148.02]\n",
      "\n",
      "Total weight change from state to national: 81569136.00\n",
      "Average absolute change per household: 10380.3936\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Calibrate state level with sparsity\n",
    "print(\"=== Step 1: State level calibration ===\")\n",
    "\n",
    "# Use a small subset of states for demonstration\n",
    "demo_state_areas = {\n",
    "    \"California\": \"0400000US06\",\n",
    "    \"Texas\": \"0400000US48\",\n",
    "    \"New York\": \"0400000US36\"\n",
    "}\n",
    "\n",
    "demo_national_areas = {\n",
    "    \"United States\": \"0100000US\"\n",
    "}\n",
    "\n",
    "state_level_calibrated_dataset = calibrate_single_geography_level(\n",
    "    microsimulation_class=Microsimulation,\n",
    "    calibration_areas=demo_state_areas,\n",
    "    dataset=\"hf://policyengine/policyengine-us-data/cps_2023.h5\",\n",
    "    db_uri=db_uri,\n",
    "    dataset_subsample_size=10000,  # Small sample for faster execution\n",
    "    use_dataset_weights=False,  # Start with equal weights\n",
    "    regularize_with_l0=True,  # Enable sparsity\n",
    "    noise_level=10.0\n",
    ")\n",
    "\n",
    "# Examine the results\n",
    "state_weights = state_level_calibrated_dataset.entities[\"household\"][\"household_weight\"].values\n",
    "print(f\"State calibration completed:\")\n",
    "print(f\"  - Number of households: {len(state_weights)}\")\n",
    "print(f\"  - Non-zero weights: {np.count_nonzero(state_weights)}\")\n",
    "print(f\"  - Sparsity ratio: {1 - np.count_nonzero(state_weights)/len(state_weights):.2%}\")\n",
    "print(f\"  - Weight range: [{state_weights.min():.2f}, {state_weights.max():.2f}]\")\n",
    "\n",
    "# Save state-calibrated dataset\n",
    "SingleYearDataset_to_Dataset(\n",
    "    state_level_calibrated_dataset, \n",
    "    output_path=\"Demo_Dataset_state_level.h5\"\n",
    ")\n",
    "\n",
    "# Step 2: Calibrate national level using state-calibrated weights\n",
    "print(\"\\n=== Step 2: National level calibration ===\")\n",
    "\n",
    "national_level_calibrated_dataset = calibrate_single_geography_level(\n",
    "    microsimulation_class=Microsimulation,\n",
    "    calibration_areas=demo_national_areas,\n",
    "    dataset=\"Demo_Dataset_state_level.h5\",  # Use state-calibrated dataset\n",
    "    db_uri=db_uri,\n",
    "    stack_datasets=False,  # Don't stack since we're using pre-stacked data\n",
    "    noise_level=0.0,  # Minimal noise to preserve state calibration\n",
    "    use_dataset_weights=True,  # Start from state-calibrated weights\n",
    "    regularize_with_l0=False  # No sparsity at national level\n",
    ")\n",
    "\n",
    "# Compare results\n",
    "national_weights = national_level_calibrated_dataset.entities[\"household\"][\"household_weight\"].values\n",
    "print(f\"National calibration completed:\")\n",
    "print(f\"  - Number of households: {len(national_weights)}\")\n",
    "print(f\"  - Weight range: [{national_weights.min():.2f}, {national_weights.max():.2f}]\")\n",
    "\n",
    "# Save final dataset\n",
    "SingleYearDataset_to_Dataset(\n",
    "    national_level_calibrated_dataset,\n",
    "    output_path=\"Demo_Dataset_national_level.h5\"\n",
    ")\n",
    "\n",
    "# Verify that calibration changed weights\n",
    "weight_difference = abs(state_weights - national_weights).sum()\n",
    "print(f\"\\nTotal weight change from state to national: {weight_difference:.2f}\")\n",
    "print(f\"Average absolute change per household: {weight_difference/len(state_weights):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6791c130",
   "metadata": {},
   "source": [
    "## Method 2: all levels at once\n",
    "\n",
    "This approach stacks the base dataset for multiple geographic areas at the lowest level and then calibrates said dataset for all levels simultaneously. It provides richer data but requires more computational resources.\n",
    "\n",
    "### Key features:\n",
    "- **Simultaneous calibration**: All geographic levels calibrated together\n",
    "- **Data stacking**: Base dataset replicated for each geographic area at the specified level (most often the lowest level in the geographic hierarchy)\n",
    "- **Data richness**: More observations as the dataset is not regularized until the final calibration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e0cef79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Method 2: All levels at once ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reweighting progress: 100%|██████████| 600/600 [00:06<00:00, 92.14epoch/s, loss=0.219, weights_mean=4.49e+4, weights_std=1.31e+5, weights_min=0.784]\n",
      "Sparse reweighting progress: 100%|██████████| 1200/1200 [00:18<00:00, 64.02epoch/s, loss=0.226, loss_rel_change=-0.778]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full calibration completed:\n",
      "  - Number of households: 1451\n",
      "  - Expected max (before sparsity): 3000\n",
      "  - Non-zero weights: 1451\n",
      "  - Sparsity ratio: 0.00%\n",
      "  - Weight range: [10.81, 2280943.00]\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Method 2: All levels at once ===\")\n",
    "\n",
    "# Use the same subset of states for fair comparison\n",
    "fully_calibrated_dataset = calibrate_all_levels(\n",
    "    microsimulation_class=Microsimulation,\n",
    "    database_stacking_areas=demo_state_areas,\n",
    "    geo_hierarchy=[\"0100000US\", \"0400000US\"],\n",
    "    dataset=\"hf://policyengine/policyengine-us-data/cps_2023.h5\",\n",
    "    db_uri=db_uri,\n",
    "    dataset_subsample_size=1000,  # Sample size per area\n",
    "    regularize_with_l0=True,  # Enable sparsity\n",
    "    noise_level=10.0,\n",
    "    raise_error=False  # Don't fail if some targets have no contributing records\n",
    ")\n",
    "\n",
    "# Examine results\n",
    "full_weights = fully_calibrated_dataset.entities[\"household\"][\"household_weight\"].values\n",
    "print(f\"Full calibration completed:\")\n",
    "print(f\"  - Number of households: {len(full_weights)}\")\n",
    "print(f\"  - Expected max (before sparsity): {1000 * len(demo_state_areas)}\")\n",
    "print(f\"  - Non-zero weights: {np.count_nonzero(full_weights)}\")\n",
    "print(f\"  - Sparsity ratio: {1 - np.count_nonzero(full_weights)/len(full_weights):.2%}\")\n",
    "print(f\"  - Weight range: [{full_weights.min():.2f}, {full_weights.max():.2f}]\")\n",
    "\n",
    "# Save fully calibrated dataset\n",
    "SingleYearDataset_to_Dataset(\n",
    "    fully_calibrated_dataset, \n",
    "    output_path=\"Demo_Dataset_fully_calibrated.h5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1daf7d",
   "metadata": {},
   "source": [
    "## When to use each method\n",
    "\n",
    "### Geographic level iteration (`calibrate_single_geography_level`)\n",
    "\n",
    "**Use when:**\n",
    "- You have limited computational resources\n",
    "- You want fine-grained control over each geographic level\n",
    "- You need to debug calibration issues at specific levels\n",
    "- You have hierarchical targets that should be calibrated sequentially\n",
    "\n",
    "**Key parameters:**\n",
    "- `regularize_with_l0=True`: Enable sparsity at lower levels\n",
    "- `noise_level=0.0`: Minimize changes when refining upper levels\n",
    "- `use_dataset_weights=True`: Preserve previous calibration results\n",
    "- `stack_datasets=False`: Use pre-processed datasets in subsequent steps\n",
    "\n",
    "### All levels at once (`calibrate_all_levels`)\n",
    "\n",
    "**Use when:**\n",
    "- You have sufficient computational resources\n",
    "- You want to optimize across all geographic levels simultaneously\n",
    "- You need maximum data richness for statistical accuracy\n",
    "- Your targets are independent across geographic levels or not present in each of the levels\n",
    "\n",
    "**Key parameters:**\n",
    "- `dataset_subsample_size`: Balance between accuracy and computation time\n",
    "- `regularize_with_l0=True`: Control sparsity in the final result\n",
    "\n",
    "## Best practices\n",
    "\n",
    "1. **Start small**: Use subsamples and limited geographic areas for testing\n",
    "2. **Monitor sparsity**: High sparsity reduces computation but may lose representativeness, explore the `microcalibrate` repo to understand the hyperparameters that affect it and adjust them\n",
    "3. **Validate results**: Check that calibrated weights produce expected target values (`microcalibrate` includes a dashboard that allows close evaluation)\n",
    "4. **Save intermediate results**: Keep state-level datasets for debugging\n",
    "5. **Use appropriate noise levels**: Higher noise helps avoid local minima, but too much distorts results, specially when building on previous calibrations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pe3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
