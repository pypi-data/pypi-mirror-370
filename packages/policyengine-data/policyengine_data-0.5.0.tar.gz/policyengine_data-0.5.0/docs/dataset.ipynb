{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "gq2207gugn",
   "metadata": {},
   "source": [
    "# PolicyEngine Dataset classes\n",
    "\n",
    "This notebook provides documentation for the `SingleYearDataset` and `MultiYearDataset` classes in PolicyEngine Data. These classes are designed to handle structured data for policy analysis and microsimulation.\n",
    "\n",
    "More information on how to integrate with PolicyEngine Core and country-specific data packages will be added as this develops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baee1feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from tables import NaturalNameWarning\n",
    "\n",
    "from policyengine_data.single_year_dataset import SingleYearDataset\n",
    "from policyengine_data.multi_year_dataset import MultiYearDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7832e1ab",
   "metadata": {},
   "source": [
    "## SingleYearDataset\n",
    "\n",
    "The `SingleYearDataset` class is designed to handle data for a single year, organizing it by entities (typically \"person\" and \"household\" in addition to others). Each entity contains a pandas DataFrame with variables relevant to that entity.\n",
    "\n",
    "### Key features:\n",
    "- Stores data for a single time period\n",
    "- Organizes data by entities (person, household, etc.)\n",
    "- All data in a given entity is combined into a single table\n",
    "- Forces data shape validation in the dataset creation process given the table format\n",
    "- Supports basic functionality from the legacy `Dataset` like loading and saving but deprecates multiple data format and loading to the cloud complexity\n",
    "\n",
    "### Creating a SingleYearDataset\n",
    "\n",
    "There are three main ways to create a `SingleYearDataset`:\n",
    "\n",
    "1. **From entity DataFrames**: Create directly from a dictionary of entity DataFrames\n",
    "2. **From HDF5 file**: Load from an existing HDF5 file\n",
    "3. **From simulation**: Create from a PolicyEngine Core microsimulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79636fbd",
   "metadata": {},
   "source": [
    "#### Method 1: From entity DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cf913d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created for year: 2023\n",
      "Available entities: ['person', 'household']\n",
      "Person data shape: (1000, 4)\n",
      "Household data shape: (400, 4)\n"
     ]
    }
   ],
   "source": [
    "# Create sample data for demonstration\n",
    "np.random.seed(42)\n",
    "\n",
    "# Person-level data\n",
    "person_data = pd.DataFrame({\n",
    "    'person_id': range(1000),\n",
    "    'age': np.random.randint(18, 80, 1000),\n",
    "    'income': np.random.normal(50000, 15000, 1000),\n",
    "    'household_id': np.repeat(range(400), [3, 2, 3, 2] * 100)  # Varying household sizes\n",
    "})\n",
    "\n",
    "# Household-level data\n",
    "household_data = pd.DataFrame({\n",
    "    'household_id': range(400),\n",
    "    'household_size': np.random.randint(1, 6, 400),\n",
    "    'housing_cost': np.random.normal(1200, 300, 400),\n",
    "    'state': np.random.choice(['CA', 'TX', 'NY', 'FL'], 400)\n",
    "})\n",
    "\n",
    "# Create entities dictionary\n",
    "entities = {\n",
    "    'person': person_data,\n",
    "    'household': household_data\n",
    "}\n",
    "\n",
    "# Create SingleYearDataset\n",
    "dataset_2023 = SingleYearDataset(\n",
    "    entities=entities,\n",
    "    time_period=2023\n",
    ")\n",
    "\n",
    "print(f\"Dataset created for year: {dataset_2023.time_period}\")\n",
    "print(f\"Available entities: {list(dataset_2023.entities.keys())}\")\n",
    "print(f\"Person data shape: {dataset_2023.entities['person'].shape}\")\n",
    "print(f\"Household data shape: {dataset_2023.entities['household'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cade694",
   "metadata": {},
   "source": [
    "#### Method 2: Loading from HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93f4652e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to sample_dataset_2023.h5\n",
      "Dataset loaded from file for year: 2023\n",
      "Loaded entities: ['household', 'person']\n",
      "Original person data shape: (1000, 4)\n",
      "Loaded person data shape: (1000, 4)\n",
      "Data integrity check: True\n"
     ]
    }
   ],
   "source": [
    "# Save the dataset to an HDF5 file\n",
    "file_path = \"sample_dataset_2023.h5\"\n",
    "dataset_2023.save(file_path)\n",
    "print(f\"Dataset saved to {file_path}\")\n",
    "\n",
    "# Load the dataset from the HDF5 file\n",
    "loaded_dataset = SingleYearDataset(file_path=file_path)\n",
    "print(f\"Dataset loaded from file for year: {loaded_dataset.time_period}\")\n",
    "print(f\"Loaded entities: {list(loaded_dataset.entities.keys())}\")\n",
    "\n",
    "# Verify the data is the same\n",
    "print(f\"Original person data shape: {dataset_2023.entities['person'].shape}\")\n",
    "print(f\"Loaded person data shape: {loaded_dataset.entities['person'].shape}\")\n",
    "print(f\"Data integrity check: {dataset_2023.entities['person'].equals(loaded_dataset.entities['person'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504f33ea",
   "metadata": {},
   "source": [
    "#### Method 3: From a PolicyEngine MicroSimulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f1a90f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created from PolicyEngine US microdata stored in hf://policyengine/policyengine-us-data/cps_2023.h5\n",
      "Dataset created for time period: 2023\n"
     ]
    }
   ],
   "source": [
    "from policyengine_us import Microsimulation\n",
    "\n",
    "start_year = 2023\n",
    "dataset = \"hf://policyengine/policyengine-us-data/cps_2023.h5\"\n",
    "\n",
    "sim = Microsimulation(dataset=dataset)\n",
    "\n",
    "single_year_dataset = SingleYearDataset.from_simulation(sim, time_period=start_year)\n",
    "single_year_dataset.time_period = start_year\n",
    "\n",
    "print(f\"Dataset created from PolicyEngine US microdata stored in {dataset}\")\n",
    "print(f\"Dataset created for time period: {single_year_dataset.time_period}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4c218b",
   "metadata": {},
   "source": [
    "### Main functionalities of SingleYearDataset\n",
    "\n",
    "#### 1. Data access and properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4041f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Person entity columns: ['person_id', 'age', 'income', 'household_id']\n",
      "Household entity columns: ['household_id', 'household_size', 'housing_cost', 'state']\n",
      "\n",
      "Variables by entity:\n",
      "person: ['person_id', 'age', 'income', 'household_id']\n",
      "household: ['household_id', 'household_size', 'housing_cost', 'state']\n",
      "\n",
      "Time period: 2023\n",
      "Data format: arrays\n",
      "Table names: ('person', 'household')\n",
      "Number of tables: 2\n"
     ]
    }
   ],
   "source": [
    "# Access entity data\n",
    "print(\"Person entity columns:\", dataset_2023.entities['person'].columns.tolist())\n",
    "print(\"Household entity columns:\", dataset_2023.entities['household'].columns.tolist())\n",
    "\n",
    "# Get variables by entity\n",
    "print(\"\\nVariables by entity:\")\n",
    "variables = dataset_2023.variables\n",
    "for entity, vars_list in variables.items():\n",
    "    print(f\"{entity}: {vars_list}\")\n",
    "\n",
    "# Access basic properties\n",
    "print(f\"\\nTime period: {dataset_2023.time_period}\")\n",
    "print(f\"Data format: {dataset_2023.data_format}\")\n",
    "print(f\"Table names: {dataset_2023.table_names}\")\n",
    "print(f\"Number of tables: {len(dataset_2023.tables)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c9d669",
   "metadata": {},
   "source": [
    "Note that the data format property will be removed once we fully move away from legacy code that used the old `Dataset` classes as only entity tables as DataFrames will be supported"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aca442",
   "metadata": {},
   "source": [
    "#### 2. Data loading and copying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c09e7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data keys (first 10): ['person_id', 'age', 'income', 'household_id', 'household_size', 'housing_cost', 'state']\n",
      "Sample variable 'age' shape: (1000,)\n",
      "\n",
      "Original dataset time period: 2023\n",
      "Copied dataset time period: 2023\n",
      "Are they the same object? False\n",
      "Do they have the same data? True\n"
     ]
    }
   ],
   "source": [
    "# Load data as a flat dictionary (useful for PolicyEngine Core)\n",
    "loaded_data = dataset_2023.load()\n",
    "print(\"Loaded data keys (first 10):\", list(loaded_data.keys())[:10])\n",
    "print(\"Sample variable 'age' shape:\", loaded_data['age'].shape)\n",
    "\n",
    "# Create a copy of the dataset\n",
    "dataset_copy = dataset_2023.copy()\n",
    "print(f\"\\nOriginal dataset time period: {dataset_2023.time_period}\")\n",
    "print(f\"Copied dataset time period: {dataset_copy.time_period}\")\n",
    "print(f\"Are they the same object? {dataset_2023 is dataset_copy}\")\n",
    "print(f\"Do they have the same data? {dataset_2023.entities['person'].equals(dataset_copy.entities['person'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4edf01f",
   "metadata": {},
   "source": [
    "#### 3. Data validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db42fa38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset validation passed - no NaN values found\n",
      "Validation correctly failed: Column 'income' contains NaN values.\n"
     ]
    }
   ],
   "source": [
    "# Validate the dataset (checks for NaN values)\n",
    "try:\n",
    "    dataset_2023.validate()\n",
    "    print(\"Dataset validation passed - no NaN values found\")\n",
    "except ValueError as e:\n",
    "    print(f\"Validation failed: {e}\")\n",
    "\n",
    "# Create a dataset with NaN values to demonstrate validation\n",
    "invalid_person_data = person_data.copy()\n",
    "invalid_person_data.loc[0, 'income'] = np.nan\n",
    "\n",
    "invalid_entities = {\n",
    "    'person': invalid_person_data,\n",
    "    'household': household_data\n",
    "}\n",
    "\n",
    "invalid_dataset = SingleYearDataset(\n",
    "    entities=invalid_entities,\n",
    "    time_period=2023\n",
    ")\n",
    "\n",
    "# Try to validate the invalid dataset\n",
    "try:\n",
    "    invalid_dataset.validate()\n",
    "    print(\"Invalid dataset validation passed\")\n",
    "except ValueError as e:\n",
    "    print(f\"Validation correctly failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb8cd5c",
   "metadata": {},
   "source": [
    "## MultiYearDataset\n",
    "\n",
    "The `MultiYearDataset` class is designed to handle data across multiple years, containing a collection of `SingleYearDataset` instances. This is useful for storing all the data necessary for multi-year analysis in a single object, rather than having to load and manage multiple `Dataset` objects one per year.\n",
    "\n",
    "### Key features:\n",
    "- Stores multiple `SingleYearDataset` instances indexed by year\n",
    "- Maintains consistency across years for entity structures\n",
    "- Supports copying and data extraction across all years\n",
    "\n",
    "### Creating a MultiYearDataset\n",
    "\n",
    "There are two main ways to create a `MultiYearDataset`:\n",
    "\n",
    "1. **From a list of SingleYearDatasets**: Create from existing SingleYearDataset instances\n",
    "2. **From HDF5 file**: Load from an existing multi-year HDF5 file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dce1010",
   "metadata": {},
   "source": [
    "#### Method 1: From SingleYearDataset list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32967970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-year dataset created with years: [2021, 2022, 2023, 2024]\n",
      "Earliest time period present: 2021\n",
      "Data format: time_period_arrays\n"
     ]
    }
   ],
   "source": [
    "# Create datasets for multiple years\n",
    "datasets_by_year = []\n",
    "\n",
    "for year in [2021, 2022, 2023, 2024]:\n",
    "    # Create slightly different data for each year (e.g., income growth)\n",
    "    year_person_data = person_data.copy()\n",
    "    year_person_data['income'] = year_person_data['income'] * (1.03 ** (year - 2023))  # 3% annual growth\n",
    "    \n",
    "    year_household_data = household_data.copy()\n",
    "    year_household_data['housing_cost'] = year_household_data['housing_cost'] * (1.05 ** (year - 2023))  # 5% annual growth\n",
    "    \n",
    "    year_entities = {\n",
    "        'person': year_person_data,\n",
    "        'household': year_household_data\n",
    "    }\n",
    "    \n",
    "    year_dataset = SingleYearDataset(\n",
    "        entities=year_entities,\n",
    "        time_period=year\n",
    "    )\n",
    "    datasets_by_year.append(year_dataset)\n",
    "\n",
    "# Create MultiYearDataset\n",
    "multi_year_dataset = MultiYearDataset(datasets=datasets_by_year)\n",
    "\n",
    "print(f\"Multi-year dataset created with years: {sorted(multi_year_dataset.datasets.keys())}\")\n",
    "print(f\"Earliest time period present: {multi_year_dataset.time_period}\")\n",
    "print(f\"Data format: {multi_year_dataset.data_format}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82b1b84",
   "metadata": {},
   "source": [
    "#### Method 2: Save and load from HDF5 File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34167c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-year dataset saved to sample_multi_year_dataset.h5\n",
      "Multi-year dataset loaded with years: [2021, 2022, 2023, 2024]\n",
      "Original 2022 average income: $49201.98\n",
      "Loaded 2022 average income: $49201.98\n",
      "Data integrity check: True\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=NaturalNameWarning)\n",
    "\n",
    "# Save the multi-year dataset to an HDF5 file\n",
    "multi_year_file_path = \"sample_multi_year_dataset.h5\"\n",
    "multi_year_dataset.save(multi_year_file_path)\n",
    "print(f\"Multi-year dataset saved to {multi_year_file_path}\")\n",
    "\n",
    "# Load the multi-year dataset from the HDF5 file\n",
    "loaded_multi_year = MultiYearDataset(file_path=multi_year_file_path)\n",
    "print(f\"Multi-year dataset loaded with years: {sorted(loaded_multi_year.datasets.keys())}\")\n",
    "\n",
    "# Verify the data integrity\n",
    "original_2022_income = multi_year_dataset[2022].entities['person']['income'].mean()\n",
    "loaded_2022_income = loaded_multi_year[2022].entities['person']['income'].mean()\n",
    "\n",
    "print(f\"Original 2022 average income: ${original_2022_income:.2f}\")\n",
    "print(f\"Loaded 2022 average income: ${loaded_2022_income:.2f}\")\n",
    "print(f\"Data integrity check: {abs(original_2022_income - loaded_2022_income) < 0.01}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5721fdce",
   "metadata": {},
   "source": [
    "### Main functionalities of MultiYearDataset\n",
    "\n",
    "#### 1. Accessing data by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4c3bbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022 dataset time period: 2022\n",
      "2022 person data shape: (1000, 4)\n",
      "2024 dataset time period: 2024\n",
      "Error accessing non-existent year: No dataset found for year 2025.\n",
      "Available years: [2021, 2022, 2023, 2024]\n"
     ]
    }
   ],
   "source": [
    "# Access specific years using get_year() method\n",
    "dataset_2022 = multi_year_dataset.get_year(2022)\n",
    "print(f\"2022 dataset time period: {dataset_2022.time_period}\")\n",
    "print(f\"2022 person data shape: {dataset_2022.entities['person'].shape}\")\n",
    "\n",
    "# Access specific years using indexing operator []\n",
    "dataset_2024 = multi_year_dataset[2024]\n",
    "print(f\"2024 dataset time period: {dataset_2024.time_period}\")\n",
    "\n",
    "# Try to access a year that doesn't exist\n",
    "try:\n",
    "    dataset_2025 = multi_year_dataset.get_year(2025)\n",
    "except ValueError as e:\n",
    "    print(f\"Error accessing non-existent year: {e}\")\n",
    "\n",
    "# List all available years\n",
    "print(f\"Available years: {sorted(multi_year_dataset.datasets.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e210fa1",
   "metadata": {},
   "source": [
    "#### 2. Variables and data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e744b959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables by year and entity:\n",
      "\n",
      "Year 2021:\n",
      "  person: ['person_id', 'age', 'income', 'household_id']\n",
      "  household: ['household_id', 'household_size', 'housing_cost', 'state']\n",
      "\n",
      "Year 2022:\n",
      "  person: ['person_id', 'age', 'income', 'household_id']\n",
      "  household: ['household_id', 'household_size', 'housing_cost', 'state']\n",
      "\n",
      "Year 2023:\n",
      "  person: ['person_id', 'age', 'income', 'household_id']\n",
      "  household: ['household_id', 'household_size', 'housing_cost', 'state']\n",
      "\n",
      "Year 2024:\n",
      "  person: ['person_id', 'age', 'income', 'household_id']\n",
      "  household: ['household_id', 'household_size', 'housing_cost', 'state']\n"
     ]
    }
   ],
   "source": [
    "# Get variables across all years\n",
    "variables_by_year = multi_year_dataset.variables\n",
    "print(\"Variables by year and entity:\")\n",
    "for year, entities in variables_by_year.items():\n",
    "    print(f\"\\nYear {year}:\")\n",
    "    for entity, vars_list in entities.items():\n",
    "        print(f\"  {entity}: {vars_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2292511",
   "metadata": {},
   "source": [
    "#### 3. Data loading and copying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ucthzwr8ppc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of loaded data structure:\n",
      "\n",
      "Variable 'person_id':\n",
      "  Year 2021: shape (1000,), mean = 499.50\n",
      "  Year 2022: shape (1000,), mean = 499.50\n",
      "  Year 2023: shape (1000,), mean = 499.50\n",
      "  Year 2024: shape (1000,), mean = 499.50\n",
      "\n",
      "Variable 'age':\n",
      "  Year 2021: shape (1000,), mean = 49.86\n",
      "  Year 2022: shape (1000,), mean = 49.86\n",
      "  Year 2023: shape (1000,), mean = 49.86\n",
      "  Year 2024: shape (1000,), mean = 49.86\n",
      "\n",
      "Original dataset years: [2021, 2022, 2023, 2024]\n",
      "Copied dataset years: [2021, 2022, 2023, 2024]\n",
      "Are they the same object? False\n",
      "Original 2023 income mean: $50678.04\n",
      "Copy 2023 income mean: $50678.04\n",
      "Data integrity check: True\n"
     ]
    }
   ],
   "source": [
    "# Load all data as a time-period indexed dictionary\n",
    "all_data = multi_year_dataset.load()\n",
    "print(\"Sample of loaded data structure:\")\n",
    "for var_name, year_data in list(all_data.items())[:2]:  # Show first 2 variables\n",
    "    print(f\"\\nVariable '{var_name}':\")\n",
    "    for year, data_array in year_data.items():\n",
    "        print(f\"  Year {year}: shape {data_array.shape}, mean = {data_array.mean():.2f}\")\n",
    "\n",
    "# Create a copy of the multi-year dataset\n",
    "multi_year_copy = multi_year_dataset.copy()\n",
    "print(f\"\\nOriginal dataset years: {sorted(multi_year_dataset.datasets.keys())}\")\n",
    "print(f\"Copied dataset years: {sorted(multi_year_copy.datasets.keys())}\")\n",
    "print(f\"Are they the same object? {multi_year_dataset is multi_year_copy}\")\n",
    "\n",
    "# Verify independence of the copy\n",
    "original_2023_income_mean = multi_year_dataset[2023].entities['person']['income'].mean()\n",
    "copy_2023_income_mean = multi_year_copy[2023].entities['person']['income'].mean()\n",
    "print(f\"Original 2023 income mean: ${original_2023_income_mean:.2f}\")\n",
    "print(f\"Copy 2023 income mean: ${copy_2023_income_mean:.2f}\")\n",
    "print(f\"Data integrity check: {abs(original_2023_income_mean - copy_2023_income_mean) < 0.01}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "qrue1qeh4ub",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned up sample_dataset_2023.h5\n",
      "Cleaned up sample_multi_year_dataset.h5\n",
      "Documentation complete! The notebook now contains comprehensive documentation for both SingleYearDataset and MultiYearDataset classes.\n"
     ]
    }
   ],
   "source": [
    "# Clean up temporary files\n",
    "import os\n",
    "\n",
    "temp_files = [\"sample_dataset_2023.h5\", \"sample_multi_year_dataset.h5\"]\n",
    "for file in temp_files:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "        print(f\"Cleaned up {file}\")\n",
    "\n",
    "print(\"Documentation complete! The notebook now contains comprehensive documentation for both SingleYearDataset and MultiYearDataset classes.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
