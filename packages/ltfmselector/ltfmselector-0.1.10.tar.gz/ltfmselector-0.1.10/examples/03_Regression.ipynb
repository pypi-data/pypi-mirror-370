{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ba5ccec-7dd6-4e6c-a26e-b30ef18b99df",
   "metadata": {},
   "source": [
    "## Example of using LTFMSelector for Regression\n",
    "As an example, we will experiment with the California Housing dataset. The target variable is the median house value for California districts, expressed in hundreds of thousands of dollars ($100,000).\n",
    "\n",
    "This dataset was derived from the 1990 U.S. census, using one row per census block group. A block group is the smallest geographical unit for which the U.S. Census Bureau publishes sample data (a block group typically has a population of 600 to 3,000 people).\n",
    "\n",
    "A household is a group of people residing within a home. Since the average number of rooms and bedrooms in this dataset are provided per household, these columns may take surprisingly large values for block groups with few households and many empty houses, such as vacation resorts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a466b28f-5ab0-484b-8824-2315a93393a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ltfmselector import LTFMSelector\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9f813a4-f3b5-4cef-b6e0-3dcbf7f4d250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      ":Number of Instances: 20640\n",
      "\n",
      ":Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      ":Attribute Information:\n",
      "    - MedInc        median income in block group\n",
      "    - HouseAge      median house age in block group\n",
      "    - AveRooms      average number of rooms per household\n",
      "    - AveBedrms     average number of bedrooms per household\n",
      "    - Population    block group population\n",
      "    - AveOccup      average number of household members\n",
      "    - Latitude      block group latitude\n",
      "    - Longitude     block group longitude\n",
      "\n",
      ":Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
      "\n",
      "The target variable is the median house value for California districts,\n",
      "expressed in hundreds of thousands of dollars ($100,000).\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "A household is a group of people residing within a home. Since the average\n",
      "number of rooms and bedrooms in this dataset are provided per household, these\n",
      "columns may take surprisingly large values for block groups with few households\n",
      "and many empty houses, such as vacation resorts.\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. rubric:: References\n",
      "\n",
      "- Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "  Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading the California Housing Dataset\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# Get data\n",
    "X = housing['data']\n",
    "\n",
    "# Get target\n",
    "y = housing['target']\n",
    "\n",
    "# Get feature names\n",
    "feature_names = housing['feature_names']\n",
    "\n",
    "# Get description\n",
    "dataset_description = housing['DESCR']\n",
    "print(dataset_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44da7d5b-906b-4de5-bf42-c7cab0f52b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data into pandas DataFrame\n",
    "housing_df = pd.DataFrame(\n",
    "    np.c_[X, y], columns = np.append(feature_names, ['target'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ac1475-df9c-49ff-889b-06079cf9beab",
   "metadata": {},
   "source": [
    "The data will then be split for training and testing.\n",
    "\n",
    "Note: It is important that the training datasets (`X`) are passed as `pandas.DataFrame` and the label (`y`) as `pandas.Series`. Other forms will be accomodated for in later versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6195128c-4414-458c-9a53-78038eae9325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset for training and test\n",
    "X_df = housing_df.drop(['target'], axis=1)\n",
    "y_df = housing_df['target']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.2, random_state=5)\n",
    "\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test  = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9c217aa-b9df-400b-9467-0e00a0585d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also remember to reset the index of X_train and X_test\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test  = X_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f6ac7b-9acb-4079-8a83-ee671b5f4e88",
   "metadata": {},
   "source": [
    "We will now train an agent using LTFMSelector to select features and a prediction models, tailored to each sample.\n",
    "\n",
    "When initializing LTFMSelector, one necessary hyperparameter is the number of episodes, over which an agent is trained. My personal recommendation is set roughly 2-3 times the number of training examples.\n",
    " - So for example here, we have 16512 training examples: Hence, ~32000 episodes\n",
    "\n",
    "Another hyperparameter that should be set is `ptype`, which should be set to `regression` for this example.\n",
    "\n",
    "If `pModels=None`, a default choice of:\n",
    " - Support Vector Machine\n",
    " - Random Forest\n",
    " - Ridge Regression (Linear least squares with L2 regularization)\n",
    "will be implemented, all using the scikit-learn library with default hyperparameters. Users can also pass a list of regression model objects, which must have `fit` and `predict` call functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1065057b-f85d-4202-a651-a959ef4fd3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training an agent using LTFMSelector to select features and an appropriate prediction model tailored to each sample\n",
    "AgentSelector = LTFMSelector(100, pType='regression') # If you got time, go for 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa45ff2-6a3c-4965-a1d5-18c05a2acb73",
   "metadata": {},
   "source": [
    "Train the agent by passing the training examples and label.\n",
    "\n",
    "The hyperparameter `agent_neuralnetwork` receives as an input a PyTorch neural network which will be used to learn the agent's policy. If `None`, a feed-forward (multilayer-perceptron) of with two hidden layers, each with 1024 units will be used.\n",
    "\n",
    "`lr` refers to the learning rate of the `AdamW` optimizer, used to update the policy network.\n",
    "\n",
    "The `fit` function returns a `dict<dict>` object, storing meta-information during the training process.\n",
    "\n",
    "Note: Just for demo purposes, training an agent over 1300 episodes may take some time but if you are simply interested in getting a feel for the interface then just set the number of episodes to 30 or less for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa5592e6-bfef-4a6d-83cc-821f1ba6c16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== Episode 1 === === ===\n",
      "\n",
      "Incorrect prediction\n",
      "True Output: 1.379 | Prediction: 2.23982177975018\n",
      "\n",
      "Episode terminated:\n",
      "- Iterations                 : 15\n",
      "- Features selected          : 7.0\n",
      "- Prediction model           : 2\n",
      "- Prediction model #(change) : 1\n",
      "\n",
      "\n",
      "=== Episode 2 === === ===\n",
      "Episode terminated:\n",
      "- Iterations                 : 2\n",
      "- Features selected          : 0.0\n",
      "- Prediction model           : 1\n",
      "- Prediction model #(change) : 1\n",
      "\n",
      "\n",
      "=== Episode 3 === === ===\n",
      "\n",
      "Correct prediction\n",
      "True Output: 2.241 | Prediction: 1.8665238859874158\n",
      "\n",
      "Episode terminated:\n",
      "- Iterations                 : 24\n",
      "- Features selected          : 6.0\n",
      "- Prediction model           : 0\n",
      "- Prediction model #(change) : 8\n",
      "\n",
      "\n",
      "=== Episode 4 === === ===\n",
      "\n",
      "Correct prediction\n",
      "True Output: 0.905 | Prediction: 1.0584499999999997\n",
      "\n",
      "Episode terminated:\n",
      "- Iterations                 : 19\n",
      "- Features selected          : 8.0\n",
      "- Prediction model           : 1\n",
      "- Prediction model #(change) : 4\n",
      "\n",
      "\n",
      "=== Episode 5 === === ===\n",
      "\n",
      "Correct prediction\n",
      "True Output: 2.775 | Prediction: 2.5794200000000003\n",
      "\n",
      "Episode terminated:\n",
      "- Iterations                 : 5\n",
      "- Features selected          : 2.0\n",
      "- Prediction model           : 1\n",
      "- Prediction model #(change) : 2\n",
      "\n",
      "\n",
      "=== Episode 6 === === ===\n",
      "\n",
      "Incorrect prediction\n",
      "True Output: 1.228 | Prediction: 2.5296115\n",
      "\n",
      "Episode terminated:\n",
      "- Iterations                 : 8\n",
      "- Features selected          : 3.0\n",
      "- Prediction model           : 1\n",
      "- Prediction model #(change) : 3\n",
      "\n",
      "\n",
      "=== Episode 7 === === ===\n",
      "\n",
      "Incorrect prediction\n",
      "True Output: 5.00001 | Prediction: 2.187799220888145\n",
      "\n",
      "Episode terminated:\n",
      "- Iterations                 : 3\n",
      "- Features selected          : 1.0\n",
      "- Prediction model           : 1\n",
      "- Prediction model #(change) : 1\n",
      "\n",
      "\n",
      "=== Episode 8 === === ===\n",
      "\n",
      "Correct prediction\n",
      "True Output: 1.481 | Prediction: 1.888709999999999\n",
      "\n",
      "Episode terminated:\n",
      "- Iterations                 : 9\n",
      "- Features selected          : 4.0\n",
      "- Prediction model           : 1\n",
      "- Prediction model #(change) : 1\n",
      "\n",
      "\n",
      "=== Episode 9 === === ===\n",
      "\n",
      "Correct prediction\n",
      "True Output: 1.118 | Prediction: 1.4278564979383233\n",
      "\n",
      "Episode terminated:\n",
      "- Iterations                 : 8\n",
      "- Features selected          : 4.0\n",
      "- Prediction model           : 0\n",
      "- Prediction model #(change) : 2\n",
      "\n",
      "\n",
      "=== Episode 10 === === ===\n",
      "\n",
      "Correct prediction\n",
      "True Output: 1.538 | Prediction: 1.0739613967530062\n",
      "\n",
      "Episode terminated:\n",
      "- Iterations                 : 19\n",
      "- Features selected          : 8.0\n",
      "- Prediction model           : 2\n",
      "- Prediction model #(change) : 1\n",
      "\n",
      "\n",
      "=== Episode 11 === === ===\n",
      "\n",
      "Incorrect prediction\n",
      "True Output: 2.627 | Prediction: 1.877590010076276\n",
      "\n",
      "Episode terminated:\n",
      "- Iterations                 : 2\n",
      "- Features selected          : 1.0\n",
      "- Prediction model           : 0\n",
      "- Prediction model #(change) : 0\n",
      "\n",
      "\n",
      "=== Episode 12 === === ===\n",
      "\n",
      "Correct prediction\n",
      "True Output: 1.427 | Prediction: 1.4800817158322372\n",
      "\n",
      "Episode terminated:\n",
      "- Iterations                 : 19\n",
      "- Features selected          : 6.0\n",
      "- Prediction model           : 0\n",
      "- Prediction model #(change) : 4\n",
      "\n",
      "\n",
      "=== Episode 13 === === ===\n",
      "\n",
      "Correct prediction\n",
      "True Output: 2.271 | Prediction: 2.05431\n",
      "\n",
      "Episode terminated:\n",
      "- Iterations                 : 23\n",
      "- Features selected          : 7.0\n",
      "- Prediction model           : 1\n",
      "- Prediction model #(change) : 3\n",
      "\n",
      "\n",
      "=== Episode 14 === === ===\n",
      "\n",
      "Correct prediction\n",
      "True Output: 1.645 | Prediction: 2.073497939624838\n",
      "\n",
      "Episode terminated:\n",
      "- Iterations                 : 2\n",
      "- Features selected          : 1.0\n",
      "- Prediction model           : 2\n",
      "- Prediction model #(change) : 0\n",
      "\n",
      "\n",
      "=== Episode 15 === === ===\n",
      "\n",
      "Incorrect prediction\n",
      "True Output: 3.65 | Prediction: 1.823750916342902\n",
      "\n",
      "Episode terminated:\n",
      "- Iterations                 : 14\n",
      "- Features selected          : 7.0\n",
      "- Prediction model           : 0\n",
      "- Prediction model #(change) : 2\n",
      "\n",
      "\n",
      "=== Episode 16 === === ===\n",
      "\n",
      "Incorrect prediction\n",
      "True Output: 1.04 | Prediction: 2.8931933333333326\n",
      "\n",
      "Episode terminated:\n",
      "- Iterations                 : 9\n",
      "- Features selected          : 2.0\n",
      "- Prediction model           : 1\n",
      "- Prediction model #(change) : 3\n",
      "\n",
      "\n",
      "=== Episode 17 === === ===\n",
      "\n",
      "Incorrect prediction\n",
      "True Output: 0.325 | Prediction: 2.3597615999999997\n",
      "\n",
      "Episode terminated:\n",
      "- Iterations                 : 16\n",
      "- Features selected          : 4.0\n",
      "- Prediction model           : 1\n",
      "- Prediction model #(change) : 2\n",
      "\n",
      "\n",
      "=== Episode 18 === === ===\n",
      "\n",
      "Correct prediction\n",
      "True Output: 1.581 | Prediction: 1.786\n",
      "\n",
      "Episode terminated:\n",
      "- Iterations                 : 9\n",
      "- Features selected          : 5.0\n",
      "- Prediction model           : 1\n",
      "- Prediction model #(change) : 2\n",
      "\n",
      "\n",
      "=== Episode 19 === === ===\n",
      "\n",
      "Incorrect prediction\n",
      "True Output: 1.406 | Prediction: 2.4496556650626897\n",
      "\n",
      "Episode terminated:\n",
      "- Iterations                 : 9\n",
      "- Features selected          : 4.0\n",
      "- Prediction model           : 2\n",
      "- Prediction model #(change) : 0\n",
      "\n",
      "\n",
      "=== Episode 20 === === ===\n",
      "\n",
      "Incorrect prediction\n",
      "True Output: 0.58 | Prediction: 1.7590316386086502\n",
      "\n",
      "Episode terminated:\n",
      "- Iterations                 : 6\n",
      "- Features selected          : 3.0\n",
      "- Prediction model           : 0\n",
      "- Prediction model #(change) : 2\n",
      "\n",
      "\n",
      "=== Episode 21 === === ===\n",
      "\n",
      "Incorrect prediction\n",
      "True Output: 2.732 | Prediction: 2.0756613100905548\n",
      "\n",
      "Episode terminated:\n",
      "- Iterations                 : 3\n",
      "- Features selected          : 2.0\n",
      "- Prediction model           : 2\n",
      "- Prediction model #(change) : 0\n",
      "\n",
      "\n",
      "=== Episode 22 === === ===\n",
      "\n",
      "Correct prediction\n",
      "True Output: 2.109 | Prediction: 2.0252367936224083\n",
      "\n",
      "Episode terminated:\n",
      "- Iterations                 : 23\n",
      "- Features selected          : 6.0\n",
      "- Prediction model           : 0\n",
      "- Prediction model #(change) : 6\n",
      "\n",
      "\n",
      "=== Episode 23 === === ===\n",
      "\n",
      "Correct prediction\n",
      "True Output: 2.239 | Prediction: 1.8880727894235574\n",
      "\n",
      "Episode terminated:\n",
      "- Iterations                 : 6\n",
      "- Features selected          : 3.0\n",
      "- Prediction model           : 0\n",
      "- Prediction model #(change) : 0\n",
      "\n",
      "\n",
      "=== Episode 24 === === ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liaw/repo/ltfmselector/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:823: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found dtype Double but expected Float",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Now letting the agent train, this could take some time ...\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m doc = \u001b[43mAgentSelector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_neuralnetwork\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/ltfmselector/src/ltfmselector/ltfmselector.py:341\u001b[39m, in \u001b[36mLTFMSelector.fit\u001b[39m\u001b[34m(self, X, y, loss_function, sample_weight, agent_neuralnetwork, lr, returnQ, background_dataset, **kwargs)\u001b[39m\n\u001b[32m    338\u001b[39m state = next_state\n\u001b[32m    340\u001b[39m \u001b[38;5;66;03m# Optimize the model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m _res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturnQ\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m returnQ:\n\u001b[32m    343\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/ltfmselector/src/ltfmselector/ltfmselector.py:615\u001b[39m, in \u001b[36mLTFMSelector.optimize_model\u001b[39m\u001b[34m(self, loss_function, returnQ)\u001b[39m\n\u001b[32m    613\u001b[39m \u001b[38;5;66;03m# Optimize the model (policy network)\u001b[39;00m\n\u001b[32m    614\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizer.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m615\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    617\u001b[39m \u001b[38;5;66;03m# In-place gradient clipping\u001b[39;00m\n\u001b[32m    618\u001b[39m torch.nn.utils.clip_grad_value_(\u001b[38;5;28mself\u001b[39m.policy_net.parameters(), \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/ltfmselector/.venv/lib/python3.13/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/ltfmselector/.venv/lib/python3.13/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repo/ltfmselector/.venv/lib/python3.13/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: Found dtype Double but expected Float"
     ]
    }
   ],
   "source": [
    "# Now letting the agent train, this could take some time ...\n",
    "doc = AgentSelector.fit(X_train, y_train, agent_neuralnetwork=None, lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070e4333-db7a-4e72-8b14-f4de73da471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check out the regression model performance in terms of the coefficient of determination\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R2: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19de8a4-6609-40fe-8ba1-ae821264801f",
   "metadata": {},
   "source": [
    "For examples of how you can investigate the features and models selected per sample, simply refer to the other previous notebooks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
