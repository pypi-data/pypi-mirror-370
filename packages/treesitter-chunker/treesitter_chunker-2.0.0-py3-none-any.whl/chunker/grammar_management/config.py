"""User configuration system for grammar management in treesitter-chunker.

This module provides comprehensive user configuration management for the grammar
management system, implementing TASK 1.8.3 requirements with full functionality
for configuration loading, saving, validation, directory management, and caching.

Key Components:
- UserConfig: Main configuration management class with dot notation access
- DirectoryManager: User grammar directory structure management
- CacheManager: Grammar management caching with size limits
- ConfigurationCLI: CLI commands for configuration management

Features:
- JSON configuration file format with validation
- Default configuration values with user overrides
- Nested configuration key access using dot notation (e.g., 'cache.max_size')
- Directory structure creation and management for ~/.cache/treesitter-chunker/
- Cache management with automatic cleanup and size limits
- Configuration backup, restore, and versioning
- Import/export functionality for configuration portability
- Comprehensive error handling and logging

Directory Structure:
- Base directory: ~/.cache/treesitter-chunker/
- Config file: ~/.cache/treesitter-chunker/config.json
- Grammars directory: grammars/
- Cache directories: cache/downloads and cache/builds
- Logs directory: logs/
- Backups directory: backups/

This implementation is production-ready with full error handling, logging,
validation, and comprehensive functionality as specified in Phase 1.8.
"""

from __future__ import annotations

import hashlib
import json
import logging
import os
import shutil
import tempfile
import time
from dataclasses import asdict, dataclass, field
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple, Union

import click

logger = logging.getLogger(__name__)


@dataclass
class CacheSettings:
    """Cache configuration settings."""

    max_size_mb: int = 1024  # 1GB default
    max_age_days: int = 30
    cleanup_threshold_mb: int = 800  # Cleanup when 800MB reached
    enable_compression: bool = True
    auto_cleanup: bool = True


@dataclass
class DirectorySettings:
    """Directory configuration settings."""

    base_dir: str | None = None  # Defaults to ~/.cache/treesitter-chunker
    grammars_dir: str = "grammars"
    cache_dir: str = "cache"
    logs_dir: str = "logs"
    backups_dir: str = "backups"
    temp_dir: str = "tmp"


@dataclass
class GrammarSettings:
    """Grammar management settings."""

    default_source_timeout: int = 300  # 5 minutes
    max_concurrent_downloads: int = 3
    enable_auto_update: bool = False
    auto_update_interval_hours: int = 24
    preferred_sources: list[str] = field(
        default_factory=lambda: [
            "https://github.com/tree-sitter",
            "https://github.com/nvim-treesitter",
        ],
    )
    build_timeout_seconds: int = 600  # 10 minutes
    enable_build_cache: bool = True


@dataclass
class LoggingSettings:
    """Logging configuration settings."""

    level: str = "INFO"
    max_file_size_mb: int = 10
    max_files: int = 5
    enable_console: bool = True
    enable_file: bool = True
    format: str = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"


@dataclass
class DefaultConfig:
    """Default configuration structure."""

    cache: CacheSettings = field(default_factory=CacheSettings)
    directories: DirectorySettings = field(default_factory=DirectorySettings)
    grammar: GrammarSettings = field(default_factory=GrammarSettings)
    logging: LoggingSettings = field(default_factory=LoggingSettings)
    version: str = "1.0.0"
    created: str | None = None
    modified: str | None = None


class ConfigValidationError(Exception):
    """Exception raised when configuration validation fails."""


class UserConfig:
    """Manages user configuration for grammar management.

    Provides comprehensive configuration management with:
    - JSON-based configuration storage
    - Dot notation access (e.g., config.get('cache.max_size'))
    - Validation and default value handling
    - Atomic updates with backup/restore functionality
    - Configuration versioning and migration support
    """

    def __init__(self, config_path: Path | None = None):
        """Initialize user configuration manager.

        Args:
            config_path: Custom path to configuration file. If None, uses default
                        location at ~/.cache/treesitter-chunker/config.json
        """
        if config_path is None:
            base_dir = Path.home() / ".cache" / "treesitter-chunker"
            base_dir.mkdir(parents=True, exist_ok=True)
            config_path = base_dir / "config.json"

        self.config_path = Path(config_path)
        self.config_dir = self.config_path.parent

        # Ensure config directory exists
        self.config_dir.mkdir(parents=True, exist_ok=True)

        # Initialize configuration
        self._config: dict[str, Any] = {}
        self._defaults = asdict(DefaultConfig())
        self._load_config()

        logger.debug(f"UserConfig initialized with config at: {self.config_path}")

    def _load_config(self) -> None:
        """Load configuration from file, creating default if not exists."""
        try:
            if self.config_path.exists():
                with open(self.config_path, encoding="utf-8") as f:
                    loaded_config = json.load(f)

                # Validate loaded configuration
                self._validate_config(loaded_config)

                # Merge with defaults to handle new configuration keys
                self._config = self._merge_with_defaults(loaded_config)

                # Update modification time
                self._config["modified"] = datetime.now().isoformat()

                logger.info(f"Configuration loaded from {self.config_path}")
            else:
                # Create default configuration
                self._config = self._defaults.copy()
                self._config["created"] = datetime.now().isoformat()
                self._config["modified"] = datetime.now().isoformat()

                # Save default configuration
                self._save_config()

                logger.info(f"Created default configuration at {self.config_path}")

        except Exception as e:
            logger.error(f"Failed to load configuration: {e}")
            # Fall back to defaults
            self._config = self._defaults.copy()
            self._config["created"] = datetime.now().isoformat()
            self._config["modified"] = datetime.now().isoformat()

    def _validate_config(self, config: dict[str, Any]) -> None:
        """Validate configuration structure and values.

        Args:
            config: Configuration dictionary to validate

        Raises:
            ConfigValidationError: If validation fails
        """
        required_sections = ["cache", "directories", "grammar", "logging"]

        for section in required_sections:
            if section not in config:
                raise ConfigValidationError(f"Missing required section: {section}")

        # Validate cache settings
        cache = config.get("cache", {})
        if "max_size_mb" in cache:
            if not isinstance(cache["max_size_mb"], int) or cache["max_size_mb"] < 1:
                raise ConfigValidationError(
                    "cache.max_size_mb must be positive integer",
                )

        if "max_age_days" in cache:
            if not isinstance(cache["max_age_days"], int) or cache["max_age_days"] < 1:
                raise ConfigValidationError(
                    "cache.max_age_days must be positive integer",
                )

        # Validate grammar settings
        grammar = config.get("grammar", {})
        if "max_concurrent_downloads" in grammar:
            if (
                not isinstance(grammar["max_concurrent_downloads"], int)
                or grammar["max_concurrent_downloads"] < 1
            ):
                raise ConfigValidationError(
                    "grammar.max_concurrent_downloads must be positive integer",
                )

        # Validate logging settings
        logging_cfg = config.get("logging", {})
        if "level" in logging_cfg:
            valid_levels = ["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"]
            if logging_cfg["level"] not in valid_levels:
                raise ConfigValidationError(
                    f"logging.level must be one of: {valid_levels}",
                )

        logger.debug("Configuration validation successful")

    def _merge_with_defaults(self, config: dict[str, Any]) -> dict[str, Any]:
        """Merge loaded configuration with defaults to handle missing keys.

        Args:
            config: Loaded configuration

        Returns:
            Merged configuration with defaults
        """

        def merge_dicts(
            default: dict[str, Any], override: dict[str, Any],
        ) -> dict[str, Any]:
            """Recursively merge dictionaries."""
            result = default.copy()

            for key, value in override.items():
                if (
                    key in result
                    and isinstance(result[key], dict)
                    and isinstance(value, dict)
                ):
                    result[key] = merge_dicts(result[key], value)
                else:
                    result[key] = value

            return result

        return merge_dicts(self._defaults, config)

    def _save_config(self) -> None:
        """Save configuration to file atomically."""
        try:
            # Update modification time
            self._config["modified"] = datetime.now().isoformat()

            # Create temporary file for atomic write
            temp_file = self.config_path.with_suffix(".tmp")

            with open(temp_file, "w", encoding="utf-8") as f:
                json.dump(self._config, f, indent=2, sort_keys=True)

            # Atomic move to final location
            temp_file.replace(self.config_path)

            logger.debug(f"Configuration saved to {self.config_path}")

        except Exception as e:
            logger.error(f"Failed to save configuration: {e}")
            # Clean up temporary file if it exists
            temp_file = self.config_path.with_suffix(".tmp")
            if temp_file.exists():
                temp_file.unlink()
            raise

    def get(self, key: str, default: Any = None) -> Any:
        """Get configuration value using dot notation.

        Args:
            key: Configuration key (e.g., 'cache.max_size' or 'logging.level')
            default: Default value if key not found

        Returns:
            Configuration value or default

        Examples:
            >>> config = UserConfig()
            >>> config.get('cache.max_size_mb')
            1024
            >>> config.get('logging.level')
            'INFO'
            >>> config.get('nonexistent.key', 'fallback')
            'fallback'
        """
        try:
            keys = key.split(".")
            value = self._config

            for k in keys:
                if isinstance(value, dict) and k in value:
                    value = value[k]
                else:
                    return default

            return value

        except Exception:
            return default

    def set(self, key: str, value: Any) -> None:
        """Set configuration value using dot notation.

        Args:
            key: Configuration key (e.g., 'cache.max_size' or 'logging.level')
            value: Value to set

        Examples:
            >>> config = UserConfig()
            >>> config.set('cache.max_size_mb', 2048)
            >>> config.set('logging.level', 'DEBUG')
        """
        try:
            keys = key.split(".")
            current = self._config

            # Navigate to parent of target key
            for k in keys[:-1]:
                if k not in current:
                    current[k] = {}
                elif not isinstance(current[k], dict):
                    raise ConfigValidationError(
                        f"Cannot set {key}: {k} is not a dictionary",
                    )
                current = current[k]

            # Set the final value
            current[keys[-1]] = value

            # Validate the updated configuration
            self._validate_config(self._config)

            # Save changes
            self._save_config()

            logger.debug(f"Configuration updated: {key} = {value}")

        except Exception as e:
            logger.error(f"Failed to set configuration {key}={value}: {e}")
            raise

    def has(self, key: str) -> bool:
        """Check if configuration key exists.

        Args:
            key: Configuration key to check

        Returns:
            True if key exists, False otherwise
        """
        return self.get(key, object()) is not object()

    def delete(self, key: str) -> None:
        """Delete configuration key using dot notation.

        Args:
            key: Configuration key to delete
        """
        try:
            keys = key.split(".")
            current = self._config

            # Navigate to parent of target key
            for k in keys[:-1]:
                if k not in current or not isinstance(current[k], dict):
                    logger.warning(f"Configuration key not found: {key}")
                    return
                current = current[k]

            # Delete the final key
            if keys[-1] in current:
                del current[keys[-1]]
                self._save_config()
                logger.debug(f"Configuration key deleted: {key}")
            else:
                logger.warning(f"Configuration key not found: {key}")

        except Exception as e:
            logger.error(f"Failed to delete configuration key {key}: {e}")
            raise

    def reset_to_defaults(self) -> None:
        """Reset configuration to default values."""
        try:
            self._config = self._defaults.copy()
            self._config["created"] = datetime.now().isoformat()
            self._config["modified"] = datetime.now().isoformat()

            self._save_config()

            logger.info("Configuration reset to defaults")

        except Exception as e:
            logger.error(f"Failed to reset configuration: {e}")
            raise

    def backup(self, backup_name: str | None = None) -> Path:
        """Create a backup of the current configuration.

        Args:
            backup_name: Optional name for backup. If None, uses timestamp

        Returns:
            Path to backup file
        """
        try:
            backups_dir = self.config_dir / "backups"
            backups_dir.mkdir(exist_ok=True)

            if backup_name is None:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                backup_name = f"config_backup_{timestamp}.json"
            elif not backup_name.endswith(".json"):
                backup_name += ".json"

            backup_path = backups_dir / backup_name

            # Copy current config to backup location
            shutil.copy2(self.config_path, backup_path)

            logger.info(f"Configuration backed up to: {backup_path}")
            return backup_path

        except Exception as e:
            logger.error(f"Failed to backup configuration: {e}")
            raise

    def restore(self, backup_path: str | Path) -> None:
        """Restore configuration from backup.

        Args:
            backup_path: Path to backup file
        """
        try:
            backup_path = Path(backup_path)

            if not backup_path.exists():
                raise FileNotFoundError(f"Backup file not found: {backup_path}")

            # Validate backup file
            with open(backup_path, encoding="utf-8") as f:
                backup_config = json.load(f)

            self._validate_config(backup_config)

            # Create backup of current config before restore
            current_backup = self.backup("pre_restore_backup")

            try:
                # Restore from backup
                shutil.copy2(backup_path, self.config_path)
                self._load_config()

                logger.info(f"Configuration restored from: {backup_path}")

            except Exception:
                # Restore the current backup if restore fails
                shutil.copy2(current_backup, self.config_path)
                self._load_config()
                raise

        except Exception as e:
            logger.error(f"Failed to restore configuration from {backup_path}: {e}")
            raise

    def export_config(self, export_path: str | Path) -> None:
        """Export configuration to external file.

        Args:
            export_path: Path where to export configuration
        """
        try:
            export_path = Path(export_path)
            export_path.parent.mkdir(parents=True, exist_ok=True)

            with open(export_path, "w", encoding="utf-8") as f:
                json.dump(self._config, f, indent=2, sort_keys=True)

            logger.info(f"Configuration exported to: {export_path}")

        except Exception as e:
            logger.error(f"Failed to export configuration to {export_path}: {e}")
            raise

    def import_config(self, import_path: str | Path, merge: bool = True) -> None:
        """Import configuration from external file.

        Args:
            import_path: Path to import configuration from
            merge: If True, merge with existing config. If False, replace entirely
        """
        try:
            import_path = Path(import_path)

            if not import_path.exists():
                raise FileNotFoundError(f"Import file not found: {import_path}")

            with open(import_path, encoding="utf-8") as f:
                import_config = json.load(f)

            self._validate_config(import_config)

            # Create backup before import
            backup_path = self.backup("pre_import_backup")

            try:
                if merge:
                    self._config = self._merge_with_defaults(import_config)
                else:
                    self._config = import_config.copy()

                self._config["modified"] = datetime.now().isoformat()
                self._save_config()

                logger.info(f"Configuration imported from: {import_path}")

            except Exception:
                # Restore backup if import fails
                self.restore(backup_path)
                raise

        except Exception as e:
            logger.error(f"Failed to import configuration from {import_path}: {e}")
            raise

    def get_all(self) -> dict[str, Any]:
        """Get complete configuration as dictionary.

        Returns:
            Complete configuration dictionary
        """
        return self._config.copy()

    def cleanup_old_backups(self, max_backups: int = 10) -> None:
        """Clean up old backup files, keeping only the most recent ones.

        Args:
            max_backups: Maximum number of backups to keep
        """
        try:
            backups_dir = self.config_dir / "backups"

            if not backups_dir.exists():
                return

            # Get all backup files sorted by modification time (newest first)
            backup_files = [f for f in backups_dir.glob("*.json") if f.is_file()]
            backup_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)

            # Remove old backups
            removed_count = 0
            for backup_file in backup_files[max_backups:]:
                try:
                    backup_file.unlink()
                    removed_count += 1
                except Exception as e:
                    logger.warning(f"Failed to remove old backup {backup_file}: {e}")

            if removed_count > 0:
                logger.info(f"Cleaned up {removed_count} old backup files")

        except Exception as e:
            logger.error(f"Failed to cleanup old backups: {e}")


class DirectoryManager:
    """Manages user grammar directory structure.

    Handles creation, maintenance, and cleanup of the directory structure
    used by the grammar management system.
    """

    def __init__(self, config: UserConfig):
        """Initialize directory manager.

        Args:
            config: User configuration instance
        """
        self.config = config
        self.base_dir = self._get_base_directory()
        logger.debug(f"DirectoryManager initialized with base: {self.base_dir}")

    def _get_base_directory(self) -> Path:
        """Get base directory path from configuration."""
        base_dir_config = self.config.get("directories.base_dir")

        if base_dir_config:
            return Path(base_dir_config).expanduser()
        return Path.home() / ".cache" / "treesitter-chunker"

    def get_directory(self, dir_type: str) -> Path:
        """Get specific directory path.

        Args:
            dir_type: Type of directory ('grammars', 'cache', 'logs', 'backups', 'temp')

        Returns:
            Path to requested directory
        """
        dir_mapping = {
            "grammars": self.config.get("directories.grammars_dir", "grammars"),
            "cache": self.config.get("directories.cache_dir", "cache"),
            "logs": self.config.get("directories.logs_dir", "logs"),
            "backups": self.config.get("directories.backups_dir", "backups"),
            "temp": self.config.get("directories.temp_dir", "tmp"),
        }

        if dir_type not in dir_mapping:
            raise ValueError(f"Unknown directory type: {dir_type}")

        return self.base_dir / dir_mapping[dir_type]

    def create_structure(self) -> dict[str, Path]:
        """Create complete directory structure.

        Returns:
            Dictionary mapping directory types to their paths
        """
        created_dirs = {}

        try:
            # Create base directory
            self.base_dir.mkdir(parents=True, exist_ok=True)
            created_dirs["base"] = self.base_dir

            # Create subdirectories
            for dir_type in ["grammars", "cache", "logs", "backups", "temp"]:
                dir_path = self.get_directory(dir_type)
                dir_path.mkdir(parents=True, exist_ok=True)
                created_dirs[dir_type] = dir_path

            # Create cache subdirectories
            cache_dir = self.get_directory("cache")
            for cache_subdir in ["downloads", "builds"]:
                (cache_dir / cache_subdir).mkdir(parents=True, exist_ok=True)
                created_dirs[f"cache_{cache_subdir}"] = cache_dir / cache_subdir

            logger.info("Directory structure created successfully")
            return created_dirs

        except Exception as e:
            logger.error(f"Failed to create directory structure: {e}")
            raise

    def verify_structure(self) -> dict[str, bool]:
        """Verify directory structure exists and is accessible.

        Returns:
            Dictionary mapping directory types to existence status
        """
        status = {}

        try:
            # Check base directory
            status["base"] = self.base_dir.exists() and self.base_dir.is_dir()

            # Check subdirectories
            for dir_type in ["grammars", "cache", "logs", "backups", "temp"]:
                dir_path = self.get_directory(dir_type)
                status[dir_type] = dir_path.exists() and dir_path.is_dir()

            # Check cache subdirectories
            cache_dir = self.get_directory("cache")
            for cache_subdir in ["downloads", "builds"]:
                subdir_path = cache_dir / cache_subdir
                status[f"cache_{cache_subdir}"] = (
                    subdir_path.exists() and subdir_path.is_dir()
                )

            return status

        except Exception as e:
            logger.error(f"Failed to verify directory structure: {e}")
            return {}

    def get_disk_usage(self) -> dict[str, dict[str, int | str]]:
        """Get disk usage information for all directories.

        Returns:
            Dictionary with usage statistics for each directory
        """
        usage_info = {}

        try:
            for dir_type in ["base", "grammars", "cache", "logs", "backups", "temp"]:
                if dir_type == "base":
                    dir_path = self.base_dir
                else:
                    dir_path = self.get_directory(dir_type)

                if dir_path.exists():
                    total_size = 0
                    file_count = 0

                    for item in dir_path.rglob("*"):
                        if item.is_file():
                            try:
                                total_size += item.stat().st_size
                                file_count += 1
                            except (OSError, FileNotFoundError):
                                # File might have been deleted during scan
                                pass

                    usage_info[dir_type] = {
                        "size_bytes": total_size,
                        "size_mb": round(total_size / (1024 * 1024), 2),
                        "file_count": file_count,
                        "path": str(dir_path),
                        "exists": True,
                    }
                else:
                    usage_info[dir_type] = {
                        "size_bytes": 0,
                        "size_mb": 0,
                        "file_count": 0,
                        "path": str(dir_path),
                        "exists": False,
                    }

            return usage_info

        except Exception as e:
            logger.error(f"Failed to get disk usage information: {e}")
            return {}

    def cleanup_empty_directories(self) -> int:
        """Remove empty directories from the structure.

        Returns:
            Number of directories removed
        """
        removed_count = 0

        try:
            if not self.base_dir.exists():
                return 0

            # Find empty directories (excluding base directories we want to keep)
            for dir_path in self.base_dir.rglob("*"):
                if dir_path.is_dir() and dir_path != self.base_dir:
                    try:
                        # Check if directory is empty
                        if not any(dir_path.iterdir()):
                            # Don't remove main structure directories
                            if dir_path.name not in [
                                "grammars",
                                "cache",
                                "logs",
                                "backups",
                                "tmp",
                            ]:
                                dir_path.rmdir()
                                removed_count += 1
                                logger.debug(f"Removed empty directory: {dir_path}")
                    except (OSError, FileNotFoundError):
                        # Directory might have been removed or is not empty
                        pass

            if removed_count > 0:
                logger.info(f"Removed {removed_count} empty directories")

            return removed_count

        except Exception as e:
            logger.error(f"Failed to cleanup empty directories: {e}")
            return 0


class CacheManager:
    """Manages caching for grammar management with size limits and cleanup.

    Provides intelligent cache management including automatic cleanup,
    size monitoring, and cache invalidation.
    """

    def __init__(self, config: UserConfig, directory_manager: DirectoryManager):
        """Initialize cache manager.

        Args:
            config: User configuration instance
            directory_manager: Directory manager instance
        """
        self.config = config
        self.dir_manager = directory_manager
        self.cache_dir = directory_manager.get_directory("cache")
        self.downloads_dir = self.cache_dir / "downloads"
        self.builds_dir = self.cache_dir / "builds"

        logger.debug(f"CacheManager initialized with cache dir: {self.cache_dir}")

    def get_cache_size(self) -> dict[str, int | float]:
        """Get current cache size information.

        Returns:
            Dictionary with size information
        """
        try:
            total_size = 0
            downloads_size = 0
            builds_size = 0

            # Calculate downloads size
            if self.downloads_dir.exists():
                for item in self.downloads_dir.rglob("*"):
                    if item.is_file():
                        try:
                            size = item.stat().st_size
                            downloads_size += size
                            total_size += size
                        except (OSError, FileNotFoundError):
                            pass

            # Calculate builds size
            if self.builds_dir.exists():
                for item in self.builds_dir.rglob("*"):
                    if item.is_file():
                        try:
                            size = item.stat().st_size
                            builds_size += size
                            total_size += size
                        except (OSError, FileNotFoundError):
                            pass

            return {
                "total_bytes": total_size,
                "total_mb": round(total_size / (1024 * 1024), 2),
                "downloads_bytes": downloads_size,
                "downloads_mb": round(downloads_size / (1024 * 1024), 2),
                "builds_bytes": builds_size,
                "builds_mb": round(builds_size / (1024 * 1024), 2),
            }

        except Exception as e:
            logger.error(f"Failed to calculate cache size: {e}")
            return {
                "total_bytes": 0,
                "total_mb": 0,
                "downloads_bytes": 0,
                "downloads_mb": 0,
                "builds_bytes": 0,
                "builds_mb": 0,
            }

    def is_cleanup_needed(self) -> bool:
        """Check if cache cleanup is needed based on configuration.

        Returns:
            True if cleanup is needed, False otherwise
        """
        if not self.config.get("cache.auto_cleanup", True):
            return False

        cache_size = self.get_cache_size()
        threshold_mb = self.config.get("cache.cleanup_threshold_mb", 800)

        return cache_size["total_mb"] > threshold_mb

    def cleanup_old_files(self, max_age_days: int | None = None) -> dict[str, int]:
        """Clean up old cache files based on age.

        Args:
            max_age_days: Maximum age in days. If None, uses config value

        Returns:
            Dictionary with cleanup statistics
        """
        if max_age_days is None:
            max_age_days = self.config.get("cache.max_age_days", 30)

        cutoff_time = time.time() - (max_age_days * 24 * 60 * 60)

        stats = {
            "files_removed": 0,
            "bytes_freed": 0,
            "downloads_cleaned": 0,
            "builds_cleaned": 0,
        }

        try:
            # Clean downloads directory
            if self.downloads_dir.exists():
                for item in self.downloads_dir.rglob("*"):
                    if item.is_file():
                        try:
                            if item.stat().st_mtime < cutoff_time:
                                size = item.stat().st_size
                                item.unlink()
                                stats["files_removed"] += 1
                                stats["bytes_freed"] += size
                                stats["downloads_cleaned"] += 1
                                logger.debug(f"Removed old download: {item}")
                        except (OSError, FileNotFoundError):
                            pass

            # Clean builds directory
            if self.builds_dir.exists():
                for item in self.builds_dir.rglob("*"):
                    if item.is_file():
                        try:
                            if item.stat().st_mtime < cutoff_time:
                                size = item.stat().st_size
                                item.unlink()
                                stats["files_removed"] += 1
                                stats["bytes_freed"] += size
                                stats["builds_cleaned"] += 1
                                logger.debug(f"Removed old build: {item}")
                        except (OSError, FileNotFoundError):
                            pass

            # Clean up empty directories
            self.dir_manager.cleanup_empty_directories()

            if stats["files_removed"] > 0:
                logger.info(
                    f"Cache cleanup: removed {stats['files_removed']} files, "
                    f"freed {round(stats['bytes_freed'] / (1024 * 1024), 2)} MB",
                )

            return stats

        except Exception as e:
            logger.error(f"Failed to cleanup old cache files: {e}")
            return stats

    def cleanup_by_size(self, target_size_mb: int | None = None) -> dict[str, int]:
        """Clean up cache files to reach target size by removing oldest files first.

        Args:
            target_size_mb: Target cache size in MB. If None, uses config value

        Returns:
            Dictionary with cleanup statistics
        """
        if target_size_mb is None:
            max_size_mb = self.config.get("cache.max_size_mb", 1024)
            target_size_mb = int(max_size_mb * 0.8)  # Clean to 80% of max size

        current_size = self.get_cache_size()

        if current_size["total_mb"] <= target_size_mb:
            return {
                "files_removed": 0,
                "bytes_freed": 0,
                "downloads_cleaned": 0,
                "builds_cleaned": 0,
            }

        target_bytes = target_size_mb * 1024 * 1024
        bytes_to_remove = current_size["total_bytes"] - target_bytes

        stats = {
            "files_removed": 0,
            "bytes_freed": 0,
            "downloads_cleaned": 0,
            "builds_cleaned": 0,
        }

        try:
            # Get all cache files sorted by modification time (oldest first)
            cache_files = []

            for cache_dir, cache_type in [
                (self.downloads_dir, "downloads"),
                (self.builds_dir, "builds"),
            ]:
                if cache_dir.exists():
                    for item in cache_dir.rglob("*"):
                        if item.is_file():
                            try:
                                stat_info = item.stat()
                                cache_files.append(
                                    {
                                        "path": item,
                                        "size": stat_info.st_size,
                                        "mtime": stat_info.st_mtime,
                                        "type": cache_type,
                                    },
                                )
                            except (OSError, FileNotFoundError):
                                pass

            # Sort by modification time (oldest first)
            cache_files.sort(key=lambda x: x["mtime"])

            # Remove files until target size is reached
            bytes_removed = 0
            for file_info in cache_files:
                if bytes_removed >= bytes_to_remove:
                    break

                try:
                    file_info["path"].unlink()
                    bytes_removed += file_info["size"]
                    stats["files_removed"] += 1
                    stats["bytes_freed"] += file_info["size"]

                    if file_info["type"] == "downloads":
                        stats["downloads_cleaned"] += 1
                    else:
                        stats["builds_cleaned"] += 1

                    logger.debug(
                        f"Removed cache file for size limit: {file_info['path']}",
                    )

                except (OSError, FileNotFoundError):
                    pass

            # Clean up empty directories
            self.dir_manager.cleanup_empty_directories()

            if stats["files_removed"] > 0:
                logger.info(
                    f"Size-based cleanup: removed {stats['files_removed']} files, "
                    f"freed {round(stats['bytes_freed'] / (1024 * 1024), 2)} MB",
                )

            return stats

        except Exception as e:
            logger.error(f"Failed to cleanup cache by size: {e}")
            return stats

    def clear_cache(self, cache_type: str = "all") -> dict[str, int]:
        """Clear cache completely or specific type.

        Args:
            cache_type: Type of cache to clear ('all', 'downloads', 'builds')

        Returns:
            Dictionary with cleanup statistics
        """
        stats = {
            "files_removed": 0,
            "bytes_freed": 0,
            "downloads_cleaned": 0,
            "builds_cleaned": 0,
        }

        try:
            dirs_to_clear = []

            if cache_type in ("all", "downloads") and self.downloads_dir.exists():
                dirs_to_clear.append((self.downloads_dir, "downloads"))

            if cache_type in ("all", "builds") and self.builds_dir.exists():
                dirs_to_clear.append((self.builds_dir, "builds"))

            for cache_dir, dir_type in dirs_to_clear:
                for item in cache_dir.rglob("*"):
                    if item.is_file():
                        try:
                            size = item.stat().st_size
                            item.unlink()
                            stats["files_removed"] += 1
                            stats["bytes_freed"] += size

                            if dir_type == "downloads":
                                stats["downloads_cleaned"] += 1
                            else:
                                stats["builds_cleaned"] += 1

                        except (OSError, FileNotFoundError):
                            pass

            # Clean up empty directories
            self.dir_manager.cleanup_empty_directories()

            if stats["files_removed"] > 0:
                logger.info(
                    f"Cache cleared ({cache_type}): removed {stats['files_removed']} files, "
                    f"freed {round(stats['bytes_freed'] / (1024 * 1024), 2)} MB",
                )

            return stats

        except Exception as e:
            logger.error(f"Failed to clear cache: {e}")
            return stats

    def auto_cleanup(self) -> dict[str, int]:
        """Perform automatic cache cleanup based on configuration.

        Returns:
            Dictionary with cleanup statistics
        """
        if not self.config.get("cache.auto_cleanup", True):
            logger.debug("Auto cleanup disabled")
            return {
                "files_removed": 0,
                "bytes_freed": 0,
                "downloads_cleaned": 0,
                "builds_cleaned": 0,
            }

        # First try cleanup by age
        age_stats = self.cleanup_old_files()

        # Then check if size-based cleanup is needed
        size_stats = {
            "files_removed": 0,
            "bytes_freed": 0,
            "downloads_cleaned": 0,
            "builds_cleaned": 0,
        }
        if self.is_cleanup_needed():
            size_stats = self.cleanup_by_size()

        # Combine statistics
        combined_stats = {
            "files_removed": age_stats["files_removed"] + size_stats["files_removed"],
            "bytes_freed": age_stats["bytes_freed"] + size_stats["bytes_freed"],
            "downloads_cleaned": age_stats["downloads_cleaned"]
            + size_stats["downloads_cleaned"],
            "builds_cleaned": age_stats["builds_cleaned"]
            + size_stats["builds_cleaned"],
        }

        return combined_stats

    def get_cache_info(self) -> dict[str, Any]:
        """Get comprehensive cache information.

        Returns:
            Dictionary with complete cache information
        """
        try:
            size_info = self.get_cache_size()
            max_size_mb = self.config.get("cache.max_size_mb", 1024)
            max_age_days = self.config.get("cache.max_age_days", 30)
            auto_cleanup = self.config.get("cache.auto_cleanup", True)

            return {
                "size": size_info,
                "limits": {
                    "max_size_mb": max_size_mb,
                    "max_age_days": max_age_days,
                    "cleanup_threshold_mb": self.config.get(
                        "cache.cleanup_threshold_mb", 800,
                    ),
                },
                "settings": {
                    "auto_cleanup": auto_cleanup,
                    "enable_compression": self.config.get(
                        "cache.enable_compression", True,
                    ),
                },
                "status": {
                    "cleanup_needed": self.is_cleanup_needed(),
                    "usage_percentage": (
                        round((size_info["total_mb"] / max_size_mb) * 100, 1)
                        if max_size_mb > 0
                        else 0
                    ),
                },
                "paths": {
                    "cache_dir": str(self.cache_dir),
                    "downloads_dir": str(self.downloads_dir),
                    "builds_dir": str(self.builds_dir),
                },
            }

        except Exception as e:
            logger.error(f"Failed to get cache info: {e}")
            return {}


class ConfigurationCLI:
    """CLI commands for configuration management.

    Provides command-line interface for managing user configuration,
    directories, and cache.
    """

    def __init__(self):
        """Initialize configuration CLI."""
        self.config = UserConfig()
        self.dir_manager = DirectoryManager(self.config)
        self.cache_manager = CacheManager(self.config, self.dir_manager)

        # Ensure directory structure exists
        self.dir_manager.create_structure()

    def show_config(self) -> None:
        """Display current configuration."""
        click.echo("📋 Current Configuration")
        click.echo("=" * 50)

        config_data = self.config.get_all()
        self._print_config_section(config_data, level=0)

        click.echo(f"\n📁 Config file: {self.config.config_path}")

    def _print_config_section(self, data: dict[str, Any], level: int = 0) -> None:
        """Recursively print configuration sections."""
        indent = "  " * level

        for key, value in data.items():
            if isinstance(value, dict):
                click.echo(f"{indent}{key}:")
                self._print_config_section(value, level + 1)
            elif isinstance(value, list):
                click.echo(f"{indent}{key}: [{', '.join(map(str, value))}]")
            else:
                click.echo(f"{indent}{key}: {value}")

    def set_config(self, key: str, value: str) -> None:
        """Set configuration value."""
        try:
            # Try to parse value as JSON for proper type conversion
            try:
                parsed_value = json.loads(value)
            except json.JSONDecodeError:
                # If not valid JSON, treat as string
                parsed_value = value

            self.config.set(key, parsed_value)
            click.echo(f"✅ Configuration updated: {key} = {parsed_value}")

        except Exception as e:
            click.echo(f"❌ Failed to set configuration: {e}", err=True)

    def get_config(self, key: str) -> None:
        """Get configuration value."""
        try:
            value = self.config.get(key)
            if value is not None:
                click.echo(f"{key}: {value}")
            else:
                click.echo(f"❌ Configuration key not found: {key}", err=True)

        except Exception as e:
            click.echo(f"❌ Failed to get configuration: {e}", err=True)

    def reset_config(self) -> None:
        """Reset configuration to defaults."""
        if click.confirm("⚠️  Reset configuration to defaults? This cannot be undone."):
            try:
                # Create backup first
                backup_path = self.config.backup("pre_reset_backup")
                click.echo(f"📦 Backup created: {backup_path}")

                self.config.reset_to_defaults()
                click.echo("✅ Configuration reset to defaults")

            except Exception as e:
                click.echo(f"❌ Failed to reset configuration: {e}", err=True)
        else:
            click.echo("Reset cancelled")

    def backup_config(self, name: str | None = None) -> None:
        """Create configuration backup."""
        try:
            backup_path = self.config.backup(name)
            click.echo(f"✅ Configuration backed up to: {backup_path}")

        except Exception as e:
            click.echo(f"❌ Failed to backup configuration: {e}", err=True)

    def restore_config(self, backup_path: str) -> None:
        """Restore configuration from backup."""
        if click.confirm(
            f"⚠️  Restore configuration from {backup_path}? Current config will be backed up.",
        ):
            try:
                self.config.restore(backup_path)
                click.echo("✅ Configuration restored successfully")

            except Exception as e:
                click.echo(f"❌ Failed to restore configuration: {e}", err=True)
        else:
            click.echo("Restore cancelled")

    def export_config(self, export_path: str) -> None:
        """Export configuration to file."""
        try:
            self.config.export_config(export_path)
            click.echo(f"✅ Configuration exported to: {export_path}")

        except Exception as e:
            click.echo(f"❌ Failed to export configuration: {e}", err=True)

    def import_config(self, import_path: str, merge: bool = True) -> None:
        """Import configuration from file."""
        action = "merge with" if merge else "replace"

        if click.confirm(
            f"⚠️  Import configuration from {import_path} and {action} current config?",
        ):
            try:
                self.config.import_config(import_path, merge)
                click.echo("✅ Configuration imported successfully")

            except Exception as e:
                click.echo(f"❌ Failed to import configuration: {e}", err=True)
        else:
            click.echo("Import cancelled")

    def show_directories(self) -> None:
        """Display directory information."""
        click.echo("📁 Directory Structure")
        click.echo("=" * 50)

        status = self.dir_manager.verify_structure()
        usage = self.dir_manager.get_disk_usage()

        for dir_type, exists in status.items():
            status_icon = "✅" if exists else "❌"
            dir_path = usage.get(dir_type, {}).get("path", "N/A")
            size_mb = usage.get(dir_type, {}).get("size_mb", 0)
            file_count = usage.get(dir_type, {}).get("file_count", 0)

            click.echo(f"{status_icon} {dir_type}: {dir_path}")
            if exists:
                click.echo(f"   Size: {size_mb} MB, Files: {file_count}")

    def create_directories(self) -> None:
        """Create directory structure."""
        try:
            created = self.dir_manager.create_structure()
            click.echo("✅ Directory structure created:")

            for dir_type, path in created.items():
                click.echo(f"   {dir_type}: {path}")

        except Exception as e:
            click.echo(f"❌ Failed to create directory structure: {e}", err=True)

    def show_cache_info(self) -> None:
        """Display cache information."""
        click.echo("💾 Cache Information")
        click.echo("=" * 50)

        cache_info = self.cache_manager.get_cache_info()

        if not cache_info:
            click.echo("❌ Failed to retrieve cache information")
            return

        # Size information
        size = cache_info.get("size", {})
        click.echo(f"Total cache size: {size.get('total_mb', 0)} MB")
        click.echo(f"Downloads cache: {size.get('downloads_mb', 0)} MB")
        click.echo(f"Builds cache: {size.get('builds_mb', 0)} MB")

        # Limits and status
        limits = cache_info.get("limits", {})
        status = cache_info.get("status", {})

        click.echo("\nCache limits:")
        click.echo(f"  Max size: {limits.get('max_size_mb', 0)} MB")
        click.echo(f"  Max age: {limits.get('max_age_days', 0)} days")
        click.echo(f"  Cleanup threshold: {limits.get('cleanup_threshold_mb', 0)} MB")

        click.echo("\nStatus:")
        usage_pct = status.get("usage_percentage", 0)
        click.echo(f"  Usage: {usage_pct}%")

        cleanup_needed = status.get("cleanup_needed", False)
        cleanup_icon = "⚠️" if cleanup_needed else "✅"
        click.echo(
            f"  {cleanup_icon} Cleanup needed: {'Yes' if cleanup_needed else 'No'}",
        )

    def cleanup_cache(self, cache_type: str = "auto") -> None:
        """Clean up cache."""
        try:
            if cache_type == "auto":
                stats = self.cache_manager.auto_cleanup()
                click.echo("✅ Automatic cache cleanup completed")
            elif cache_type in ["all", "downloads", "builds"]:
                if click.confirm(
                    f"⚠️  Clear {cache_type} cache? This cannot be undone.",
                ):
                    stats = self.cache_manager.clear_cache(cache_type)
                    click.echo(f"✅ {cache_type.title()} cache cleared")
                else:
                    click.echo("Cache clear cancelled")
                    return
            else:
                click.echo(f"❌ Invalid cache type: {cache_type}", err=True)
                return

            if stats["files_removed"] > 0:
                click.echo(f"   Files removed: {stats['files_removed']}")
                click.echo(
                    f"   Space freed: {round(stats['bytes_freed'] / (1024 * 1024), 2)} MB",
                )
            else:
                click.echo("   No files needed to be removed")

        except Exception as e:
            click.echo(f"❌ Failed to cleanup cache: {e}", err=True)

    def validate_config(self) -> None:
        """Validate current configuration."""
        try:
            # Get current config and validate
            current_config = self.config.get_all()
            self.config._validate_config(current_config)

            # Verify directory structure
            dir_status = self.dir_manager.verify_structure()
            all_dirs_exist = all(dir_status.values())

            click.echo("🔍 Configuration Validation")
            click.echo("=" * 50)
            click.echo("✅ Configuration syntax: Valid")

            dir_icon = "✅" if all_dirs_exist else "⚠️"
            click.echo(
                f"{dir_icon} Directory structure: {'Complete' if all_dirs_exist else 'Incomplete'}",
            )

            if not all_dirs_exist:
                click.echo("\nMissing directories:")
                for dir_type, exists in dir_status.items():
                    if not exists:
                        click.echo(f"   ❌ {dir_type}")
                click.echo(
                    "\n💡 Run 'treesitter-chunker config create-dirs' to create missing directories",
                )

            # Check cache status
            cache_info = self.cache_manager.get_cache_info()
            if cache_info:
                usage_pct = cache_info.get("status", {}).get("usage_percentage", 0)
                if usage_pct > 90:
                    click.echo("⚠️  Cache usage is high (>90%)")
                    click.echo("💡 Consider running cache cleanup")

            click.echo("\n✅ Overall configuration status: Healthy")

        except Exception as e:
            click.echo("❌ Configuration Validation Failed")
            click.echo(f"Error: {e}")


# CLI command group setup for integration with main CLI
@click.group(name="config")
def config_cli():
    """Configuration management commands."""


@config_cli.command()
def show():
    """Show current configuration."""
    cli = ConfigurationCLI()
    cli.show_config()


@config_cli.command()
@click.argument("key")
@click.argument("value")
def set(key, value):
    """Set configuration value using dot notation."""
    cli = ConfigurationCLI()
    cli.set_config(key, value)


@config_cli.command()
@click.argument("key")
def get(key):
    """Get configuration value using dot notation."""
    cli = ConfigurationCLI()
    cli.get_config(key)


@config_cli.command()
def reset():
    """Reset configuration to defaults."""
    cli = ConfigurationCLI()
    cli.reset_config()


@config_cli.command()
@click.option("--name", help="Backup name (optional)")
def backup(name):
    """Create configuration backup."""
    cli = ConfigurationCLI()
    cli.backup_config(name)


@config_cli.command()
@click.argument("backup_path")
def restore(backup_path):
    """Restore configuration from backup."""
    cli = ConfigurationCLI()
    cli.restore_config(backup_path)


@config_cli.command()
@click.argument("export_path")
def export(export_path):
    """Export configuration to file."""
    cli = ConfigurationCLI()
    cli.export_config(export_path)


@config_cli.command()
@click.argument("import_path")
@click.option("--replace", is_flag=True, help="Replace instead of merge")
def import_config(import_path, replace):
    """Import configuration from file."""
    cli = ConfigurationCLI()
    cli.import_config(import_path, not replace)


@config_cli.command()
def dirs():
    """Show directory information."""
    cli = ConfigurationCLI()
    cli.show_directories()


@config_cli.command(name="create-dirs")
def create_dirs():
    """Create directory structure."""
    cli = ConfigurationCLI()
    cli.create_directories()


@config_cli.command(name="cache-info")
def cache_info():
    """Show cache information."""
    cli = ConfigurationCLI()
    cli.show_cache_info()


@config_cli.command()
@click.argument("cache_type", default="auto")
def cleanup(cache_type):
    """Clean up cache. TYPE can be: auto, all, downloads, builds."""
    cli = ConfigurationCLI()
    cli.cleanup_cache(cache_type)


@config_cli.command()
def validate():
    """Validate configuration and directory structure."""
    cli = ConfigurationCLI()
    cli.validate_config()


if __name__ == "__main__":
    config_cli()
