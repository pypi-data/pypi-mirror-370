"""Interactive chat interfaces, which are superset to chat templates.

"""
__author__ = 'Paul Landes'

from dataclasses import dataclass
from transformers import PreTrainedTokenizer, PreTrainedModel
from .generate import GeneratorResource


@dataclass
class LlamaGeneratorResource(GeneratorResource):
    """There are 4 different roles that are supported by Llama text models:

    * ``system``: Sets the context in which to interact with the AI model. It
                  typically includes rules, guidelines, or necessary information
                  that help the model respond effectively.

    * ``user``: Represents the human interacting with the model. It includes the
                inputs, commands, and questions to the model.

    * ``ipython``: A new role introduced in Llama 3.1. Semantically, this role
                   means "tool". This role is used to mark messages with the
                   output of a tool call when sent back to the model from the
                   executor.

    * ``assistant``: Represents the response generated by the AI model based on
                     the context provided in the system, ipython and user
                     prompts.

    """
    def configure_tokenizer(self, tokenizer: PreTrainedTokenizer):
        tokenizer.pad_token = '<|finetune_right_pad_id|>'

    def configure_model(self, model: PreTrainedModel):
        model.config.pad_token_id = model.config.eos_token_id
