# ğŸ›¡ï¸ Trustra â€” Trust-First AutoML Framework

> **"One `fit()`. Full trust."**

Trustra is a **next-generation, open-source AutoML framework** that doesnâ€™t just maximize accuracy â€” it **ensures model integrity** by automatically detecting **data leakage, bias, drift, and instability** â€” and generating **auditable trust reports**.

Unlike traditional AutoML tools that optimize only for performance, **Trustra enforces responsibility by design**.

---

## ğŸš€ Why Trustra?

Most AutoML tools (like H2O, AutoGluon, or SageMaker) focus on **"How accurate is the model?"**  
Trustra asks:  
> â“ **"Can we trust this model?"**  
> â“ **"Is it fair?"**  
> â“ **"Is it safe for production?"**

We built Trustra because:
- Real-world models fail due to **hidden data issues**, not poor algorithms.
- Bias goes undetected until it harms users.
- Drift creeps in silently.
- Teams waste weeks on manual validation.

ğŸ‘‰ **Trustra automates trust.**

---

## âœ¨ Key Features

| Feature | Description |
|-------|-------------|
| ğŸ” **Data Quality Checks** | Detects missing values, duplicates, class imbalance, and **data leakage** (e.g., target leakage) |
| âš–ï¸ **Fairness Audit** | Automatically audits bias across sensitive features (e.g., gender, race) using **Demographic Parity & Equalized Odds** |
| ğŸ“‰ **Drift Detection** | Flags feature drift between train/validation using KS test & PSI |
| ğŸ§  **Auto Model Selection** | Uses **Optuna** to find the best model (Logistic Regression, Random Forest, Gradient Boosting) and hyperparameters |
| ğŸ“Š **Trust Report** | Generates a **self-contained HTML report** with model performance, fairness metrics, and detected issues |
| ğŸš€ **Simple API** | Just `model.fit(X_train, y_train)` â€” no complex pipelines |
| ğŸ’¡ **Explainability Ready** | Designed for integration with SHAP/LIME (coming soon) |

---

## ğŸ† Results on Synthetic Data

| Metric | Result |
|-------|--------|
| **CV AUC** | 0.960 |
| **Bias (DPD)** | 0.051 (Low) |
| **Data Issues Found** | 0 |
| **Training Time** | < 10 seconds |
| **Fairness Audit** | âœ… Passed |

> âœ… Generated fully automatic, no manual checks.

---

## ğŸŒŸ What Makes Trustra Unique?

| Trustra | Traditional AutoML |
|--------|-------------------|
| Built-in **fairness** | Fairness? You code it. |
| Auto **data leakage** detection | Silent failure risk |
| **Trust report** generated | Just predictions |
| **Drift & imbalance** checks | Ignored |
| One `fit()` â†’ full audit | Manual validation needed |
| **Open, transparent, auditable** | Black-box models |

> Trustra is **not just AutoML â€” itâ€™s Responsible AI automation**.

---

## ğŸ§© How It Works

```python
from trustra import TrustRA

# Initialize with target and sensitive features
model = TrustRA(target="income", sensitive_features=["gender"])

# Run full trust-first pipeline
model.fit(X_train, y_train, X_val, y_val)

# Get predictions
preds = model.predict(X_val)

# Report saved as: trustra_report.html
```
---
## Pipeline Stages:
> Data Validation â†’ Check quality, leakage, duplicates
> Fairness Audit â†’ Measure DPD/EOD
> Model Training â†’ Optuna + Cross-validation
> Report Generation â†’ Interactive HTML with Plotly
---

## ğŸ“¦ Installation
```bash
# Clone the repo
git clone https://github.com/Devansh-567/Trustra---Trust-First-AutoML-Framework.git
cd Trustra---Trust-First-AutoML-Framework

# Install in editable mode
pip install -e .

# Optional: Install dependencies
pip install -r requirements.txt
```
---

## ğŸ§ª Example Usage
```bash
python examples/binary_classification.py
```

### Generates: 
> âœ… ```bash trustra_report.html```
> âœ… Console metrics (AUC, fairness, issues)
---

## ğŸ“„ License
MIT License
Copyright Â© 2025 Devansh

---

## ğŸ‘¤ Author
> Devansh Singh
> devansh.jay.singh@gmail.com
> "Built Trustra to make AI trustworthy, one model at a time."
