Metadata-Version: 2.4
Name: ntt-ai-observability-exporter
Version: 0.1.4
Summary: NTT AI Observability Exporter for Azure Monitor OpenTelemetry in AI Foundry projects
Author-email: Anand Vaibhav Singh <anandvaibhav-singh_nttltd@example.com>
License: MIT
Project-URL: Homepage, https://github.com/nttlimited/ntt-ai-observability-exporter
Project-URL: Bug Tracker, https://github.com/nttlimited/ntt-ai-observability-exporter/issues
Keywords: ntt,azure,telemetry,opentelemetry,monitoring,ai,observability
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: azure-monitor-opentelemetry>=1.0.0b15
Requires-Dist: azure-core-tracing-opentelemetry==1.0.0b12
Requires-Dist: opentelemetry-sdk==1.31.1
Requires-Dist: azure-monitor-opentelemetry-exporter>=1.0.0b37
Requires-Dist: opentelemetry-api>=1.15.0
Requires-Dist: opentelemetry-instrumentation>=0.38b0
Dynamic: license-file

# NTT AI Observability Exporter

A specialized telemetry exporter for NTT AI Foundry projects using Azure Monitor OpenTelemetry. This package simplifies telemetry setup for AI applications built with Azure services.

## Features

- Automatic instrumentation of Azure SDK libraries
- Simplified configuration for Azure Monitor OpenTelemetry
- Specialized support for Semantic Kernel telemetry
- Compatible with Azure AI Foundry projects

## Installation

```bash
# Using pip
pip install ntt-ai-observability-exporter

# Using uv
uv pip install ntt-ai-observability-exporter
```
## Updating Your Package Documentation

Make sure to add a note in your package documentation (such as README.md) about the dependencies:

```markdown
## Dependencies

This package depends on:
- azure-monitor-opentelemetry (>=1.0.0)
- opentelemetry-sdk (>=1.15.0)

These dependencies will be automatically installed when you install the package via pip.

```bash
# Using pip
pip install ntt-ai-observability-exporter

# Using uv
uv pip install ntt-ai-observability-exporter
```

## Usage

### Simple Usage - One Line Setup

```python
from ntt_ai_observability_exporter import configure_telemetry

# That's it! This single line configures all telemetry
configure_telemetry()

# Now you can use your AI components normally - telemetry is automatic
```

### Configuration Options

```python
# Explicit configuration
configure_telemetry(
    connection_string="InstrumentationKey=your-key;IngestionEndpoint=your-endpoint",
    customer_name="your-customer",
    agent_name="your-agent"
)

```

## What Gets Instrumented Automatically

The Azure Monitor OpenTelemetry package automatically instruments:

- **Azure SDK libraries** (including azure.ai.openai)
- **HTTP client libraries** (requests, aiohttp)

This means when you use Azure AI Foundry components, telemetry is captured without any additional code.

## Configuration Parameters

- `connection_string`: Azure Monitor connection string
- `customer_name`: Maps to `service.name` in OpenTelemetry resource
- `agent_name`: Maps to `service.instance.id` in OpenTelemetry resource

## Environment Variables

You can set these environment variables:

- `AZURE_MONITOR_CONNECTION_STRING`: The connection string for Azure Monitor
- `CUSTOMER_NAME`: Maps to `service.name` in OpenTelemetry resource
- `AGENT_NAME`: Maps to `service.instance.id` in OpenTelemetry resource



## Telemetry Types Captured

The configuration captures:

- **Traces**: Request flows and operations
- **Metrics**: Performance measurements 
- **Logs**: When integrated with Python logging

## Example in Azure AI Foundry Project

```python
# Import the NTT AI Observability Exporter
from ntt_ai_observability_exporter import configure_telemetry

# Configure telemetry with your project details
configure_telemetry(
    connection_string="InstrumentationKey=xxx;IngestionEndpoint=https://westeurope-5.in.applicationinsights.azure.com/",
    customer_name="customer-name-foundry",
    agent_name="ai-foundry-agent"
)

# Now use Azure AI components as normal - telemetry is automatic
from azure.ai.assistant import AssistantClient

client = AssistantClient(...)
# All operations are automatically instrumented
```


## Semantic Kernel Telemetry Support

For applications using Semantic Kernel, use the specialized configuration function:

```python
from ntt_ai_observability_exporter import configure_semantic_kernel_telemetry

# Configure Semantic Kernel telemetry BEFORE creating any Kernel instances
configure_semantic_kernel_telemetry(
    connection_string="your_connection_string",
    customer_name="your_customer_name",
    agent_name="your_agent_name"
)

# Then create and use your Semantic Kernel
from semantic_kernel import Kernel
kernel = Kernel()
# ... rest of your code
```
