apiVersion: agent/v1
kind: AgentSpec
metadata:
  name: QA Engineer Assistant
  id: qa_engineer
  namespace: software
  version: 1.0.0
  agent_type: Supervised
  level: oracles
  description: An agent that helps design and execute effective test plans.
spec:
  language_model:
    location: local
    provider: ollama
    model: llama3.2:1b
    api_base: http://localhost:11434
  persona:
    name: QABot
    role: QA Engineer
    goal: Design and execute effective test plans
    traits:
    - analytical
    - detail-oriented
    - thorough
  tasks:
  - name: create_test_plan
    instruction: You are a Quality Assurance Engineer. Your goal is to ensure software
      quality. Create a high-level test plan including test cases for the given feature.
    inputs:
    - name: feature_specification
      type: str
      description: The feature specification to be tested.
      required: true
    outputs:
    - name: test_plan
      type: str
      description: A high-level test plan with key test cases.
  agentflow:
  - name: generate_test_plan
    type: Generate
    task: create_test_plan
  evaluation:
    builtin_metrics:
    - name: answer_exact_match
      threshold: 1.0
  feature_specifications:
    scenarios:
      # BDD Scenario 1: Test Plan Creation
      - name: "comprehensive_test_plan_creation"
        description: "Given a complex feature specification, the agent should generate a comprehensive test plan with multiple test categories"
        input:
          feature_specification: "User authentication system with login, registration, password reset, and two-factor authentication. System should handle rate limiting and account lockouts."
        expected_output:
          test_plan: |
            **Test Plan: User Authentication System**
            
            **1. Functional Testing**
            - User Registration: Valid/invalid email formats, password strength requirements
            - User Login: Correct/incorrect credentials, case sensitivity
            - Password Reset: Valid email flow, invalid email handling, link expiration
            - Two-Factor Authentication: Code generation, verification, backup codes
            
            **2. Security Testing**
            - Rate Limiting: Multiple failed login attempts, API request throttling
            - Account Lockout: Brute force protection, unlock mechanisms
            - SQL Injection: Input validation on all authentication fields
            - Session Management: Token expiration, concurrent sessions
            
            **3. Performance Testing**
            - Load Testing: Concurrent user logins, system response under stress
            - Database Performance: Authentication queries optimization
            
            **4. Usability Testing**
            - Error Messages: Clear, actionable feedback for users
            - User Flow: Intuitive navigation through authentication process

      # BDD Scenario 2: Bug Report Analysis
      - name: "bug_report_analysis"
        description: "When analyzing a bug report, the agent should provide structured analysis with reproduction steps and severity assessment"
        input:
          feature_specification: "Bug Report: 'Users can't upload files larger than 5MB on mobile devices. Desktop works fine. Error message says \"Upload failed\" with no details.'"
        expected_output:
          test_plan: |
            **Bug Analysis: File Upload Issue on Mobile**
            
            **Severity:** High (Core functionality affected on major platform)
            
            **Reproduction Steps:**
            1. Open application on mobile device
            2. Navigate to file upload section
            3. Select file larger than 5MB
            4. Attempt upload
            5. Observe error message
            
            **Test Cases to Validate:**
            - File size validation: Test exact 5MB threshold
            - Error handling: Verify descriptive error messages
            - Platform compatibility: Compare mobile vs desktop behavior
            - File type verification: Test various file formats
            - Network conditions: Test on different connection speeds
            
            **Additional Investigation:**
            - Check mobile-specific file size limits
            - Verify API endpoint differences between platforms
            - Test on different mobile browsers/apps

      # BDD Scenario 3: API Testing Strategy
      - name: "api_testing_strategy"
        description: "Given an API specification, the agent should create a comprehensive API testing approach"
        input:
          feature_specification: "REST API for e-commerce product catalog: GET /products (list), POST /products (create), PUT /products/{id} (update), DELETE /products/{id} (delete). Requires authentication and supports pagination."
        expected_output:
          test_plan: |
            **API Testing Plan: E-commerce Product Catalog**
            
            **1. Endpoint Testing**
            - GET /products: Valid requests, pagination parameters, filtering
            - POST /products: Valid product creation, required fields validation
            - PUT /products/{id}: Product updates, partial updates, non-existent IDs
            - DELETE /products/{id}: Successful deletion, authorization checks
            
            **2. Authentication Testing**
            - Valid tokens: Successful API access
            - Invalid tokens: Proper 401 responses
            - Expired tokens: Token refresh flow
            - No authentication: Proper rejection
            
            **3. Data Validation**
            - Input validation: Required fields, data types, format validation
            - Boundary testing: Max/min values, string lengths
            - Malformed requests: Invalid JSON, missing headers
            
            **4. Error Handling**
            - HTTP status codes: 200, 201, 400, 401, 404, 500
            - Error response format: Consistent error structure
            - Rate limiting: 429 responses for excessive requests

      # BDD Scenario 4: Test Automation Framework
      - name: "test_automation_framework"
        description: "When asked to design test automation, the agent should provide a structured framework approach"
        input:
          feature_specification: "Design test automation framework for a web application with user management, inventory tracking, and reporting modules. Need both UI and API test coverage."
        expected_output:
          test_plan: |
            **Test Automation Framework Design**
            
            **1. Framework Architecture**
            - Page Object Model: Separate page classes for UI elements
            - Data-Driven Testing: External test data management
            - Hybrid Framework: Keyword + Data-driven approach
            - Reporting: Detailed test execution reports
            
            **2. Test Layers**
            - Unit Tests: Individual component testing
            - API Tests: Backend service validation
            - Integration Tests: Module interaction testing
            - UI Tests: End-to-end user workflows
            
            **3. Tool Selection**
            - UI Automation: Selenium WebDriver with Python/Java
            - API Testing: RestAssured or Postman/Newman
            - Test Runner: TestNG or pytest
            - CI/CD Integration: Jenkins or GitHub Actions
            
            **4. Test Organization**
            - Smoke Tests: Critical path validation
            - Regression Suite: Full feature coverage
            - Performance Tests: Load and stress testing
            - Cross-browser Testing: Multiple browser support

      # BDD Scenario 5: Performance Testing Plan
      - name: "performance_testing_plan"
        description: "Given performance requirements, the agent should create a detailed performance testing strategy"
        input:
          feature_specification: "Web application should handle 1000 concurrent users, page load time under 3 seconds, API response time under 500ms. System includes user authentication, product search, and checkout process."
        expected_output:
          test_plan: |
            **Performance Testing Plan**
            
            **1. Performance Requirements**
            - Concurrent Users: 1000 simultaneous users
            - Page Load Time: < 3 seconds
            - API Response Time: < 500ms
            - System Uptime: 99.9% availability
            
            **2. Test Types**
            - Load Testing: Normal expected load (1000 users)
            - Stress Testing: Beyond normal capacity (1500+ users)
            - Spike Testing: Sudden load increases
            - Volume Testing: Large data sets
            
            **3. Key Scenarios**
            - User Login: Authentication under load
            - Product Search: Database query performance
            - Checkout Process: Transaction processing under stress
            - Concurrent Sessions: Multiple user interactions
            
            **4. Monitoring & Metrics**
            - Response Times: Average, median, 95th percentile
            - Throughput: Requests per second
            - Resource Utilization: CPU, memory, disk I/O
            - Error Rates: Failed requests percentage
            
            **5. Tools & Environment**
            - JMeter or LoadRunner for load generation
            - Application Performance Monitoring (APM)
            - Database performance monitoring
            - Production-like test environment
  optimization:
    strategy: few_shot_bootstrapping
    metric: answer_correctness
    metric_threshold: 0.7
    few_shot_bootstrapping_config:
      max_bootstrapped_demos: 4
      max_rounds: 1
