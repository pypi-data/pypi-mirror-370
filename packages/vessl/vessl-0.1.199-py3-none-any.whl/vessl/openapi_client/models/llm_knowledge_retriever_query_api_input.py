# coding: utf-8

"""
    Aron API

    No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)  # noqa: E501

    The version of the OpenAPI document: 1.0.0
    Generated by: https://openapi-generator.tech
"""


try:
    from inspect import getfullargspec
except ImportError:
    from inspect import getargspec as getfullargspec
import pprint
import re  # noqa: F401
import six

from vessl.openapi_client.configuration import Configuration


class LLMKnowledgeRetrieverQueryAPIInput(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'collection_name': 'str',
        'embedding_model': 'LlmEmbeddingModelRequest',
        'prompt': 'str',
        'top_k': 'int',
        'vector_db': 'LlmVectorDBRequest'
    }

    attribute_map = {
        'collection_name': 'collection_name',
        'embedding_model': 'embedding_model',
        'prompt': 'prompt',
        'top_k': 'top_k',
        'vector_db': 'vector_db'
    }

    def __init__(self, collection_name=None, embedding_model=None, prompt=None, top_k=None, vector_db=None, local_vars_configuration=None):  # noqa: E501
        """LLMKnowledgeRetrieverQueryAPIInput - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration.get_default_copy()
        self.local_vars_configuration = local_vars_configuration

        self._collection_name = None
        self._embedding_model = None
        self._prompt = None
        self._top_k = None
        self._vector_db = None
        self.discriminator = None

        if collection_name is not None:
            self.collection_name = collection_name
        if embedding_model is not None:
            self.embedding_model = embedding_model
        if prompt is not None:
            self.prompt = prompt
        if top_k is not None:
            self.top_k = top_k
        if vector_db is not None:
            self.vector_db = vector_db

    @property
    def collection_name(self):
        """Gets the collection_name of this LLMKnowledgeRetrieverQueryAPIInput.  # noqa: E501


        :return: The collection_name of this LLMKnowledgeRetrieverQueryAPIInput.  # noqa: E501
        :rtype: str
        """
        return self._collection_name

    @collection_name.setter
    def collection_name(self, collection_name):
        """Sets the collection_name of this LLMKnowledgeRetrieverQueryAPIInput.


        :param collection_name: The collection_name of this LLMKnowledgeRetrieverQueryAPIInput.  # noqa: E501
        :type collection_name: str
        """

        self._collection_name = collection_name

    @property
    def embedding_model(self):
        """Gets the embedding_model of this LLMKnowledgeRetrieverQueryAPIInput.  # noqa: E501


        :return: The embedding_model of this LLMKnowledgeRetrieverQueryAPIInput.  # noqa: E501
        :rtype: LlmEmbeddingModelRequest
        """
        return self._embedding_model

    @embedding_model.setter
    def embedding_model(self, embedding_model):
        """Sets the embedding_model of this LLMKnowledgeRetrieverQueryAPIInput.


        :param embedding_model: The embedding_model of this LLMKnowledgeRetrieverQueryAPIInput.  # noqa: E501
        :type embedding_model: LlmEmbeddingModelRequest
        """

        self._embedding_model = embedding_model

    @property
    def prompt(self):
        """Gets the prompt of this LLMKnowledgeRetrieverQueryAPIInput.  # noqa: E501


        :return: The prompt of this LLMKnowledgeRetrieverQueryAPIInput.  # noqa: E501
        :rtype: str
        """
        return self._prompt

    @prompt.setter
    def prompt(self, prompt):
        """Sets the prompt of this LLMKnowledgeRetrieverQueryAPIInput.


        :param prompt: The prompt of this LLMKnowledgeRetrieverQueryAPIInput.  # noqa: E501
        :type prompt: str
        """

        self._prompt = prompt

    @property
    def top_k(self):
        """Gets the top_k of this LLMKnowledgeRetrieverQueryAPIInput.  # noqa: E501


        :return: The top_k of this LLMKnowledgeRetrieverQueryAPIInput.  # noqa: E501
        :rtype: int
        """
        return self._top_k

    @top_k.setter
    def top_k(self, top_k):
        """Sets the top_k of this LLMKnowledgeRetrieverQueryAPIInput.


        :param top_k: The top_k of this LLMKnowledgeRetrieverQueryAPIInput.  # noqa: E501
        :type top_k: int
        """

        self._top_k = top_k

    @property
    def vector_db(self):
        """Gets the vector_db of this LLMKnowledgeRetrieverQueryAPIInput.  # noqa: E501


        :return: The vector_db of this LLMKnowledgeRetrieverQueryAPIInput.  # noqa: E501
        :rtype: LlmVectorDBRequest
        """
        return self._vector_db

    @vector_db.setter
    def vector_db(self, vector_db):
        """Sets the vector_db of this LLMKnowledgeRetrieverQueryAPIInput.


        :param vector_db: The vector_db of this LLMKnowledgeRetrieverQueryAPIInput.  # noqa: E501
        :type vector_db: LlmVectorDBRequest
        """

        self._vector_db = vector_db

    def to_dict(self, serialize=False):
        """Returns the model properties as a dict"""
        result = {}

        def convert(x):
            if hasattr(x, "to_dict"):
                args = getfullargspec(x.to_dict).args
                if len(args) == 1:
                    return x.to_dict()
                else:
                    return x.to_dict(serialize)
            else:
                return x

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            attr = self.attribute_map.get(attr, attr) if serialize else attr
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: convert(x),
                    value
                ))
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], convert(item[1])),
                    value.items()
                ))
            else:
                result[attr] = convert(value)

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, LLMKnowledgeRetrieverQueryAPIInput):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, LLMKnowledgeRetrieverQueryAPIInput):
            return True

        return self.to_dict() != other.to_dict()
