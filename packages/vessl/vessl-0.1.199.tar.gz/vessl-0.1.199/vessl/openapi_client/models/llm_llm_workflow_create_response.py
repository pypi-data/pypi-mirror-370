# coding: utf-8

"""
    Aron API

    No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)  # noqa: E501

    The version of the OpenAPI document: 1.0.0
    Generated by: https://openapi-generator.tech
"""


try:
    from inspect import getfullargspec
except ImportError:
    from inspect import getargspec as getfullargspec
import pprint
import re  # noqa: F401
import six

from vessl.openapi_client.configuration import Configuration


class LlmLLMWorkflowCreateResponse(object):
    """NOTE: This class is auto generated by OpenAPI Generator.
    Ref: https://openapi-generator.tech

    Do not edit the class manually.
    """

    """
    Attributes:
      openapi_types (dict): The key is attribute name
                            and the value is attribute type.
      attribute_map (dict): The key is attribute name
                            and the value is json key in definition.
    """
    openapi_types = {
        'cluster': 'ProtoCluster',
        'initial_revision': 'ProtoLLMWorkflowRevision',
        'model_service': 'ProtoModelService',
        'resource_preset': 'ProtoResourcePreset',
        'workflow': 'ProtoLLMWorkflow'
    }

    attribute_map = {
        'cluster': 'Cluster',
        'initial_revision': 'InitialRevision',
        'model_service': 'ModelService',
        'resource_preset': 'ResourcePreset',
        'workflow': 'Workflow'
    }

    def __init__(self, cluster=None, initial_revision=None, model_service=None, resource_preset=None, workflow=None, local_vars_configuration=None):  # noqa: E501
        """LlmLLMWorkflowCreateResponse - a model defined in OpenAPI"""  # noqa: E501
        if local_vars_configuration is None:
            local_vars_configuration = Configuration.get_default_copy()
        self.local_vars_configuration = local_vars_configuration

        self._cluster = None
        self._initial_revision = None
        self._model_service = None
        self._resource_preset = None
        self._workflow = None
        self.discriminator = None

        if cluster is not None:
            self.cluster = cluster
        if initial_revision is not None:
            self.initial_revision = initial_revision
        if model_service is not None:
            self.model_service = model_service
        if resource_preset is not None:
            self.resource_preset = resource_preset
        if workflow is not None:
            self.workflow = workflow

    @property
    def cluster(self):
        """Gets the cluster of this LlmLLMWorkflowCreateResponse.  # noqa: E501


        :return: The cluster of this LlmLLMWorkflowCreateResponse.  # noqa: E501
        :rtype: ProtoCluster
        """
        return self._cluster

    @cluster.setter
    def cluster(self, cluster):
        """Sets the cluster of this LlmLLMWorkflowCreateResponse.


        :param cluster: The cluster of this LlmLLMWorkflowCreateResponse.  # noqa: E501
        :type cluster: ProtoCluster
        """

        self._cluster = cluster

    @property
    def initial_revision(self):
        """Gets the initial_revision of this LlmLLMWorkflowCreateResponse.  # noqa: E501


        :return: The initial_revision of this LlmLLMWorkflowCreateResponse.  # noqa: E501
        :rtype: ProtoLLMWorkflowRevision
        """
        return self._initial_revision

    @initial_revision.setter
    def initial_revision(self, initial_revision):
        """Sets the initial_revision of this LlmLLMWorkflowCreateResponse.


        :param initial_revision: The initial_revision of this LlmLLMWorkflowCreateResponse.  # noqa: E501
        :type initial_revision: ProtoLLMWorkflowRevision
        """

        self._initial_revision = initial_revision

    @property
    def model_service(self):
        """Gets the model_service of this LlmLLMWorkflowCreateResponse.  # noqa: E501


        :return: The model_service of this LlmLLMWorkflowCreateResponse.  # noqa: E501
        :rtype: ProtoModelService
        """
        return self._model_service

    @model_service.setter
    def model_service(self, model_service):
        """Sets the model_service of this LlmLLMWorkflowCreateResponse.


        :param model_service: The model_service of this LlmLLMWorkflowCreateResponse.  # noqa: E501
        :type model_service: ProtoModelService
        """

        self._model_service = model_service

    @property
    def resource_preset(self):
        """Gets the resource_preset of this LlmLLMWorkflowCreateResponse.  # noqa: E501


        :return: The resource_preset of this LlmLLMWorkflowCreateResponse.  # noqa: E501
        :rtype: ProtoResourcePreset
        """
        return self._resource_preset

    @resource_preset.setter
    def resource_preset(self, resource_preset):
        """Sets the resource_preset of this LlmLLMWorkflowCreateResponse.


        :param resource_preset: The resource_preset of this LlmLLMWorkflowCreateResponse.  # noqa: E501
        :type resource_preset: ProtoResourcePreset
        """

        self._resource_preset = resource_preset

    @property
    def workflow(self):
        """Gets the workflow of this LlmLLMWorkflowCreateResponse.  # noqa: E501


        :return: The workflow of this LlmLLMWorkflowCreateResponse.  # noqa: E501
        :rtype: ProtoLLMWorkflow
        """
        return self._workflow

    @workflow.setter
    def workflow(self, workflow):
        """Sets the workflow of this LlmLLMWorkflowCreateResponse.


        :param workflow: The workflow of this LlmLLMWorkflowCreateResponse.  # noqa: E501
        :type workflow: ProtoLLMWorkflow
        """

        self._workflow = workflow

    def to_dict(self, serialize=False):
        """Returns the model properties as a dict"""
        result = {}

        def convert(x):
            if hasattr(x, "to_dict"):
                args = getfullargspec(x.to_dict).args
                if len(args) == 1:
                    return x.to_dict()
                else:
                    return x.to_dict(serialize)
            else:
                return x

        for attr, _ in six.iteritems(self.openapi_types):
            value = getattr(self, attr)
            attr = self.attribute_map.get(attr, attr) if serialize else attr
            if isinstance(value, list):
                result[attr] = list(map(
                    lambda x: convert(x),
                    value
                ))
            elif isinstance(value, dict):
                result[attr] = dict(map(
                    lambda item: (item[0], convert(item[1])),
                    value.items()
                ))
            else:
                result[attr] = convert(value)

        return result

    def to_str(self):
        """Returns the string representation of the model"""
        return pprint.pformat(self.to_dict())

    def __repr__(self):
        """For `print` and `pprint`"""
        return self.to_str()

    def __eq__(self, other):
        """Returns true if both objects are equal"""
        if not isinstance(other, LlmLLMWorkflowCreateResponse):
            return False

        return self.to_dict() == other.to_dict()

    def __ne__(self, other):
        """Returns true if both objects are not equal"""
        if not isinstance(other, LlmLLMWorkflowCreateResponse):
            return True

        return self.to_dict() != other.to_dict()
