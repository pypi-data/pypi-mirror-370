#!/usr/bin/env python3
"""
æ•°æ®åˆ†æžAgentç¤ºä¾‹ - ä½¿ç”¨LLM Flow Engineçš„DSLå·¥ä½œæµ
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨å·¥ä½œæµå¼•æ“Žè¿›è¡Œæ™ºèƒ½æ•°æ®åˆ†æž
"""
import asyncio
import sys
import os
import json
import tempfile

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from llm_flow_engine.flow_engine import FlowEngine
from llm_flow_engine.functions.file_time import file_write, file_read

class DataAnalysisAgent:
    """æ•°æ®åˆ†æžAgent - ä½¿ç”¨LLM Flow Engineå·¥ä½œæµ"""
    
    def __init__(self):
        self.model = "gemma3:4b"
        self.engine = FlowEngine()
        self.temp_dir = tempfile.mkdtemp()
        self.initialized = False
    
    async def initialize(self):
        """åˆå§‹åŒ–æ•°æ®åˆ†æžå·¥å…·"""
        if self.initialized:
            return
            
        print("ðŸ“Š åˆå§‹åŒ–æ•°æ®åˆ†æžAgentï¼ˆDSLå·¥ä½œæµæ¨¡å¼ï¼‰...")
        
        # æ³¨å†Œæ•°æ®åˆ†æžä¸“ç”¨å·¥å…·åˆ°å¼•æ“Ž
        self.engine.register_function("generate_sample_data", self._generate_sample_data)
        self.engine.register_function("load_csv_data", self._load_csv_data)
        self.engine.register_function("create_chart_config", self._create_chart_config)
        self.engine.register_function("analyze_data_statistics", self._analyze_data_statistics)
        
        self.initialized = True
        print("âœ… æ•°æ®åˆ†æžAgentï¼ˆDSLå·¥ä½œæµæ¨¡å¼ï¼‰åˆå§‹åŒ–å®Œæˆ")
    
    async def _generate_sample_data(self, data_type: str, size: int = 100) -> str:
        """ç”Ÿæˆç¤ºä¾‹æ•°æ®"""
        import random
        
        if data_type == "sales":
            data = []
            products = ["æ‰‹æœº", "ç”µè„‘", "å¹³æ¿", "è€³æœº", "é”®ç›˜"]
            regions = ["åŒ—äº¬", "ä¸Šæµ·", "å¹¿å·ž", "æ·±åœ³", "æ­å·ž"]
            
            for i in range(size):
                data.append({
                    "id": i + 1,
                    "product": random.choice(products),
                    "region": random.choice(regions),
                    "sales": round(random.uniform(1000, 50000), 2),
                    "quantity": random.randint(1, 100),
                    "date": f"2024-{random.randint(1,12):02d}-{random.randint(1,28):02d}"
                })
        
        elif data_type == "user":
            data = []
            ages = list(range(18, 65))
            cities = ["åŒ—äº¬", "ä¸Šæµ·", "å¹¿å·ž", "æ·±åœ³", "æˆéƒ½"]
            
            for i in range(size):
                data.append({
                    "user_id": f"U{i+1:04d}",
                    "age": random.choice(ages),
                    "city": random.choice(cities),
                    "login_count": random.randint(1, 365),
                    "spend_amount": round(random.uniform(0, 10000), 2)
                })
        
        else:  # product
            data = []
            categories = ["ç”µå­", "æœè£…", "é£Ÿå“", "å®¶å±…", "è¿åŠ¨"]
            
            for i in range(size):
                data.append({
                    "product_id": f"P{i+1:04d}",
                    "category": random.choice(categories),
                    "price": round(random.uniform(10, 5000), 2),
                    "rating": round(random.uniform(1, 5), 1),
                    "review_count": random.randint(0, 1000)
                })
        
        # ä¿å­˜æ•°æ®åˆ°ä¸´æ—¶æ–‡ä»¶
        file_path = os.path.join(self.temp_dir, f"{data_type}_data.json")
        await file_write(file_path, json.dumps(data, ensure_ascii=False, indent=2))
        
        return f"ç”Ÿæˆ{size}æ¡{data_type}ç¤ºä¾‹æ•°æ®ï¼Œä¿å­˜åˆ°ï¼š{file_path}"
    
    async def _load_csv_data(self, file_path: str) -> str:
        """åŠ è½½CSVæ•°æ®"""
        try:
            content = await file_read(file_path)
            lines = content.strip().split('\n')
            return f"æˆåŠŸåŠ è½½CSVæ•°æ®ï¼Œå…±{len(lines)}è¡Œæ•°æ®ã€‚å‰5è¡Œé¢„è§ˆï¼š\n" + '\n'.join(lines[:5])
        except Exception as e:
            return f"åŠ è½½CSVæ•°æ®å¤±è´¥ï¼š{str(e)}"
    
    async def _create_chart_config(self, chart_type: str, data_fields: str) -> str:
        """åˆ›å»ºå›¾è¡¨é…ç½®"""
        config = {
            "type": chart_type,
            "fields": data_fields.split(","),
            "options": {
                "responsive": True,
                "maintainAspectRatio": False
            }
        }
        
        config_path = os.path.join(self.temp_dir, f"{chart_type}_chart_config.json")
        await file_write(config_path, json.dumps(config, indent=2))
        
        return f"å›¾è¡¨é…ç½®å·²åˆ›å»ºï¼š{config_path}"
    
    async def _analyze_data_statistics(self, data_file: str) -> str:
        """åˆ†æžæ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
        try:
            content = await file_read(data_file)
            data = json.loads(content)
            
            if not data:
                return "æ•°æ®ä¸ºç©º"
            
            # åŸºæœ¬ç»Ÿè®¡
            total_records = len(data)
            
            # æ•°å€¼å­—æ®µç»Ÿè®¡
            numeric_stats = {}
            for item in data:
                for key, value in item.items():
                    if isinstance(value, (int, float)):
                        if key not in numeric_stats:
                            numeric_stats[key] = []
                        numeric_stats[key].append(value)
            
            stats_result = {
                "total_records": total_records,
                "numeric_fields": {}
            }
            
            for field, values in numeric_stats.items():
                stats_result["numeric_fields"][field] = {
                    "min": min(values),
                    "max": max(values),
                    "avg": round(sum(values) / len(values), 2),
                    "count": len(values)
                }
            
            return json.dumps(stats_result, ensure_ascii=False, indent=2)
        
        except Exception as e:
            return f"ç»Ÿè®¡åˆ†æžå¤±è´¥ï¼š{str(e)}"
    
    async def analyze_sales_data(self, request: str) -> str:
        """é”€å”®æ•°æ®åˆ†æžå·¥ä½œæµ"""
        await self.initialize()
        
        print(f"\nðŸ“ˆ é”€å”®æ•°æ®åˆ†æž: {request}")
        print("ðŸ¤– æ­£åœ¨é€šè¿‡å·¥ä½œæµè¿›è¡Œé”€å”®æ•°æ®åˆ†æž...")
        
        sales_analysis_dsl = f"""
metadata:
  version: "1.0"
  description: "é”€å”®æ•°æ®åˆ†æžå·¥ä½œæµ"

input:
  type: "start"
  name: "analysis_request"
  data:
    request: "{request}"

executors:
  # æ­¥éª¤1: ç”Ÿæˆé”€å”®æ•°æ®
  - name: generate_data
    type: "task"
    func: generate_sample_data
    custom_vars:
      data_type: "sales"
      size: 100

  # æ­¥éª¤2: ç»Ÿè®¡åˆ†æž
  - name: statistical_analysis
    type: "task"
    func: data_statistics
    custom_vars:
      data: "${{generate_data.output}}"
    depends_on: ["generate_data"]

  # æ­¥éª¤3: é”€å”®è¶‹åŠ¿åˆ†æž
  - name: trend_analysis
    type: "task"
    func: llm_simple_call
    custom_vars:
      user_input: |
        åŸºäºŽä»¥ä¸‹é”€å”®æ•°æ®ç»Ÿè®¡ç»“æžœï¼Œåˆ†æžé”€å”®è¶‹åŠ¿å’Œå…³é”®æ´žå¯Ÿï¼š
        
        ç”¨æˆ·éœ€æ±‚ï¼š${{analysis_request.request}}
        æ•°æ®ç”Ÿæˆç»“æžœï¼š${{generate_data.output}}
        ç»Ÿè®¡åˆ†æžï¼š${{statistical_analysis.output}}
        
        è¯·æä¾›ï¼š
        1. é”€å”®æ•°æ®æ€»ä½“æ¦‚å†µ
        2. å…³é”®æŒ‡æ ‡åˆ†æžï¼ˆå¹³å‡é”€å”®é¢ã€é”€é‡ç­‰ï¼‰
        3. å¯èƒ½çš„è¶‹åŠ¿å’Œæ¨¡å¼
        4. ä¸šåŠ¡å»ºè®®
      model: "{self.model}"
    depends_on: ["statistical_analysis"]

  # æ­¥éª¤4: åˆ›å»ºå¯è§†åŒ–é…ç½®
  - name: create_visualization
    type: "task"
    func: create_chart_config
    custom_vars:
      chart_type: "bar"
      data_fields: "product,sales,quantity"
    depends_on: ["trend_analysis"]

output:
  name: "analysis_result"
  value: |
    é”€å”®æ•°æ®åˆ†æžå®Œæˆï¼š
    ${{trend_analysis.output}}
    
    å¯è§†åŒ–é…ç½®ï¼š${{create_visualization.output}}
"""
        
        result = await self.engine.execute_dsl(sales_analysis_dsl, {"request": request})
        
        if result['success']:
            return result['results'].get('analysis_result', 'é”€å”®åˆ†æžå¤±è´¥')
        else:
            return f"é”€å”®åˆ†æžé”™è¯¯ï¼š{result['error']}"
    
    async def analyze_user_behavior(self, request: str) -> str:
        """ç”¨æˆ·è¡Œä¸ºåˆ†æžå·¥ä½œæµ"""
        await self.initialize()
        
        print(f"\nðŸ‘¥ ç”¨æˆ·è¡Œä¸ºåˆ†æž: {request}")
        print("ðŸ¤– æ­£åœ¨é€šè¿‡å·¥ä½œæµè¿›è¡Œç”¨æˆ·è¡Œä¸ºåˆ†æž...")
        
        user_analysis_dsl = f"""
metadata:
  version: "1.0"
  description: "ç”¨æˆ·è¡Œä¸ºåˆ†æžå·¥ä½œæµ"

input:
  type: "start"
  name: "user_request"
  data:
    request: "{request}"

executors:
  # æ­¥éª¤1: ç”Ÿæˆç”¨æˆ·æ•°æ®
  - name: generate_user_data
    type: "task"
    func: generate_sample_data
    custom_vars:
      data_type: "user"
      size: 150

  # æ­¥éª¤2: æ•°æ®è¿‡æ»¤å’Œåˆ†ç»„
  - name: filter_analysis
    type: "task"
    func: llm_simple_call
    custom_vars:
      user_input: |
        åˆ†æžç”¨æˆ·æ•°æ®çš„å…³é”®ç»´åº¦ï¼š
        
        ç”¨æˆ·éœ€æ±‚ï¼š${{user_request.request}}
        ç”Ÿæˆçš„æ•°æ®ï¼š${{generate_user_data.output}}
        
        è¯·åˆ†æžä»¥ä¸‹ç»´åº¦ï¼š
        1. ç”¨æˆ·å¹´é¾„åˆ†å¸ƒ
        2. åŸŽå¸‚åˆ†å¸ƒ
        3. æ´»è·ƒåº¦åˆ†æžï¼ˆç™»å½•æ¬¡æ•°ï¼‰
        4. æ¶ˆè´¹è¡Œä¸ºåˆ†æžï¼ˆæ¶ˆè´¹é‡‘é¢ï¼‰
        5. ç”¨æˆ·ä»·å€¼åˆ†æ®µ
      model: "{self.model}"
    depends_on: ["generate_user_data"]

  # æ­¥éª¤3: æ·±åº¦æ´žå¯Ÿ
  - name: deep_insights
    type: "task"
    func: llm_simple_call
    custom_vars:
      user_input: |
        åŸºäºŽç”¨æˆ·è¡Œä¸ºåˆ†æžç»“æžœï¼Œæä¾›æ·±åº¦ä¸šåŠ¡æ´žå¯Ÿï¼š
        
        åˆ†æžç»“æžœï¼š${{filter_analysis.output}}
        
        è¯·æä¾›ï¼š
        1. æ ¸å¿ƒç”¨æˆ·ç‰¹å¾
        2. é«˜ä»·å€¼ç”¨æˆ·ç”»åƒ
        3. ç”¨æˆ·ç•™å­˜å’Œæ´»è·ƒåº¦å»ºè®®
        4. ä¸ªæ€§åŒ–æŽ¨èç­–ç•¥
        5. è¿è¥ä¼˜åŒ–å»ºè®®
      model: "{self.model}"
    depends_on: ["filter_analysis"]

  # æ­¥éª¤4: ç”ŸæˆæŠ¥å‘Š
  - name: generate_report
    type: "task"
    func: llm_simple_call
    custom_vars:
      user_input: |
        å°†åˆ†æžç»“æžœæ•´åˆä¸ºå®Œæ•´çš„ç”¨æˆ·è¡Œä¸ºåˆ†æžæŠ¥å‘Šï¼š
        
        åŸºç¡€åˆ†æžï¼š${{filter_analysis.output}}
        æ·±åº¦æ´žå¯Ÿï¼š${{deep_insights.output}}
        
        æŠ¥å‘Šæ ¼å¼è¦æ±‚ï¼š
        1. æ‰§è¡Œæ‘˜è¦
        2. å…³é”®å‘çŽ°
        3. æ•°æ®å¯è§†åŒ–å»ºè®®
        4. è¡ŒåŠ¨è®¡åˆ’
        5. åŽç»­ç›‘æŽ§æŒ‡æ ‡
      model: "{self.model}"
    depends_on: ["deep_insights"]

output:
  name: "user_analysis_report"
  value: "${{generate_report.output}}"
"""
        
        result = await self.engine.execute_dsl(user_analysis_dsl, {"request": request})
        
        if result['success']:
            return result['results'].get('user_analysis_report', 'ç”¨æˆ·è¡Œä¸ºåˆ†æžå¤±è´¥')
        else:
            return f"ç”¨æˆ·è¡Œä¸ºåˆ†æžé”™è¯¯ï¼š{result['error']}"
    
    async def comprehensive_data_analysis(self, data_type: str, analysis_goals: str) -> str:
        """ç»¼åˆæ•°æ®åˆ†æžå·¥ä½œæµ - å¤šæ­¥éª¤å¤æ‚åˆ†æž"""
        await self.initialize()
        
        print(f"\nðŸŽ¯ ç»¼åˆæ•°æ®åˆ†æž: {data_type} - {analysis_goals}")
        print("ðŸ¤– æ­£åœ¨æ‰§è¡Œç»¼åˆæ•°æ®åˆ†æžå·¥ä½œæµ...")
        
        comprehensive_dsl = f"""
metadata:
  version: "1.0"
  description: "ç»¼åˆæ•°æ®åˆ†æžå·¥ä½œæµ"

input:
  type: "start"
  name: "comprehensive_request"
  data:
    data_type: "{data_type}"
    goals: "{analysis_goals}"

executors:
  # æ­¥éª¤1: æ•°æ®å‡†å¤‡
  - name: data_preparation
    type: "task"
    func: generate_sample_data
    custom_vars:
      data_type: "${{comprehensive_request.data_type}}"
      size: 200

  # æ­¥éª¤2: æ•°æ®è´¨é‡æ£€æŸ¥
  - name: data_quality_check
    type: "task"
    func: llm_simple_call
    custom_vars:
      user_input: |
        æ£€æŸ¥æ•°æ®è´¨é‡å¹¶æä¾›æ•°æ®æ¦‚è§ˆï¼š
        
        æ•°æ®ç±»åž‹ï¼š${{comprehensive_request.data_type}}
        æ•°æ®ç”Ÿæˆç»“æžœï¼š${{data_preparation.output}}
        
        è¯·æ£€æŸ¥ï¼š
        1. æ•°æ®å®Œæ•´æ€§
        2. æ•°æ®åˆ†å¸ƒæƒ…å†µ
        3. æ½œåœ¨çš„æ•°æ®é—®é¢˜
        4. æ•°æ®é¢„å¤„ç†å»ºè®®
      model: "{self.model}"
    depends_on: ["data_preparation"]

  # æ­¥éª¤3: æè¿°æ€§åˆ†æž
  - name: descriptive_analysis
    type: "task"
    func: data_statistics
    custom_vars:
      data: "${{data_preparation.output}}"
    depends_on: ["data_quality_check"]

  # æ­¥éª¤4: æŽ¢ç´¢æ€§åˆ†æž
  - name: exploratory_analysis
    type: "task"
    func: llm_simple_call
    custom_vars:
      user_input: |
        è¿›è¡ŒæŽ¢ç´¢æ€§æ•°æ®åˆ†æžï¼š
        
        åˆ†æžç›®æ ‡ï¼š${{comprehensive_request.goals}}
        æ•°æ®è´¨é‡ï¼š${{data_quality_check.output}}
        æè¿°æ€§ç»Ÿè®¡ï¼š${{descriptive_analysis.output}}
        
        æŽ¢ç´¢ä»¥ä¸‹æ–¹é¢ï¼š
        1. æ•°æ®åˆ†å¸ƒç‰¹å¾
        2. å˜é‡é—´å…³ç³»
        3. å¼‚å¸¸å€¼è¯†åˆ«
        4. æ¨¡å¼å‘çŽ°
        5. å‡è®¾ç”Ÿæˆ
      model: "{self.model}"
    depends_on: ["descriptive_analysis"]

  # æ­¥éª¤5: é«˜çº§åˆ†æž
  - name: advanced_analysis
    type: "task"
    func: llm_simple_call
    custom_vars:
      user_input: |
        åŸºäºŽæŽ¢ç´¢æ€§åˆ†æžç»“æžœï¼Œè¿›è¡Œé«˜çº§æ•°æ®åˆ†æžï¼š
        
        æŽ¢ç´¢æ€§åˆ†æžï¼š${{exploratory_analysis.output}}
        
        é«˜çº§åˆ†æžå†…å®¹ï¼š
        1. é¢„æµ‹æ€§åˆ†æžå»ºè®®
        2. ç»†åˆ†åˆ†æž
        3. ç›¸å…³æ€§åˆ†æž
        4. è¶‹åŠ¿åˆ†æž
        5. ä¸šåŠ¡å½±å“è¯„ä¼°
      model: "{self.model}"
    depends_on: ["exploratory_analysis"]

  # æ­¥éª¤6: å¯è§†åŒ–å»ºè®®
  - name: visualization_recommendations
    type: "task"
    func: llm_simple_call
    custom_vars:
      user_input: |
        åŸºäºŽåˆ†æžç»“æžœæŽ¨èæœ€ä½³å¯è§†åŒ–æ–¹æ¡ˆï¼š
        
        é«˜çº§åˆ†æžç»“æžœï¼š${{advanced_analysis.output}}
        
        æŽ¨èå†…å®¹ï¼š
        1. å›¾è¡¨ç±»åž‹é€‰æ‹©
        2. å…³é”®æŒ‡æ ‡dashboardè®¾è®¡
        3. äº¤äº’å¼å¯è§†åŒ–å»ºè®®
        4. æŠ¥å‘Šç»“æž„è®¾è®¡
        5. å—ä¼—å®šåˆ¶åŒ–å»ºè®®
      model: "{self.model}"
    depends_on: ["advanced_analysis"]

  # æ­¥éª¤7: æœ€ç»ˆæŠ¥å‘Š
  - name: final_report
    type: "task"
    func: text_merge
    custom_vars:
      texts:
        - "# ç»¼åˆæ•°æ®åˆ†æžæŠ¥å‘Š\n\n## æ•°æ®æ¦‚è§ˆ\n${{data_quality_check.output}}"
        - "\n\n## æè¿°æ€§åˆ†æž\n${{descriptive_analysis.output}}"
        - "\n\n## æŽ¢ç´¢æ€§åˆ†æž\n${{exploratory_analysis.output}}"
        - "\n\n## é«˜çº§åˆ†æž\n${{advanced_analysis.output}}"
        - "\n\n## å¯è§†åŒ–å»ºè®®\n${{visualization_recommendations.output}}"
      separator: ""
    depends_on: ["visualization_recommendations"]

output:
  name: "comprehensive_report"
  value: "${{final_report.output}}"
"""
        
        result = await self.engine.execute_dsl(comprehensive_dsl, {"data_type": data_type, "goals": analysis_goals})
        
        if result['success']:
            return result['results'].get('comprehensive_report', 'ç»¼åˆåˆ†æžå¤±è´¥')
        else:
            return f"ç»¼åˆåˆ†æžé”™è¯¯ï¼š{result['error']}"

async def demo_data_analysis_flow():
    """æ•°æ®åˆ†æžAgentå·¥ä½œæµæ¼”ç¤º"""
    print("ðŸŽ¨ æ•°æ®åˆ†æžAgentæ¼”ç¤º (LLM Flow Engineå·¥ä½œæµæ¨¡å¼)")
    print("=" * 60)
    
    agent = DataAnalysisAgent()
    
    # æµ‹è¯•ä¸åŒçš„æ•°æ®åˆ†æžå·¥ä½œæµ
    analysis_scenarios = [
        {
            "type": "é”€å”®æ•°æ®åˆ†æž",
            "method": "analyze_sales_data",
            "request": "åˆ†æžé”€å”®æ•°æ®çš„æ•´ä½“è¶‹åŠ¿ï¼Œæ‰¾å‡ºè¡¨çŽ°æœ€å¥½çš„äº§å“å’Œåœ°åŒº"
        },
        {
            "type": "ç”¨æˆ·è¡Œä¸ºåˆ†æž", 
            "method": "analyze_user_behavior",
            "request": "åˆ†æžç”¨æˆ·æ´»è·ƒåº¦å’Œæ¶ˆè´¹è¡Œä¸ºï¼Œåˆ¶å®šç”¨æˆ·å¢žé•¿ç­–ç•¥"
        },
        {
            "type": "ç»¼åˆæ•°æ®åˆ†æž",
            "method": "comprehensive_data_analysis", 
            "data_type": "product",
            "goals": "äº§å“æ€§èƒ½åˆ†æžå’Œå¸‚åœºå®šä½ä¼˜åŒ–"
        }
    ]
    
    for i, scenario in enumerate(analysis_scenarios, 1):
        print(f"\nðŸ“Š åˆ†æžåœºæ™¯ {i}: {scenario['type']}")
        print("-" * 50)
        
        method = getattr(agent, scenario['method'])
        
        if scenario['type'] == "ç»¼åˆæ•°æ®åˆ†æž":
            response = await method(scenario['data_type'], scenario['goals'])
        else:
            response = await method(scenario['request'])
            
        print(f"ðŸ¤– åˆ†æžç»“æžœ: {response[:500]}...")
        if len(response) > 500:
            print("... (ç»“æžœå·²æˆªæ–­)")
        print("=" * 60)
        
        await asyncio.sleep(2)

if __name__ == "__main__":
    asyncio.run(demo_data_analysis_flow())
