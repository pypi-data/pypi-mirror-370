Metadata-Version: 2.4
Name: qagen
Version: 0.1.1
Summary: A powerful Chinese document QA pairs generation and validation tool with multiple LLM support
Project-URL: Homepage, https://github.com/crisschan/qa-gen-cn
Project-URL: Documentation, https://github.com/crisschan/qa-gen-cn#readme
Project-URL: Repository, https://github.com/crisschan/qa-gen-cn
Project-URL: Bug Tracker, https://github.com/crisschan/qa-gen-cn/issues
Project-URL: Source Code, https://github.com/crisschan/qa-gen-cn
Author-email: CrissChan <can101208@gmail.com>
License: MIT
License-File: LICENSE
Keywords: ai,chinese,document-processing,llm,nlp,qa-generation
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Text Processing :: Linguistic
Requires-Python: >=3.9
Requires-Dist: jieba>=0.42.1
Requires-Dist: langchain-community>=0.1.0
Requires-Dist: langchain-ollama>=0.1.0
Requires-Dist: langchain-openai>=0.1.0
Requires-Dist: langchain>=0.1.0
Requires-Dist: numpy<2.0
Requires-Dist: scikit-learn>=1.3.0
Requires-Dist: sentence-transformers>=2.2.0
Requires-Dist: torch>=2.0.0
Provides-Extra: dev
Requires-Dist: black>=23.0.0; extra == 'dev'
Requires-Dist: flake8>=6.0.0; extra == 'dev'
Requires-Dist: mypy>=1.0.0; extra == 'dev'
Requires-Dist: pytest-cov>=4.0.0; extra == 'dev'
Requires-Dist: pytest-mock>=3.10.0; extra == 'dev'
Requires-Dist: pytest>=7.0.0; extra == 'dev'
Provides-Extra: test
Requires-Dist: pytest-cov>=4.0.0; extra == 'test'
Requires-Dist: pytest-mock>=3.10.0; extra == 'test'
Requires-Dist: pytest>=7.0.0; extra == 'test'
Description-Content-Type: text/markdown

# QA Generation CN - ä¸­æ–‡é—®ç­”å¯¹ç”Ÿæˆå·¥å…·

ä¸€ä¸ªå¼ºå¤§çš„ä¸­æ–‡æ–‡æ¡£é—®ç­”å¯¹ï¼ˆQA pairsï¼‰è‡ªåŠ¨ç”Ÿæˆå’ŒéªŒè¯å·¥å…·ï¼Œæ”¯æŒå¤šç§LLMæä¾›å•†ï¼Œå…·å¤‡å®Œå–„çš„è´¨é‡éªŒè¯æœºåˆ¶ã€‚

## âœ¨ åŠŸèƒ½ç‰¹æ€§

- ğŸ¤– **å¤šLLMæ”¯æŒ**: æ”¯æŒOllamaï¼ˆæœ¬åœ°ï¼‰å’ŒOpenAIï¼ˆäº‘ç«¯ï¼‰æ¨¡å‹
- ğŸ“„ **æ™ºèƒ½æ–‡æ¡£å¤„ç†**: è‡ªåŠ¨åˆ†å—ã€ä¸­æ–‡ä¼˜åŒ–å¤„ç†
- âœ… **å¤šç»´åº¦éªŒè¯**: è¯­ä¹‰ç›¸ä¼¼åº¦ã€å…³é”®è¯åŒ¹é…ã€é•¿åº¦æ§åˆ¶ã€å”¯ä¸€æ€§æ£€æµ‹
- ğŸ“Š **è¯¦ç»†ç»Ÿè®¡**: ç”Ÿæˆè´¨é‡æŠ¥å‘Šå’Œæ•°æ®åˆ†æ
- ğŸ¯ **ä¸­æ–‡ä¼˜åŒ–**: ä¸“é—¨é’ˆå¯¹ä¸­æ–‡å†…å®¹ä¼˜åŒ–
- ğŸ”§ **çµæ´»é…ç½®**: ä¸°å¯Œçš„å‚æ•°é…ç½®é€‰é¡¹

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å…‹éš†é¡¹ç›®
git clone <repository-url>
cd qa_gen_cn

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# æ¿€æ´»condaç¯å¢ƒï¼ˆå¦‚æœä½¿ç”¨ï¼‰
conda activate LLM
```

### 2. é…ç½®LLM

#### ä½¿ç”¨Ollamaï¼ˆæ¨èï¼Œæœ¬åœ°è¿è¡Œï¼‰

```bash
# å®‰è£…Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# å¯åŠ¨OllamaæœåŠ¡
ollama serve

# ä¸‹è½½æ¨¡å‹
ollama pull llama3.1:8b
# æˆ–ä¸‹è½½å…¶ä»–æ¨¡å‹
ollama pull qwen3:8b
ollama pull gemma2:9b
```

#### ä½¿ç”¨OpenAIï¼ˆäº‘ç«¯ï¼‰

```bash
# è®¾ç½®APIå¯†é’¥
export OPENAI_API_KEY="your-api-key-here"
```

### 3. åŸºç¡€ä½¿ç”¨

#### æ–¹æ³•ä¸€ï¼šä½¿ç”¨å®Œæ•´è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
# è¿è¡Œå®Œæ•´çš„ç”Ÿæˆå’ŒéªŒè¯æµç¨‹
python examples/generate_and_validate_qa.py
```

#### æ–¹æ³•äºŒï¼šä½¿ç”¨ç®€åŒ–è„šæœ¬

```bash
# ä»…ç”ŸæˆQA pairsï¼Œä¸è¿›è¡ŒéªŒè¯
python examples/generator_and_no_validate_qa.py
```

#### æ–¹æ³•ä¸‰ï¼šç¼–ç¨‹æ–¹å¼ä½¿ç”¨

```python
from qa_gen_cn import generate_qa_pairs

# åŸºç¡€ä½¿ç”¨
qa_pairs = generate_qa_pairs(
    doc_path="your_document.txt",
    llm_provider="ollama",
    llm_model="llama3.1:8b"
)

# è‡ªå®šä¹‰é…ç½®
qa_pairs = generate_qa_pairs(
    doc_path="your_document.txt",
    llm_provider="openai",
    llm_model="gpt-3.5-turbo",
    show_chunks=True,
    validation_config={
        "keyword_top_n": 10
    },
    api_key="your-openai-api-key"
)
```

## ğŸ“– è¯¦ç»†ä½¿ç”¨æŒ‡å—

### 1. æ–‡æ¡£æ ¼å¼è¦æ±‚

æ”¯æŒçº¯æ–‡æœ¬æ–‡ä»¶ï¼ˆ.txtï¼‰ï¼Œå†…å®¹ç¤ºä¾‹ï¼š

```text
å¤§æœ‰å”ç‹é™æ••å°ï¼Œé’¦å·®ç„å¥˜é—®ç¦…å®—ã€‚åšå¿ƒç£¨ç¢å¯»é¾™ç©´ï¼Œç€æ„ä¿®æŒä¸Šé¹«å³°ã€‚
è¾¹ç•Œè¿œæ¸¸å¤šå°‘å›½ï¼Œäº‘å±±å‰åº¦ä¸‡åƒé‡ã€‚è‡ªä»Šåˆ«é©¾æŠ•è¥¿å»ï¼Œç§‰æ•™è¿¦æŒæ‚Ÿå¤§ç©ºã€‚

å´è¯´ä¸‰è—è‡ªè´è§‚åä¸‰å¹´ä¹æœˆæœ›å‰ä¸‰æ—¥ï¼Œè’™å”ç‹ä¸å¤šå®˜é€å‡ºé•¿å®‰å…³å¤–ã€‚
ä¸€äºŒæ—¥é©¬ä¸åœè¹„ï¼Œæ—©è‡³æ³•é—¨å¯ºã€‚æœ¬å¯ºä½æŒä¸Šæˆ¿é•¿è€ï¼Œå¸¦é¢†ä¼—åƒ§æœ‰äº”ç™¾ä½™äººï¼Œ
ä¸¤è¾¹ç½—åˆ—ï¼Œæ¥è‡³é‡Œé¢ï¼Œç›¸è§çŒ®èŒ¶ã€‚èŒ¶ç½¢è¿›æ–‹ã€‚æ–‹åä¸è§‰å¤©æ™šã€‚
```

### 2. é…ç½®å‚æ•°è¯¦è§£

#### LLMé…ç½®

```python
# Ollamaé…ç½®
llm_config = {
    "llm_provider": "ollama",
    "llm_model": "llama3.1:8b",  # æˆ–å…¶ä»–å¯ç”¨æ¨¡å‹
    "show_chunks": True,  # æ˜¾ç¤ºæ–‡æ¡£åˆ†å—è¿‡ç¨‹
    "chunk_size": 500,   # æ–‡æ¡£å—å¤§å°
    "chunk_overlap": 50  # å—é‡å å¤§å°
}

# OpenAIé…ç½®
openai_config = {
    "llm_provider": "openai",
    "llm_model": "gpt-3.5-turbo",  # æˆ– "gpt-4"
    "api_key": "your-api-key"
}
```

#### éªŒè¯é…ç½®

```python
validation_config = {
    # è¯­ä¹‰ç›¸ä¼¼åº¦éªŒè¯
    "similarity_threshold": 0.3,  # ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0-1ï¼‰
    "similarity_model": "paraphrase-multilingual-MiniLM-L12-v2",
    
}
```

### 3. é«˜çº§ä½¿ç”¨ç¤ºä¾‹

#### è‡ªå®šä¹‰ç”Ÿæˆæµç¨‹

```python
from qa_gen_cn.generator import QAGenerator
from qa_gen_cn.llm_factory import LLMFactory
from qa_gen_cn.validator import QAPairValidator
from qa_gen_cn.utils import load_document

# 1. åˆå§‹åŒ–LLM
llm = LLMFactory.create_llm(
    provider='ollama', 
    model='llama3.1:8b',
    temperature=0.7
)

# 2. åˆ›å»ºç”Ÿæˆå™¨
generator = QAGenerator(llm=llm, show_chunks=True)

# 3. ç”ŸæˆQA pairs
qa_pairs = generator.generate_from_document(
    doc_path="your_document.txt",
    chunk_size=3000,
    chunk_overlap=100
)

# 4. é…ç½®éªŒè¯å™¨
validator = QAPairValidator({
   "similarity_threshold": 0.4,
   'similarity_model':'paraphrase-multilingual-MiniLM-L12-v2'
})

# 5. éªŒè¯QA pairs
doc_content = " ".join([doc.page_content for doc in load_document("your_document.txt")])
validated_pairs = validator.validate(qa_pairs, doc_content)

print(f"ç”Ÿæˆ {len(qa_pairs)} ä¸ªQA pairsï¼ŒéªŒè¯é€šè¿‡ {len(validated_pairs)} ä¸ª")
```



## ğŸ“Š è¾“å‡ºç»“æœ

### æ–‡ä»¶ç»“æ„

è¿è¡Œå®Œæˆåï¼Œä¼šåœ¨`output`ç›®å½•ç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š

```
output/
â”œâ”€â”€ qa_generation_result.json  # å®Œæ•´ç»“æœï¼ˆåŒ…å«é…ç½®ã€ç»Ÿè®¡ç­‰ï¼‰
â”œâ”€â”€ qa_pairs.json             # çº¯QA pairsæ•°æ®
â””â”€â”€ statistics.txt            # ç»Ÿè®¡æŠ¥å‘Š
```

### è¾“å‡ºæ ¼å¼ç¤ºä¾‹

#### QA Pairs JSONæ ¼å¼

```json
[
  {
    "question": "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
    "answer": "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œæ—¨åœ¨åˆ›å»ºèƒ½å¤Ÿæ¨¡æ‹Ÿäººç±»æ™ºèƒ½çš„æœºå™¨ã€‚"
  },
  {
    "question": "æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ çš„å…³ç³»æ˜¯ä»€ä¹ˆï¼Ÿ",
    "answer": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„åˆ†æ”¯ï¼Œæ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„å­é›†ï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œå­¦ä¹ ã€‚"
  }
]
```

#### ç»Ÿè®¡æŠ¥å‘Šç¤ºä¾‹

```
=== QA Pairs ç”Ÿæˆå’ŒéªŒè¯ç»Ÿè®¡æŠ¥å‘Š ===

æ–‡æ¡£è·¯å¾„: examples/1.txt
LLMé…ç½®: {'provider': 'ollama', 'model': 'llama3.1:8b'}

ç»Ÿè®¡ä¿¡æ¯:
- æ€»ç”Ÿæˆæ•°é‡: 25
- éªŒè¯é€šè¿‡æ•°é‡: 18
- éªŒè¯é€šè¿‡ç‡: 72.00%
- å¹³å‡é—®é¢˜é•¿åº¦: 23.4 å­—ç¬¦
- å¹³å‡ç­”æ¡ˆé•¿åº¦: 156.7 å­—ç¬¦

éªŒè¯é…ç½®:
- keyword_top_n: 15
```

## ğŸ”§ éªŒè¯æœºåˆ¶è¯¦è§£

### 1. è¯­ä¹‰ç›¸ä¼¼åº¦éªŒè¯
- **åŸç†**: ä½¿ç”¨å¤šè¯­è¨€è¯­ä¹‰æ¨¡å‹è®¡ç®—é—®é¢˜ã€ç­”æ¡ˆä¸åŸæ–‡çš„ç›¸ä¼¼åº¦
- **ä½œç”¨**: ç¡®ä¿ç”Ÿæˆçš„QA pairsä¸åŸæ–‡å†…å®¹ç›¸å…³
- **é…ç½®**: `similarity_threshold` (0-1ï¼Œè¶Šé«˜è¶Šä¸¥æ ¼),`similarity_model`

### 2. å…³é”®è¯åŒ¹é…éªŒè¯
- **åŸç†**: æå–åŸæ–‡å…³é”®è¯ï¼ŒéªŒè¯é—®é¢˜å’Œç­”æ¡ˆæ˜¯å¦åŒ…å«ç›¸å…³å…³é”®è¯
- **ä½œç”¨**: ä¿è¯QA pairsæ¶µç›–æ–‡æ¡£æ ¸å¿ƒå†…å®¹
- **é…ç½®**: `keyword_top_n` (æå–å…³é”®è¯æ•°é‡)

### 3. é•¿åº¦éªŒè¯
- **åŸç†**: æ£€æŸ¥é—®é¢˜å’Œç­”æ¡ˆçš„é•¿åº¦æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…
- **ä½œç”¨**: é¿å…è¿‡çŸ­æˆ–è¿‡é•¿çš„QA pairs
- **é…ç½®**: `question_min_length`,`question_max_length`,`answer_min_length`, `answer_max_length`

### 4. å”¯ä¸€æ€§éªŒè¯
- **åŸç†**: ä½¿ç”¨èšç±»ç®—æ³•æ£€æµ‹é‡å¤çš„QA pairs
- **ä½œç”¨**: ç¡®ä¿ç”Ÿæˆç»“æœçš„å¤šæ ·æ€§
- **é…ç½®**: `similarity_model`,`uniqueness_check_enabled`,`uniqueness_distance_threshold` (èšç±»è·ç¦»é˜ˆå€¼)ï¼Œè¶Šå°è¶Šå¥½ï¼ˆæ›´ä¸¥æ ¼å»é‡ï¼‰ï¼Œä½†éœ€è¦æ ¹æ®ä½ çš„å…·ä½“éœ€æ±‚æ¥å¹³è¡¡æ•°é‡å’Œè´¨é‡ã€‚
   - 0.0: ç†è®ºä¸Šä¸å…è®¸ä»»ä½•é‡å¤ï¼Œä½†å®é™…ä¸­å¾ˆå°‘ä½¿ç”¨
   - 1.0: å…è®¸æ‰€æœ‰å†…å®¹ï¼Œç›¸å½“äºå…³é—­å»é‡åŠŸèƒ½
   - å»ºè®®èŒƒå›´: 0.05-0.3 ä¹‹é—´ï¼Œæ ¹æ®å…·ä½“éœ€æ±‚è°ƒæ•´


### 5. ç‰¹åˆ«æ³¨æ„
Validation 1,2,3,4 validationæ˜¯äº’æ–¥çš„ï¼Œåªèƒ½é€‰æ‹©ä¸€ä¸ªéªŒè¯
éªŒè¯ä¼˜å…ˆçº§ï¼š**1>2>3>4**ï¼Œåœ¨self.configä¸­é…ç½®äº†ï¼š
   1 similarity_thresholdå’Œsimilarity_modelï¼Œåé¢å…¶ä»–éªŒè¯çš„é…ç½®å¯ä»¥ä¸é…ç½®ï¼Œå¦‚æœé…ç½®äº†ä¹Ÿä¸èµ·ä½œç”¨ã€‚
   2 question_min_lengthå’Œquestion_max_lengthï¼Œanswer_min_lengthå’Œanswer_max_lengthï¼Œåé¢å…¶ä»–éªŒè¯çš„é…ç½®å¯ä»¥ä¸é…ç½®ï¼Œå¦‚æœé…ç½®äº†ä¹Ÿä¸èµ·ä½œç”¨ã€‚
   3 keyword_top_nï¼Œåé¢å…¶ä»–éªŒè¯çš„é…ç½®å¯ä»¥ä¸é…ç½®ï¼Œå¦‚æœé…ç½®äº†ä¹Ÿä¸èµ·ä½œç”¨ã€‚
   4 similarity_modelã€uniqueness_distance_thresholdå’Œuniqueness_check_enabledï¼Œå…¶ä»–éªŒè¯çš„é…ç½®å¯ä»¥ä¸é…ç½®ï¼Œå¦‚æœé…ç½®äº†ä¹Ÿä¸èµ·ä½œç”¨ã€‚
## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

#### 1. Ollamaè¿æ¥é—®é¢˜

```bash
# æ£€æŸ¥OllamaæœåŠ¡çŠ¶æ€
ollama list

# é‡å¯OllamaæœåŠ¡
ollama serve

# æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½
ollama show llama3.1:8b
```

#### 2. OpenAI APIé—®é¢˜

```bash
# æ£€æŸ¥APIå¯†é’¥
echo $OPENAI_API_KEY

# æµ‹è¯•APIè¿æ¥
curl -H "Authorization: Bearer $OPENAI_API_KEY" \
     https://api.openai.com/v1/models
```

#### 3. éªŒè¯å¤±è´¥ç‡é«˜

```python
# é™ä½éªŒè¯æ ‡å‡†
validation_config = {
    "similarity_threshold": 0.1,  # é™ä½ç›¸ä¼¼åº¦è¦æ±‚
}
```

#### 4. å†…å­˜ä¸è¶³

```python
# å‡å°å¤„ç†å—å¤§å°
config = {
    "chunk_size": 2000,      # å‡å°å—å¤§å°
    "chunk_overlap": 100     # å‡å°é‡å 
}
```

### è°ƒè¯•æ¨¡å¼

å¯ç”¨è¯¦ç»†è¾“å‡ºæŸ¥çœ‹å¤„ç†è¿‡ç¨‹ï¼š

```python
# æ˜¾ç¤ºæ–‡æ¡£åˆ†å—
"show_chunks": True

# æŸ¥çœ‹éªŒè¯è¯¦æƒ…
validator = QAPairValidator(config)
# å¯ä»¥å•ç‹¬æµ‹è¯•å„ä¸ªéªŒè¯æ–¹æ³•
```

## ğŸ§ª æµ‹è¯•

è¿è¡Œå•å…ƒæµ‹è¯•ç¡®ä¿åŠŸèƒ½æ­£å¸¸ï¼š

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
python -m pytest tests/ -v

# è¿è¡Œç‰¹å®šæµ‹è¯•
python -m pytest tests/test_generator.py -v

# è¿è¡Œè¦†ç›–ç‡æµ‹è¯•
python -m pytest tests/ --cov=qa_gen_cn --cov-report=html
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
qa_gen_cn/
â”œâ”€â”€ qa_gen_cn/                    # æ ¸å¿ƒæ¨¡å—
â”‚   â”œâ”€â”€ __init__.py              # ä¸»å…¥å£
â”‚   â”œâ”€â”€ generator.py             # QAç”Ÿæˆå™¨
â”‚   â”œâ”€â”€ llm_factory.py           # LLMå·¥å‚
â”‚   â”œâ”€â”€ validator.py             # éªŒè¯å™¨
â”‚   â”œâ”€â”€ super_json.py            # JSONå¤„ç†å·¥å…·
â”‚   â””â”€â”€ utils.py                 # å·¥å…·å‡½æ•°
â”œâ”€â”€ examples/                    # ç¤ºä¾‹ä»£ç 
â”‚   â”œâ”€â”€ generate_and_validate_qa.py    # å®Œæ•´ç”Ÿæˆè„šæœ¬
â”‚   â”œâ”€â”€ generator_and_no_validate_qa.py # ç®€åŒ–ç”Ÿæˆè„šæœ¬
â”‚   â””â”€â”€ 1.txt                   # ç¤ºä¾‹æ–‡æ¡£
â”œâ”€â”€ tests/                       # å•å…ƒæµ‹è¯•
â”‚   â”œâ”€â”€ test_generator.py
â”‚   â”œâ”€â”€ test_validator.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ output/                      # è¾“å‡ºç›®å½•
â”œâ”€â”€ requirements.txt             # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ pyproject.toml              # é¡¹ç›®é…ç½®
â””â”€â”€ README.md                   # æœ¬æ–‡æ¡£
```

## ğŸ› ï¸ æŠ€æœ¯æ ˆ

- **LangChain**: LLMé›†æˆå’Œé“¾å¼å¤„ç†
- **Sentence Transformers**: è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—
- **jieba**: ä¸­æ–‡åˆ†è¯å’Œå…³é”®è¯æå–
- **scikit-learn**: èšç±»å’Œå»é‡ç®—æ³•
- **Ollama**: æœ¬åœ°LLMæœåŠ¡
- **OpenAI**: äº‘ç«¯LLM API
- **pytest**: å•å…ƒæµ‹è¯•æ¡†æ¶

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäºMITè®¸å¯è¯å¼€æºã€‚

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›è¿™ä¸ªé¡¹ç›®ï¼

## ğŸ“ æ”¯æŒ

å¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·ï¼š
1. æŸ¥çœ‹æœ¬æ–‡æ¡£çš„æ•…éšœæ’é™¤éƒ¨åˆ†
2. æ£€æŸ¥é¡¹ç›®çš„Issuesé¡µé¢
3. æäº¤æ–°çš„Issueæè¿°é—®é¢˜
