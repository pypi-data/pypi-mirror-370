import os
import questionary
import pandas as pd
from pathlib import Path
from geo_pysearch.sdk import (
    search_datasets, 
    search_with_enhanced_gpt,
    analyze_gpt_results,
    print_gpt_summary,
    get_cache_info, 
    clear_cache, 
    print_cache_info,
    preload_datasets
)


def search_command():
    """Main search functionality with enhanced GPT filtering options"""
    print("\nüß¨ Welcome to GeoVectorSearch CLI üß¨\n")

    # Step 1: Get disease or query
    query = questionary.text("üîç Enter your disease query or research topic:").ask()
    if not query:
        print("‚ùå Query is required!")
        return

    # Step 2: Dataset type selection
    dataset_type = questionary.select(
        "üß™ Choose dataset type:",
        choices=["microarray", "rnaseq"]
    ).ask()

    # Step 3: Number of top results
    top_k = questionary.text(
        "üìä How many top results would you like to retrieve?",
        default="50"
    ).ask()
    try:
        top_k = int(top_k.strip())
    except ValueError:
        print("‚ùå Invalid number format!")
        return

    # Step 4: Cache options
    cache_options = questionary.select(
        "üíæ Cache options:",
        choices=[
            "Use default cache location",
            "Specify custom cache directory", 
            "Force re-download files"
        ]
    ).ask()

    cache_dir = None
    force_download = False

    if cache_options == "Specify custom cache directory":
        cache_path = questionary.path("üìÅ Enter cache directory path:").ask()
        if cache_path:
            cache_dir = Path(cache_path)
    elif cache_options == "Force re-download files":
        force_download = True
        print("‚ö†Ô∏è  Files will be re-downloaded even if cached")

    # Step 5: GPT filter toggle and type selection
    gpt_filter_options = questionary.select(
        "ü§ñ Choose filtering option:",
        choices=[
            "No GPT filtering (semantic search only)",
            "Basic GPT filtering",
            "Enhanced GPT filtering (recommended for DE analysis)",
        ]
    ).ask()

    use_gpt_filter = "No GPT filtering" not in gpt_filter_options
    gpt_filter_type = "enhanced" if "Enhanced" in gpt_filter_options else "basic"

    # Step 6: GPT settings (if enabled)
    confidence_threshold = 0.3
    tier_filter = None
    return_all_gpt_results = False
    api_key = None
    api_url = None

    if use_gpt_filter:
        if gpt_filter_type == "enhanced":
            tier_filter = questionary.checkbox(
                "üéØ Choose tier filtering strategy (default: All tiers):",
                choices=[
                    questionary.Choice("Tier 1 only (highest quality datasets)", value=[1]),
                    questionary.Choice("Tier 1 & 2 (suitable datasets)", value=[1,2]),
                    questionary.Choice("All tiers (includes Tier-3: not fully suitable for DE datasets as well)", value=[1,2,3]),
                ],
                default=[1,2,3]
            ).ask()
            if tier_filter:
                tier_filter = [tier for sublist in tier_filter for tier in sublist]
            
            print(f"\nüìã Selected tiers: {", ".join([str(x) for x in tier_filter])}")

        # Common GPT settings
        confidence_threshold = questionary.text(
            "üéØ Minimum GPT confidence score (0.0 - 1.0)?",
            default="0.3"
        ).ask()
        try:
            confidence_threshold = float(confidence_threshold)
            if not 0.0 <= confidence_threshold <= 1.0:
                raise ValueError("Confidence must be between 0.0 and 1.0")
        except ValueError as e:
            print(f"‚ùå Invalid confidence score: {e}")
            return

        return_all_gpt_results = questionary.confirm(
            "üìÅ Return all GPT results (not just filtered)?",
            default=False
        ).ask()

        # API credentials
        print("\nüîê API Configuration:")
        api_key = questionary.password("Enter your OpenAI API key:").ask()
        if not api_key or not api_key.strip():
            print("\n‚ùå Error: API key is required for GPT filtering.\n")
            return

        api_url = questionary.text(
            "Enter your OpenAI API URL (eg: https://api.openai.com/v1/chat/completions):"
        ).ask()
        if not api_url or not api_url.strip():
            print("\n‚ùå Error: API URL is required for GPT filtering.\n")
            return

    # Step 7: Perform search
    print(f"\nüîé Searching datasets with {gpt_filter_type if use_gpt_filter else 'semantic'} filtering...")
    try:
        # Show progress message for first-time users
        cache_info = get_cache_info(cache_dir)
        if cache_info['total_files'] == 0:
            print("üì• First run detected - downloading and caching dataset files...")
            print("‚è≥ This may take a few minutes but will be faster on subsequent runs.")

        # Use enhanced search if enhanced GPT filtering is selected
        if use_gpt_filter and gpt_filter_type == "enhanced":
            results = search_with_enhanced_gpt(
                query=query,
                dataset_type=dataset_type,
                top_k=top_k,
                tier_filter=tier_filter,
                confidence_threshold=confidence_threshold,
                return_all_gpt_results=return_all_gpt_results,
                api_key=api_key,
                api_url=api_url,
                cache_dir=cache_dir,
                force_download=force_download
            )
        else:
            # Use standard search for basic or no GPT filtering
            results = search_datasets(
                query=query,
                dataset_type=dataset_type,
                top_k=top_k,
                use_gpt_filter=use_gpt_filter,
                gpt_filter_type=gpt_filter_type,
                confidence_threshold=confidence_threshold,
                return_all_gpt_results=return_all_gpt_results,
                api_key=api_key,
                api_url=api_url,
                cache_dir=cache_dir,
                force_download=force_download
            )

        # Step 8: Display results summary
        if not results.empty:
            print(f"\n‚úÖ Found {len(results)} results!")
            
            # Enhanced GPT results analysis
            if use_gpt_filter and 'gpt_tier' in results.columns:
                print("\nüìä GPT Filtering Summary:")
                print_gpt_summary(results)
            
            # Show top results preview
            print(f"\nüìã Top {min(5, len(results))} results preview:")
            preview_cols = ['gse']
            
            available_cols = results.columns.tolist()
            preview_additions = ['similarity', 'gpt_confidence', 'gpt_tier', 'gpt_tissue_type', 
                               'gpt_study_design', 'gpt_anatomical_relevance']
            
            for col in preview_additions:
                if col in available_cols:
                    preview_cols.append(col)
            
            preview_df = results[preview_cols].head(5)
            print(preview_df.to_string(index=False, max_colwidth=30))
            
            # Show detailed info for enhanced results
            if 'gpt_tier' in results.columns:
                show_details = questionary.confirm(
                    "\nüîç Show detailed GPT assessments for top results?",
                    default=False
                ).ask()
                
                if show_details:
                    print("\n" + "="*80)
                    print("DETAILED GPT ASSESSMENTS")
                    print("="*80)
                    
                    for idx, (_, row) in enumerate(results.head(3).iterrows(), 1):
                        print(f"\n--- Dataset #{idx}: {row['gse']} ---")
                        print(f"Tier: {row.get('gpt_tier', 'N/A')}")
                        print(f"Confidence: {row.get('gpt_confidence', 'N/A'):.3f}")
                        print(f"Disease Samples: {row.get('gpt_disease_samples', 'N/A')}")
                        print(f"Control Samples: {row.get('gpt_control_samples', 'N/A')}")
                        print(f"Tissue Type: {row.get('gpt_tissue_type', 'N/A')}")
                        print(f"Study Design: {row.get('gpt_study_design', 'N/A')}")
                        print(f"Reason: {row.get('gpt_reason', 'N/A')}")
                        if row.get('gpt_key_limitations') and row.get('gpt_key_limitations') != 'none':
                            print(f"Limitations: {row.get('gpt_key_limitations', 'N/A')}")
            
            # Step 9: Save results
            save_results = questionary.confirm(
                "\nüíæ Save results to CSV file?",
                default=True
            ).ask()
            
            if save_results:
                # Generate more descriptive filename
                filter_suffix = ""
                if use_gpt_filter:
                    if gpt_filter_type == "enhanced" and tier_filter:
                        tier_str = "_".join(map(str, sorted(tier_filter)))
                        filter_suffix = f"_enhanced_tier{tier_str}"
                    else:
                        filter_suffix = f"_{gpt_filter_type}"
                
                filename = f"results_{dataset_type}_{query.replace(' ', '_').replace('/', '_').replace("'",'')}{filter_suffix}.csv"
                results.to_csv(filename, index=False)
                print(f"\n‚úÖ Results saved to: {filename}")
                print(f"   üìÑ Columns saved: {len(results.columns)}")
                print(f"   üìä Rows saved: {len(results)}")
            
            # Show cache info
            print(f"\nüíæ Cache info:")
            cache_info = get_cache_info(cache_dir)
            print(f"   üìÅ Cache location: {cache_info['cache_dir']}")
            print(f"   üì¶ Cached files: {cache_info['total_files']}")
            print(f"   üíø Cache size: {cache_info['total_size_mb']} MB")
            
        else:
            print("\n‚ö†Ô∏è No results found for your query.")
            if use_gpt_filter and tier_filter and len(tier_filter) == 1 and tier_filter[0] == 1:
                suggest_broader = questionary.confirm(
                    "üí° No Tier 1 datasets found. Would you like to search again with Tier 1 & 2?",
                    default=True
                ).ask()
                if suggest_broader:
                    print("üîÑ Searching with broader tier criteria...")
                    print("üí° Please run the search again and select both Tier 1 and Tier 2.")
            
    except Exception as e:
        print(f"\n‚ùå Error during search: {str(e)}")
        if "API" in str(e):
            print("üí° Tip: Check your API key and URL are correct")
        elif "tier" in str(e).lower():
            print("üí° Tip: Try selecting multiple tiers or lowering confidence threshold")


def cache_management_menu():
    """Cache management submenu"""
    while True:
        choice = questionary.select(
            "üíæ Cache Management:",
            choices=[
                "üìä View cache information",
                "üóëÔ∏è Clear all cache",
                "üéØ Clear cache for specific dataset type",
                "üì• Preload datasets", 
                "‚¨ÖÔ∏è Back to main menu"
            ]
        ).ask()

        if choice == "üìä View cache information":
            print("\nüìä Cache Information:")
            print_cache_info()
            
        elif choice == "üóëÔ∏è Clear all cache":
            confirm = questionary.confirm(
                "‚ö†Ô∏è  Are you sure you want to clear all cached files?",
                default=False
            ).ask()
            if confirm:
                clear_cache()
                print("‚úÖ All cache cleared!")
            
        elif choice == "üéØ Clear cache for specific dataset type":
            dataset_type = questionary.select(
                "Choose dataset type to clear:",
                choices=["microarray", "rnaseq"]
            ).ask()
            confirm = questionary.confirm(
                f"‚ö†Ô∏è  Clear cache for {dataset_type} datasets?",
                default=False
            ).ask()
            if confirm:
                clear_cache(dataset_type=dataset_type)
                print(f"‚úÖ Cache cleared for {dataset_type} datasets!")
                
        elif choice == "üì• Preload datasets":
            dataset_choices = questionary.checkbox(
                "Select datasets to preload:",
                choices=[
                    questionary.Choice("üß¨ Microarray datasets", value="microarray"),
                    questionary.Choice("üß™ RNA-seq datasets", value="rnaseq")
                ]
            ).ask()
            
            if dataset_choices:
                force = questionary.confirm(
                    "üîÑ Force re-download even if cached?",
                    default=False
                ).ask()
                
                print(f"\nüì• Preloading {', '.join(dataset_choices)} datasets...")
                try:
                    preload_datasets(dataset_choices, force_download=force)
                    print("‚úÖ Datasets preloaded successfully!")
                except Exception as e:
                    print(f"‚ùå Error preloading datasets: {str(e)}")
            else:
                print("No datasets selected.")
                
        elif choice == "‚¨ÖÔ∏è Back to main menu":
            break


def help_menu():
    """Enhanced help menu with GPT filtering information"""
    help_choice = questionary.select(
        "‚ùì Help Topics:",
        choices=[
            "üìö General Overview",
            "üîç Search Tips", 
            "ü§ñ GPT Filtering Guide",
            "üíæ Cache Management",
            "üîß Troubleshooting",
            "‚¨ÖÔ∏è Back to main menu"
        ]
    ).ask()
    
    if help_choice == "üìö General Overview":
        print("""
üß¨ GeoDatasetFinder CLI - General Overview

This tool helps you search for genomic datasets using semantic search and optional GPT filtering.

Key Features:
‚Ä¢ üîç Semantic search across 50,000+ microarray and RNA-seq datasets  
‚Ä¢ ü§ñ AI-powered filtering for differential expression analysis suitability
‚Ä¢ üíæ Automatic file caching for faster subsequent searches
‚Ä¢ üìä Customizable result filtering and detailed analysis
‚Ä¢ üìÅ CSV export with comprehensive metadata

Workflow:
1. Enter your disease/research query
2. Choose dataset type (microarray/RNA-seq)
3. Optionally apply GPT filtering for quality assessment
4. Review and export results
        """)
        
    elif help_choice == "üîç Search Tips":
        print("""
üîç Search Tips for Better Results

Query Best Practices:
‚Ä¢ Use specific disease names: "breast cancer" not just "cancer"
‚Ä¢ Include relevant terms: "alzheimer disease brain tissue"
‚Ä¢ Try synonyms if few results: "myocardial infarction" vs "heart attack"
‚Ä¢ Be concise: avoid very long complex queries

Examples of Good Queries:
‚Ä¢ "breast cancer"
‚Ä¢ "type 2 diabetes"
‚Ä¢ "alzheimer disease"
‚Ä¢ "lung cancer adenocarcinoma"
‚Ä¢ "inflammatory bowel disease"
‚Ä¢ "multiple sclerosis brain"

Dataset Types:
‚Ä¢ Microarray: Older technology, more datasets available
‚Ä¢ RNA-seq: Newer technology, better for novel transcript discovery
        """)
        
    elif help_choice == "ü§ñ GPT Filtering Guide":
        print("""
ü§ñ GPT Filtering Guide

Filter Types:
‚Ä¢ Basic: Simple suitable/not suitable classification
‚Ä¢ Enhanced: 3-tier system with detailed assessment (recommended)

Enhanced GPT Tiers:
‚Ä¢ Tier 1: Directly suitable for DE analysis
  - Primary human tissue samples
  - Clear case-control design  
  - Adequate sample sizes (‚â•5 per group)
  
‚Ä¢ Tier 2: Conditionally suitable  
  - Cell lines or smaller sample sizes
  - Mixed conditions but extractable comparisons
  - Animal models appropriate for the disease
  
‚Ä¢ Tier 3: Not suitable
  - No controls or inappropriate study design
  - Wrong tissue type for disease
  - Technical/methodological studies only

Configuration Tips:
‚Ä¢ Start with Tier 1 only for highest quality datasets
‚Ä¢ Add Tier 2 if you need more options
‚Ä¢ API key required - get one from OpenAI platform
        """)
        
    elif help_choice == "üíæ Cache Management":
        print("""
üíæ Cache Management

How Caching Works:
‚Ä¢ Files automatically downloaded from Hugging Face Hub on first use
‚Ä¢ Cached locally (~100-500MB per dataset type)
‚Ä¢ Subsequent searches are much faster

Cache Operations:
‚Ä¢ View Info: See cache location and size
‚Ä¢ Clear All: Remove all cached files (will re-download on next use)
‚Ä¢ Clear Specific: Remove cache for one dataset type only  
‚Ä¢ Preload: Download files before searching (recommended for first use)

Tips:
‚Ä¢ Preload datasets during off-hours for faster searches later
‚Ä¢ Clear cache if you suspect file corruption
‚Ä¢ Default cache location is user-specific temp directory
        """)
        
    elif help_choice == "üîß Troubleshooting":
        print("""
üîß Troubleshooting Common Issues

No Results Found:
‚Ä¢ Try broader or more specific query terms
‚Ä¢ Check spelling of disease names
‚Ä¢ Try different dataset type (microarray vs RNA-seq)
‚Ä¢ Lower GPT confidence threshold or add more tiers

API/GPT Errors:
‚Ä¢ Verify OpenAI API key is correct
‚Ä¢ Check API URL format: https://api.openai.com/v1/chat/completions
‚Ä¢ Ensure sufficient API credits/quota
‚Ä¢ Try reducing batch size (lower top_k)

Download/Cache Issues:
‚Ä¢ Check internet connection
‚Ä¢ Try clearing cache and re-downloading
‚Ä¢ Verify write permissions in cache directory
‚Ä¢ Check available disk space (need ~1GB free)

Performance Issues:
‚Ä¢ First run is slower due to downloads
‚Ä¢ Preload datasets during off-peak hours
‚Ä¢ Use SSD storage for cache if possible
‚Ä¢ Reduce top_k for faster processing
        """)
    
    elif help_choice == "‚¨ÖÔ∏è Back to main menu":
        return


def main():
    """Main CLI entry point with enhanced interface"""
    while True:
        choice = questionary.select(
            "\nüß¨ GeoDatasetFinder CLI - Main Menu:",
            choices=[
                "üîç Search for datasets",
                "üíæ Cache management", 
                "‚ùì Help & Guide",
                "üö™ Exit"
            ]
        ).ask()

        if choice == "üîç Search for datasets":
            search_command()
            
        elif choice == "üíæ Cache management":
            cache_management_menu()
            
        elif choice == "‚ùì Help & Guide":
            help_menu()
            
        elif choice == "üö™ Exit":
            print("""
üëã Thanks for using GeoDatasetFinder CLI!

üåü Found this tool useful? 
   Star us on GitHub: https://github.com/Tinfloz/geo-vector-search
   
üìö Need more help?
   Check our documentation for advanced usage examples
   
ü§ù Have feedback?
   Open an issue or submit a PR - we'd love to hear from you!
            """)
            break


if __name__ == "__main__":
    main()