{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d2176f0-9c8e-4f36-bb00-e6ed89a1aab9",
   "metadata": {},
   "source": [
    "# Welcome to syftr!\n",
    "\n",
    "## What is syftr?\n",
    "__syftr__ is an agent optimizer that helps you find the best agentic workflows for your budget. You bring your own dataset, compose the search space from models and components you have access to, and syftrer finds the best combination of parameters for your budget. \n",
    "\n",
    "## Getting started\n",
    "In this notebook we will guide you through your very first steps with __syftr__. First, review the `README.md` for initial environment setup - here we assume that it is done. If the setup is correct, you should not have any problems running this example. We won't be composing any new search spaces yet and use an existing example study, but we will be giving any explanations along the way.\n",
    "\n",
    "PLEASE NOTE that in order to function properly __syftr__ requires access to LLM APIs for inference and evaluation which aren't provided."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fbdb57-caa3-482a-ab6c-08d3585f3326",
   "metadata": {},
   "source": [
    "## Example study\n",
    "\n",
    "__syftr__ study configuration file is a YAML file that contains all necesssary information to run study successfully.\n",
    "\n",
    "It contains:\n",
    "* _name_: it is used as a job ID in the cluster and can be referred later on to get optimization results.\n",
    "* _dataset_: name, description, partitions spec, location. Used to describe the data location and data partitioning scheme.\n",
    "* _evaluation_: configure the evaluator for your task, such as judge LLM(s) and evaluation metric.\n",
    "* _optimization_: a section with technical parameters for optimization including number of trials, concurrency, batching of evaluation datasets etc.\n",
    "* _search_space_: this is a specification of search space of a current study. Includes agent types, embedding models, splitters rerankers and so on.\n",
    "* _toy_mode_: enables a variety of settings for rapid validation and debugging, such as limiting the grounding data and evaluation dataset sizes used.\n",
    "\n",
    "If parameter value is not specified in a study config file, the default value from `syftr/studies.py` will be used.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a300a2e-4dfb-4e84-8430-b8e3ddac0fc5",
   "metadata": {},
   "source": [
    "In this particular tutorial we will take a look at our example study that specifies some non-RAG and RAG workflows over _DRDocs_ dataset (a collection DataRobot API docs). \n",
    "Our goal is to run a study and get some meaniningful results. \n",
    "\n",
    "The number of trials is set to 10 to get you started and validate that __syftr__ is operational. We will use CPU only embedding models, disable advanced features like HyDE, , query decomposition and reranking. Also, we will use OpenAI only models. \n",
    "\n",
    "Overall, this search space will allow us to quickly compare how RAG workflows compare with using just models on _DRDocs_ dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917a2c5f-f6e5-41b9-940a-a049f9430a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../studies/example-dr-docs.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35d5fa5-09c5-4b5e-8211-163c13019321",
   "metadata": {},
   "source": [
    "## Running your first study\n",
    "\n",
    "__syftr__ has an easy-to-use Python API for interacting with the optimizer and analyzing results. In this section we will use the API to run the example study from the previous section. \n",
    "\n",
    "Let's create a study object from the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac572b14-2d98-4123-88cb-eeb05d5c6fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from syftr import api\n",
    "from syftr.configuration import cfg\n",
    "\n",
    "example_study = api.Study.from_file(cfg.paths.studies_dir / \"example-dr-docs.yaml\")\n",
    "example_study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6188d921-00fb-4efd-8cf2-c55622a221f4",
   "metadata": {},
   "source": [
    "We can see the name of study and that it is a local study, as `remote=False`. In this case __syftr__ will be run locally. \n",
    "\n",
    "A study object has `run()` method that can be used to start optimization. The method is non-blocking: it submits the current study to a Ray cluster and returns. If local mode is selected, a local Ray instance will be started automatically.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd60a58-33bf-4db9-94ff-845a04169c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_study.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b585774-1b37-4b03-92a0-3af889617fca",
   "metadata": {},
   "source": [
    "A study object has `wait_for_completion()` method that can be used to block execution until a study completes, but since we are in the Jupyter environment using it is not necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f2a4e1-2517-47d2-93e6-ac14b5dded46",
   "metadata": {},
   "outputs": [],
   "source": [
    "await example_study.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70788252-29e4-4efc-b88a-b7098c4cbc64",
   "metadata": {},
   "source": [
    "After the study job successfully completes, we can inspect its results. A `Study` object has `plot_pareto` method that shows the Pareto front visualization of a study.\n",
    "\n",
    "This plot highlights the best trade-offs between accuracy and cost. Each point represents a trial, and the gray ones are the ones that didn’t do as well compared to the ones on the Pareto front.\n",
    "\n",
    "In this case, using RAG gives better results than not using it. Workflows that used RAG tend to be closer to the Pareto front, meaning they achieve a better balance between accuracy and cost.\n",
    "\n",
    "GPT-3.5-turbo didn’t do as well as GPT-4-Mini, which lines up with what we’d expect, even if it comes with a higher cost.\n",
    "\n",
    "Overall, the plot gives a nice overview of which workflows are actually worth considering and which ones just aren’t competitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5a2c56-e979-4f36-8392-bac255374c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_study.plot_pareto()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460654eb-4638-41ba-b3fe-a54da6efbb94",
   "metadata": {},
   "source": [
    "In addition to `plot_pareto`, `pareto_flows` attribute returns __the Pareto front__ of a study: a set of flows with optimal accuracy and cost. Each flow has `metrics` attribute with resulting accuracy and cost, as well as `params` which contains the flow components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33858ef1-0a53-42ad-a234-9b167b024dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_study.pareto_flows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77627de7-8915-407e-95cf-ee5f1cdce37e",
   "metadata": {},
   "source": [
    "In addition to `pareto_flows`, a successfully completed study has an attribute `knee_point` which returns a [knee](https://en.wikipedia.org/wiki/Knee_of_a_curve) of the __syftr__'s Pareto front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b34a9f-8c4e-4e77-b29a-172f62c4e64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_study.knee_point"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syftr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
