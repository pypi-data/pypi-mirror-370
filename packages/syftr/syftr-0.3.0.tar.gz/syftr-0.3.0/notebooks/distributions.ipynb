{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions\n",
    "When computing confidence intervals that are used by the Pareto-Pruner, we assume that accuracy scores are normally and costs and latency scores are log-normally distributed. This notebook motivates the assumptions visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core import ultratb\n",
    "\n",
    "ultratb.VerboseTB.tb_highlight = \"bg:#3e0054\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STUDY_NAMES = [\n",
    "    \"rank1--alex--crag_hf-music\",\n",
    "    \"rank1--alex--crag_hf-sports\",\n",
    "    \"rank1--alex--drdocs_hf\",\n",
    "    \"rank1--alex--financebench_hf\",\n",
    "    \"rank1--alex--hotpotqa_hf-train_hard\",\n",
    "    \"rank1--alex--infinitebench_hf\",\n",
    " ]\n",
    "\n",
    "NAMES = {\n",
    "    \"rank1--alex--crag_hf-music\": \"CRAG3 Music\",\n",
    "    \"rank1--alex--crag_hf-sports\": \"CRAG3 Sports\",\n",
    "    \"rank1--alex--drdocs_hf\": \"DRDocs\",\n",
    "    \"rank1--alex--financebench_hf\": \"FinanceBench\",\n",
    "    \"rank1--alex--hotpotqa_hf-train_hard\": \"HotpotQA Train-Hard\",\n",
    "    \"rank1--alex--infinitebench_hf\": \"InfiniteBench\",\n",
    "}\n",
    "\n",
    "SUBSTRING = \"bench14--small-models\"\n",
    "PREFIX = SUBSTRING + \"--\"\n",
    "OBJECTIVE_2 = \"average cost\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from syftr.configuration import cfg\n",
    "\n",
    "distributions_dir = cfg.paths.results_dir / \"distributions\"\n",
    "distributions_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from syftr.optuna_helper import get_completed_trials\n",
    "\n",
    "df_trials = get_completed_trials(\n",
    "    study=STUDY_NAMES,\n",
    "    success_rate=0.9\n",
    ")\n",
    "# df_trials[[\"values_0\", \"values_1\", \"study_name\"]].to_csv(cfg.paths.results_dir / \"accuracy_and_latency.csv\", index=False)\n",
    "df_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import beta, norm\n",
    "\n",
    "\n",
    "def plot_accuracies(df_trials, study_name, approximation=\"normal\", p_start=0):\n",
    "    data = df_trials[df_trials[\"study_name\"] == study_name][\"values_0\"].values\n",
    "    percentile = np.percentile(data, p_start)\n",
    "    data_percentile = df_trials[\n",
    "        (df_trials[\"study_name\"] == study_name) & (df_trials[\"values_0\"] >= percentile)\n",
    "    ][\"values_0\"].values\n",
    "    mu, sigma = np.mean(data_percentile), np.std(data_percentile)\n",
    "    x = np.linspace(min(data_percentile), max(data_percentile), 100000)\n",
    "    \n",
    "    n_bins = int(np.sqrt(len(data_percentile)))\n",
    "    bins = np.linspace(x[0], x[-1], n_bins)\n",
    "    hist, bin_edges = np.histogram(data_percentile, bins=bins, density=True)\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "    _, ax = plt.subplots()\n",
    "    for i in range(len(hist)):\n",
    "        label = None if i != 0 else \"Average accuracy\"      \n",
    "        ax.bar(bin_centers[i], hist[i], width=bin_edges[i+1] - bin_edges[i], color='skyblue', label=label, alpha=0.6)\n",
    "    \n",
    "    if approximation == \"normal\":\n",
    "        approx = norm.pdf(x, mu, sigma)\n",
    "        approx_error = norm.pdf(bin_centers, mu, sigma)\n",
    "        mse = np.mean((hist - approx_error) ** 2)\n",
    "        if p_start > 0:\n",
    "            label = f\"{approximation.title()} approximation\\n$\\mu={mu:.2f}, \\sigma={sigma:.2f}$\\naccuracy $\\geq$ P{p_start}, MSE = {mse:.2f}\"\n",
    "        else:  \n",
    "            label = f\"{approximation.title()} approximation\\n$\\mu={mu:.2f}, \\sigma={sigma:.2f}$, MSE = {mse:.2f}\"\n",
    "    elif approximation == \"beta\":\n",
    "        a = mu * (mu * (1 - mu) / sigma ** 2 - 1)\n",
    "        b = a * (1 - mu) / mu\n",
    "        approx = beta.pdf(x, a, b)\n",
    "        approx_error = beta.pdf(bin_centers, a, b)\n",
    "        mse = np.mean((hist - approx_error) ** 2)\n",
    "        if p_start > 0:\n",
    "            label = f\"{approximation.title()} approximation\\n$a={a:.2f}, b={b:.2f}$\\naccuracy $\\geq$ P{p_start}, MSE = {mse:.2f}\"\n",
    "        else:\n",
    "            label = f\"{approximation.title()} approximation\\n$a={a:.2f}, b={b:.2f}$, MSE = {mse:.2f}\"\n",
    "    else:\n",
    "        approx = np.ones_like(x) * (100 - p_start) / (100 * (x[-1] - percentile)) if p_start > 0 else np.ones_like(x) / (x[-1] - percentile)\n",
    "        mse = np.mean((hist - approx[0]) ** 2)\n",
    "        if p_start > 0:\n",
    "            label = f\"{approximation.title()} approximation\\naccuracy $\\geq$ P{p_start}, MSE = {mse:.2f}\"\n",
    "        else:\n",
    "            label = f\"{approximation.title()} approximation\\nMSE = {mse:.2f}\"    \n",
    "    \n",
    "    plt.plot(x, approx, 'r', label=label)\n",
    "    plt.title(f\"Accuracy distribution for {NAMES[study_name]}\")\n",
    "    plt.xlabel(\"average accuracy\")\n",
    "    plt.ylabel(\"density\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(distributions_dir / f\"{study_name}-accuracy-distribution-{approximation}-p{p_start}.png\", dpi=300)\n",
    "    plt.savefig(distributions_dir / f\"{study_name}-accuracy-distribution-{approximation}-p{p_start}.pdf\", dpi=300)\n",
    "    plt.show()\n",
    "    return {\"Study\": study_name, \"Approximation\": approximation, \"MSE\": mse, \"P-Start\": p_start}\n",
    "\n",
    "\n",
    "errors = []\n",
    "for study_name in STUDY_NAMES:\n",
    "    errors.append(plot_accuracies(df_trials, study_name, approximation=\"normal\"))\n",
    "    # errors.append(plot_accuracies(df_trials, study_name, approximation=\"beta\"))\n",
    "    # errors.append(plot_accuracies(df_trials, study_name, approximation=\"uniform\"))\n",
    "    # errors.append(plot_accuracies(df_trials, study_name, approximation=\"normal\", p_start=20))\n",
    "    # errors.append(plot_accuracies(df_trials, study_name, approximation=\"beta\", p_start=20))\n",
    "    # errors.append(plot_accuracies(df_trials, study_name, approximation=\"uniform\", p_start=20))\n",
    "\n",
    "errors = pd.DataFrame(errors)\n",
    "errors.loc[errors.groupby(\"Study\").idxmin()[\"MSE\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import lognorm\n",
    "\n",
    "\n",
    "def plot_objective_2(df_trials, study_name, approximation):\n",
    "    data = df_trials[df_trials[\"study_name\"] == study_name][\"values_1\"].values\n",
    "    log_data = np.log(data)\n",
    "    mu, sigma = np.mean(log_data), np.std(log_data)\n",
    "    n_bins = 2 * int(np.sqrt(len(data)))\n",
    "    bins = np.logspace(np.log10(min(data)), np.log10(max(data)), n_bins+1)\n",
    "    hist, bin_edges = np.histogram(data, bins=bins, density=True)\n",
    "    plt.hist(data, bins=bins, density=True, alpha=0.6, color='skyblue', label=f\"{OBJECTIVE_2.title()}\")\n",
    "    bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "    x = np.linspace(min(data), max(data), 100000)\n",
    "    if approximation == \"log-normal\":\n",
    "        approx = lognorm.pdf(x, sigma, scale=np.exp(mu))\n",
    "        approx_error = lognorm.pdf(bin_centers, sigma, scale=np.exp(mu))\n",
    "        mse = np.mean((hist - approx_error) ** 2)\n",
    "        label = f'{approximation.title()} Approximation\\n$\\mu={mu:.2f}, \\sigma={sigma:.2f}$'\n",
    "    else:\n",
    "        raise ValueError(f\"Approximation {approximation} not supported\")\n",
    "    plt.plot(x, approx, 'r', label=label)\n",
    "    plt.xscale('log')\n",
    "    # plt.yscale('log')\n",
    "    plt.title(f\"{OBJECTIVE_2.title()} Distribution for {NAMES[study_name]}\")\n",
    "    plt.xlabel(f\"{OBJECTIVE_2} (log scale)\")\n",
    "    plt.ylabel(\"density\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "    plt.savefig(distributions_dir / f\"{study_name}-{OBJECTIVE_2}-distribution.png\", dpi=300)\n",
    "    plt.savefig(distributions_dir / f\"{study_name}-{OBJECTIVE_2}-distribution.pdf\", dpi=300)\n",
    "    plt.show()\n",
    "    return {\"Study\": study_name, \"Approximation\": \"log-normal\", \"MSE\": mse}\n",
    "\n",
    "\n",
    "errors = []\n",
    "for study_name in STUDY_NAMES:\n",
    "    errors.append(plot_objective_2(df_trials, study_name, approximation=\"log-normal\"))\n",
    "errors = pd.DataFrame(errors)\n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syftr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
