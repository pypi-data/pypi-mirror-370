{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insights\n",
    "The insights notebook is our main tool to visualize syfter results.\n",
    "1. Edit the **study_names** and **focus_study** values to analyze at the end of the notebook \n",
    "    * (either edit the regex filters or put in specific study names)\n",
    "2. Run all cells in the notebook (click \"Run All\"), everything should just work\n",
    "3. It will display all charts in the notebook \n",
    "4. It also writes a PDF in the **/results** folder that you can share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qq \"dataframe_image>=0.2.7\" diskcache adjustText seaborn statsmodels altair[all]\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.getcwd().endswith(\"syftr\"):\n",
    "    os.chdir(os.path.dirname(os.getcwd()))\n",
    "    print(f\"Changed working directory to: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, display\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from syftr.configuration import cfg\n",
    "from syftr.optuna_helper import get_study_names\n",
    "from syftr.plotting.insights import ( # noqa\n",
    "    CACHE, accuracy_plot,\n",
    "    all_parameters_all_studies_plot,\n",
    "    append_figure, append_table, compute_plot,\n",
    "    compute_trial_rate_plot, cost_plot,\n",
    "    create_benchmark_plot_and_table,\n",
    "    create_exceptions_table, descriptive_name,\n",
    "    focus_over_time_plot, get_name,\n",
    "    latency_plot, load_studies,\n",
    "    param_pareto_plot, param_plot,\n",
    "    param_plot_all_studies, pareto_area_plot,\n",
    "    pareto_comparison_plot,\n",
    "    pareto_plot_and_table, plot_all_paretos,\n",
    "    plot_metric_variability,\n",
    "    plot_retriever_pareto,\n",
    "    slowest_components_plot,\n",
    "    study_similarity_all_pairs_plot,\n",
    "    study_similarity_all_pairs_scatters_plot,\n",
    "    study_similarity_plot,\n",
    "    trial_duration_hist\n",
    ")\n",
    "\n",
    "pd.set_option(\"mode.chained_assignment\", \"raise\")\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "warnings.simplefilter(action=\"error\", category=FutureWarning)\n",
    "np.seterr(over='ignore')\n",
    "\n",
    "\n",
    "async def create_pdf_report(study_name, all_study_names=None, pdf_filename=None, titles=None, insights_prefix=None):\n",
    "    # load all studies\n",
    "    df, study_stats_table, exceptions_table = load_studies(all_study_names)\n",
    "    df_study = df[df[\"study_name\"] == study_name]\n",
    "\n",
    "    # show most interesting parameters first then append others\n",
    "    param_cols = [\n",
    "        (\n",
    "            \"params_rag_mode\",\n",
    "            \"params_llm_name\",\n",
    "            \"params_template_name\",\n",
    "        ),\n",
    "        \"params_rag_mode\",\n",
    "        \"params_llm_name\",\n",
    "        \"params_template_name\",\n",
    "        \"params_rag_method\",\n",
    "        \"params_rag_embedding_model\",\n",
    "        \"params_splitter_method\",\n",
    "        \"params_splitter_chunk_exp\",\n",
    "        \"params_splitter_chunk_overlap_frac\",\n",
    "        \"params_rag_top_k\",\n",
    "        \"params_reranker_enabled\",\n",
    "        \"params_hyde_enabled\",\n",
    "    ]\n",
    "    param_cols += [\n",
    "        c\n",
    "        for c in df_study.columns\n",
    "        if c.startswith(\"params_\") and c not in param_cols\n",
    "    ]\n",
    "    def valid_param_set(cols, df):\n",
    "        if isinstance(cols, str):\n",
    "            cols = [cols]\n",
    "        for c in cols:\n",
    "            if c not in df.columns:\n",
    "                return False\n",
    "            if df[c].nunique(dropna=False) <= 1:\n",
    "                return False\n",
    "        return True\n",
    "    param_cols = [c for c in param_cols if valid_param_set(c, df)]\n",
    "\n",
    "    # start writing a pdf report\n",
    "    if pdf_filename is None:\n",
    "        cfg.paths.results_dir.mkdir(parents=True, exist_ok=True)\n",
    "        path = cfg.paths.results_dir.resolve()\n",
    "        pdf_filename = str(path / f\"insights_{study_name}.pdf\")\n",
    "    with PdfPages(pdf_filename) as pdf:\n",
    "        display(Markdown(f\"# Benchmark Summary\"))\n",
    "\n",
    "        # study stats table\n",
    "        await append_table(pdf, study_stats_table, title=\"Study Stats\")\n",
    "\n",
    "        # exceptions table\n",
    "        table = create_exceptions_table(df, exceptions_table)\n",
    "        await append_table(pdf, table, title=\"Top Exceptions\")\n",
    "\n",
    "        # error here if the focus study isn't valid\n",
    "        if len(df_study) == 0:\n",
    "            raise ValueError(f\"The focus study '{study_name}' contains 0 trials.\")\n",
    "\n",
    "        # benchmark accuracy table\n",
    "        fig, table = create_benchmark_plot_and_table(df)\n",
    "        if fig is not None:\n",
    "            append_figure(pdf, fig, insights_prefix)\n",
    "        if table is not None:\n",
    "            await append_table(pdf, table, title=\"Benchmark Performance\")\n",
    "\n",
    "        # metric variability chart\n",
    "        fig = plot_metric_variability(df, study_name)\n",
    "        if fig is not None:\n",
    "            append_figure(pdf, fig, insights_prefix)\n",
    "\n",
    "        display(Markdown(f\"# Pareto Frontier\"))\n",
    "\n",
    "        # all pareto fronts\n",
    "        if \"retriever-only\" in study_name:\n",
    "            fig, title = plot_retriever_pareto(df, study_name, titles=titles)\n",
    "        else:\n",
    "            fig, title = plot_all_paretos(df, all_study_names, titles=titles)\n",
    "        append_figure(pdf, fig, insights_prefix, title=title)\n",
    "\n",
    "        # pareto front with descriptions\n",
    "        fig, table, fig_title = pareto_plot_and_table(df, study_name, titles=titles)\n",
    "        append_figure(pdf, fig, insights_prefix, title=fig_title)\n",
    "        await append_table(pdf, table, title=f\"Pareto Frontier ({get_name(study_name, titles)})\")\n",
    "\n",
    "        display(Markdown(f\"# Optimization Progress\"))\n",
    "\n",
    "        # optimization focus over time\n",
    "        fig = focus_over_time_plot(df, study_name, titles=titles)\n",
    "        append_figure(pdf, fig, insights_prefix)\n",
    "\n",
    "        # compute trial rate plot\n",
    "        fig = compute_trial_rate_plot(df, study_name, titles=titles)\n",
    "        append_figure(pdf, fig, insights_prefix)\n",
    "\n",
    "        # compute plot\n",
    "        fig = compute_plot(df, study_name, titles=titles)\n",
    "        append_figure(pdf, fig, insights_prefix)\n",
    "\n",
    "        # cost plot\n",
    "        fig = cost_plot(df, study_name, titles=titles)\n",
    "        append_figure(pdf, fig, insights_prefix)\n",
    "        \n",
    "        # hist of trials\n",
    "        fig = trial_duration_hist(df, study_name, titles=titles)\n",
    "        append_figure(pdf, fig, insights_prefix)\n",
    "\n",
    "        # historical pareto plots\n",
    "        fig = pareto_comparison_plot(df, study_name, titles=titles)\n",
    "        if fig is not None:\n",
    "            append_figure(pdf, fig, insights_prefix)\n",
    "\n",
    "        # pareto area plot\n",
    "        fig = pareto_area_plot(df, study_name, titles=titles)\n",
    "        append_figure(pdf, fig, insights_prefix)\n",
    "\n",
    "        # accuracy plot\n",
    "        fig = accuracy_plot(df, study_name, titles=titles)\n",
    "        append_figure(pdf, fig, insights_prefix)\n",
    "\n",
    "        # latency plot\n",
    "        fig = latency_plot(df, study_name)\n",
    "        if fig is not None:\n",
    "            append_figure(pdf, fig, insights_prefix)\n",
    "\n",
    "        display(Markdown(f\"# Parameter Analysis\"))\n",
    "\n",
    "        # plot summary of all params\n",
    "        fig, title = all_parameters_all_studies_plot(df, param_cols, group_col='study_name', titles=titles)\n",
    "        append_figure(pdf, fig, insights_prefix, title=title)\n",
    "\n",
    "        # plots for each parameter\n",
    "        for param_col in param_cols:\n",
    "            display(Markdown(f\"### {descriptive_name(param_col)} ({param_col}):\"))\n",
    "\n",
    "            # param stats across all studies\n",
    "            # if df[\"study_name\"].nunique() > 1:\n",
    "            #     fig, title = param_plot_all_studies(df, study_name, param_col)\n",
    "            #     if fig is not None:\n",
    "            #         append_figure(pdf, fig, insights_prefix, title=title)\n",
    "\n",
    "            # param stats of invidual study\n",
    "            fig, title = param_plot(df, study_name, param_col, titles=titles)\n",
    "            append_figure(pdf, fig, insights_prefix, title=title)\n",
    "\n",
    "            # parameter pareto frontier for individual study\n",
    "            if (\n",
    "                isinstance(param_col, str)\n",
    "                and df[param_col].dtype == \"O\"\n",
    "                and df[param_col].nunique(dropna=False) <= 10\n",
    "            ):\n",
    "                fig, title = param_pareto_plot(df, study_name, param_col, titles=titles)\n",
    "                append_figure(pdf, fig, insights_prefix, title=title)\n",
    "\n",
    "        display(Markdown(f\"# Study Similarity Analysis\"))\n",
    "\n",
    "        if df[\"study_name\"].nunique() > 1:\n",
    "            # single study similar to all others\n",
    "            fig = study_similarity_plot(df, study_name, titles=titles)\n",
    "            append_figure(pdf, fig, insights_prefix)\n",
    "\n",
    "            # correlation matrix of all studies\n",
    "            fig = study_similarity_all_pairs_plot(df, study_name, titles=titles)\n",
    "            append_figure(pdf, fig, insights_prefix)\n",
    "\n",
    "        #     # matrix display of scatter plots\n",
    "        #     # fig, title = study_similarity_all_pairs_scatters_plot(df, study_name, titles=titles)\n",
    "        #     # append_figure(pdf, fig, insights_prefix, title=title)\n",
    "\n",
    "        display(Markdown(f\"# Miscellaneous Analysis\"))\n",
    "\n",
    "        # plot slowest components and params\n",
    "        fig = slowest_components_plot(df, study_name)\n",
    "        append_figure(pdf, fig, insights_prefix)\n",
    "\n",
    "    return pdf_filename\n",
    "\n",
    "\n",
    "async def filter_studies_and_generate_report(include_regex, exclude_regex, focus_regex, reset_cache, titles, insights_prefix=None):\n",
    "    # cache\n",
    "    if reset_cache:\n",
    "        CACHE.clear()\n",
    "        print(\"Cache cleared.\")\n",
    "    print(f\"Cache volume: {CACHE.volume():,} bytes\\n\")\n",
    "\n",
    "    # filter the study names\n",
    "    study_names = get_study_names(\n",
    "        include_regex=include_regex, \n",
    "        exclude_regex=exclude_regex,\n",
    "    )\n",
    "\n",
    "    # find the focus study\n",
    "    focus_study = None\n",
    "    for pattern in focus_regex:\n",
    "        match = next((s for s in study_names if re.match(pattern, s)), None)\n",
    "        if match is not None:\n",
    "            focus_study = match\n",
    "            break\n",
    "    if focus_study is None:\n",
    "        raise ValueError(\"No matching study found for given focus_regex\")\n",
    "\n",
    "    # generate charts and report\n",
    "    print(f'Analyzing the focus study \"{focus_study}\" compared to {len(study_names)} other studies:')\n",
    "    print(\"    \" + \"\\n    \".join(study_names) + \"\\n\")\n",
    "    pdf_filename = await create_pdf_report(focus_study, all_study_names=study_names, titles=titles, insights_prefix=insights_prefix)\n",
    "    full_path = os.path.abspath(pdf_filename)\n",
    "    print(f\"Report saved to: {full_path}\")\n",
    "    print(\"Done!\", flush=True)\n",
    "    return full_path\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# EDIT BELOW: pick which by study names and generate the report\n",
    "await filter_studies_and_generate_report(\n",
    "    include_regex=[\n",
    "        # \".*seeding1--training .*\",\n",
    "        # \".*seeding1--testing.*\",\n",
    "        \"stefan--example1--small-study--drdocs_hf\",\n",
    "    ],\n",
    "    exclude_regex=[\n",
    "    ],\n",
    "    focus_regex=[\n",
    "        # \".*financebench.*\",\n",
    "        \".*\",  # use first matching study\n",
    "    ],\n",
    "    reset_cache=True,\n",
    "    titles={\n",
    "        \"cerebras4--rag-and-agents-cerebras-only--financebench_hf\": \"FinanceBench (Cerebras RAG and Agents)\",\n",
    "        \"cerebras4--rag-and-agents-local-only--financebench_hf\": \"FinanceBench (Local RAG and Agents)\",\n",
    "        \"cerebras4--rag-and-agents-cerebras-only--phantomwikiv050_hf--depth_20_size_10000_seed_3\": \"PhantomWiki (Cerebras RAG and Agents)\",\n",
    "        \"cerebras4--rag-and-agents-local-only--phantomwikiv050_hf--depth_20_size_10000_seed_3\": \"PhantomWiki (Local RAG and Agents)\",\n",
    "        \"cerebras5--rag-and-agents-cerebras-only--financebench_hf\": \"FinanceBench (Cerebras RAG and Agents)\",\n",
    "        \"cerebras5--rag-and-agents-local-only--financebench_hf\": \"FinanceBench (Local RAG and Agents)\",\n",
    "        \"cerebras5--rag-and-agents-cerebras-only--phantomwikiv050_hf--depth_20_size_10000_seed_3\": \"PhantomWiki (Cerebras RAG and Agents)\",\n",
    "        \"cerebras5--rag-and-agents-local-only--phantomwikiv050_hf--depth_20_size_10000_seed_3\": \"PhantomWiki (Local RAG and Agents)\",\n",
    "    },\n",
    "    insights_prefix=\"\",  # the name prefix for exported figures\n",
    ")\n",
    "# EDIT ABOVE # ^^\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging:\n",
    "---\n",
    "```python\n",
    "# Get and filter study names\n",
    "study_names = optuna.get_all_study_names(storage=cfg.postgres.get_optuna_storage())\n",
    "study_names = [s for s in study_names if re.match(r'^bench10.*', s) is not None] # include filter\n",
    "study_names = [s for s in study_names if re.match(r'.*synthetic_.*', s) is None] # exclude filter\n",
    "\n",
    "# Load raw studies from optuna\n",
    "def load_raw_study(name):\n",
    "    df = optuna.load_study(study_name=name, storage=cfg.postgres.get_optuna_storage()).trials_dataframe()\n",
    "    df['study_name'] = name\n",
    "    return df\n",
    "df = pd.concat([load_raw_study(name) for name in tqdm.tqdm(study_names)])\n",
    "display(df.T)\n",
    "\n",
    "# Load prepared studies\n",
    "study_names = ['bench14--batch-1--financebench']\n",
    "df, study_stats_table, exceptions_table = load_studies(study_names, only_successful_trials=False)\n",
    "display(df.T)\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_names = [\n",
    "#     'bench14--batch-1--financebench',\n",
    "# ]\n",
    "# df, study_stats_table, exceptions_table = load_studies(study_names, only_successful_trials=False)\n",
    "# # print(df.loc[df[df.params_rag_mode == \"rag\"].values_0.idxmax()].user_attrs_flow)\n",
    "# rag_only_df = df[df.params_rag_mode == \"rag\"]\n",
    "# for index, row in rag_only_df.iterrows():\n",
    "#     print(row['user_attrs_flow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df, study_stats_table, exceptions_table  = load_studies([\n",
    "#     \"bench13--batch-1--crag-music\",\n",
    "#     \"bench13--batch-1--financebench\",\n",
    "#     \"bench13--batch-1--hotpot-train-hard\",\n",
    "#     \"bench13--batch-1--infinitebench\",\n",
    "# ])\n",
    "\n",
    "# param_cols = [col for col in df.columns if col.startswith('params_') or 'prun' in col]\n",
    "# corrs_table = what_correlates_with(df[param_cols], df['values_0'] == 0)\n",
    "\n",
    "# pd.set_option(\"display.max_rows\", 400)\n",
    "# display(corrs_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syftr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
