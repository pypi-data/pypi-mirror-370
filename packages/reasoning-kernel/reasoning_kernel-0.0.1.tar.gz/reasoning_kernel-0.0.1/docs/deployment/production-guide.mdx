---
title: "Production Deployment Guide"
description: "Comprehensive guide for deploying Reasoning Kernel to production"
---

# Production Deployment Guide

## üöÄ Deployment Overview

The Reasoning Kernel is designed for enterprise production deployments with comprehensive security, scalability, and observability features. This guide covers Docker, Kubernetes, and cloud deployment strategies.

## üèóÔ∏è Architecture Requirements

### **System Requirements**

#### **Minimum Requirements**
- **CPU**: 4 cores (8 threads)
- **Memory**: 8GB RAM
- **Storage**: 50GB SSD
- **Network**: 1 Gbps connection
- **OS**: Ubuntu 20.04+, RHEL 8+, or container runtime

#### **Recommended Production**
- **CPU**: 8+ cores (16+ threads)
- **Memory**: 16-32GB RAM
- **Storage**: 200GB+ SSD with backup
- **Network**: 10 Gbps connection with redundancy
- **OS**: Container orchestration platform (Kubernetes)

### **External Dependencies**

#### **Required Services**
```yaml
services:
  redis:
    version: "7.0+"
    memory: "4GB+"
    persistence: enabled
    
  azure_openai:
    models: ["gpt-4", "text-embedding-ada-002"]
    quota: "high_volume"
    
  daytona_sandbox:
    endpoint: "https://api.daytona.io"
    authentication: "api_key"
```

#### **Optional Services**
```yaml
monitoring:
  prometheus: "metrics collection"
  grafana: "visualization dashboards"
  jaeger: "distributed tracing"
  
logging:
  elk_stack: "log aggregation"
  splunk: "enterprise logging"
```

## üê≥ Docker Deployment

### **Production Dockerfile**

```dockerfile
# Multi-stage build for production optimization
FROM python:3.12-slim as builder

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Install UV for fast dependency management
RUN pip install uv

# Set working directory
WORKDIR /app

# Copy dependency files
COPY pyproject.toml uv.lock ./

# Install dependencies in virtual environment
RUN uv venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"
RUN uv pip install --no-cache -e .

# Production stage
FROM python:3.12-slim as production

# Install runtime dependencies
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Create non-root user
RUN groupadd -r reasoning && useradd -r -g reasoning reasoning

# Copy virtual environment from builder
COPY --from=builder /opt/venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"

# Set working directory
WORKDIR /app

# Copy application code
COPY --chown=reasoning:reasoning . .

# Create necessary directories
RUN mkdir -p /app/logs /app/data && \
    chown -R reasoning:reasoning /app

# Switch to non-root user
USER reasoning

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Expose port
EXPOSE 8000

# Set environment variables
ENV PYTHONPATH="/app"
ENV PYTHONUNBUFFERED=1
ENV LOG_LEVEL=INFO

# Start application
CMD ["uvicorn", "reasoning_kernel.main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "4"]
```

### **Docker Compose for Development**

```yaml
version: '3.8'

services:
  reasoning-kernel:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    ports:
      - "8000:8000"
    environment:
      - LOG_LEVEL=INFO
      - REDIS_URL=redis://redis:6379/0
      - AZURE_OPENAI_API_KEY=${AZURE_OPENAI_API_KEY}
      - AZURE_OPENAI_ENDPOINT=${AZURE_OPENAI_ENDPOINT}
      - API_KEY_ENABLED=true
      - RATE_LIMITING_ENABLED=true
    depends_on:
      - redis
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
      - ./redis.conf:/usr/local/etc/redis/redis.conf
    command: redis-server /usr/local/etc/redis/redis.conf
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
    restart: unless-stopped

volumes:
  redis_data:
  prometheus_data:
  grafana_data:
```

### **Production Docker Compose**

```yaml
version: '3.8'

services:
  reasoning-kernel:
    image: reasoning-kernel:${VERSION:-latest}
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      update_config:
        parallelism: 1
        delay: 10s
    ports:
      - "8000-8002:8000"
    environment:
      - LOG_LEVEL=INFO
      - REDIS_URL=redis://redis:6379/0
      - API_KEY_ENABLED=true
      - FORCE_HTTPS=true
      - RATE_LIMITING_ENABLED=true
      - CORS_ALLOW_ORIGINS=https://your-domain.com
    secrets:
      - azure_openai_key
      - session_secret
    healthcheck:
      test: ["CMD", "curl", "-f", "https://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  nginx:
    image: nginx:alpine
    ports:
      - "443:443"
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/ssl/certs
    depends_on:
      - reasoning-kernel
    restart: unless-stopped

secrets:
  azure_openai_key:
    external: true
  session_secret:
    external: true
```

## ‚ò∏Ô∏è Kubernetes Deployment

### **Namespace Configuration**

```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: reasoning-kernel
  labels:
    name: reasoning-kernel
    environment: production
---
apiVersion: v1
kind: ResourceQuota
metadata:
  name: reasoning-kernel-quota
  namespace: reasoning-kernel
spec:
  hard:
    requests.cpu: "8"
    requests.memory: 16Gi
    limits.cpu: "16"
    limits.memory: 32Gi
    pods: "10"
    services: "5"
```

### **ConfigMap & Secrets**

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: reasoning-kernel-config
  namespace: reasoning-kernel
data:
  LOG_LEVEL: "INFO"
  API_KEY_ENABLED: "true"
  RATE_LIMITING_ENABLED: "true"
  FORCE_HTTPS: "true"
  MAX_WORKERS: "4"
  REDIS_DB: "0"
  CORS_ALLOW_ORIGINS: "https://your-domain.com"
  PROMETHEUS_METRICS_ENABLED: "true"
---
apiVersion: v1
kind: Secret
metadata:
  name: reasoning-kernel-secrets
  namespace: reasoning-kernel
type: Opaque
stringData:
  AZURE_OPENAI_API_KEY: "your-azure-openai-key"
  AZURE_OPENAI_ENDPOINT: "https://your-instance.openai.azure.com/"
  REDIS_URL: "redis://redis:6379/0"
  SESSION_SECRET: "your-session-secret-key"
  ADMIN_API_KEY: "rk_admin_key_for_bootstrap"
```

### **Redis Deployment**

```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: redis
  namespace: reasoning-kernel
spec:
  serviceName: redis
  replicas: 1
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
    spec:
      containers:
      - name: redis
        image: redis:7-alpine
        ports:
        - containerPort: 6379
        resources:
          requests:
            cpu: 500m
            memory: 1Gi
          limits:
            cpu: 1000m
            memory: 2Gi
        volumeMounts:
        - name: redis-data
          mountPath: /data
        - name: redis-config
          mountPath: /usr/local/etc/redis/redis.conf
          subPath: redis.conf
        readinessProbe:
          exec:
            command: ["redis-cli", "ping"]
          initialDelaySeconds: 5
          periodSeconds: 5
        livenessProbe:
          exec:
            command: ["redis-cli", "ping"]
          initialDelaySeconds: 30
          periodSeconds: 30
      volumes:
      - name: redis-config
        configMap:
          name: redis-config
  volumeClaimTemplates:
  - metadata:
      name: redis-data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 10Gi
      storageClassName: ssd
---
apiVersion: v1
kind: Service
metadata:
  name: redis
  namespace: reasoning-kernel
spec:
  selector:
    app: redis
  ports:
  - port: 6379
    targetPort: 6379
  type: ClusterIP
```

### **Main Application Deployment**

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: reasoning-kernel
  namespace: reasoning-kernel
  labels:
    app: reasoning-kernel
    version: v1.0.0
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  selector:
    matchLabels:
      app: reasoning-kernel
  template:
    metadata:
      labels:
        app: reasoning-kernel
        version: v1.0.0
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8000"
        prometheus.io/path: "/metrics"
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 1000
      containers:
      - name: reasoning-kernel
        image: reasoning-kernel:1.0.0
        ports:
        - containerPort: 8000
          name: http
        env:
        - name: REDIS_URL
          valueFrom:
            secretKeyRef:
              name: reasoning-kernel-secrets
              key: REDIS_URL
        - name: AZURE_OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: reasoning-kernel-secrets
              key: AZURE_OPENAI_API_KEY
        - name: AZURE_OPENAI_ENDPOINT
          valueFrom:
            secretKeyRef:
              name: reasoning-kernel-secrets
              key: AZURE_OPENAI_ENDPOINT
        envFrom:
        - configMapRef:
            name: reasoning-kernel-config
        resources:
          requests:
            cpu: 1000m
            memory: 2Gi
          limits:
            cpu: 2000m
            memory: 4Gi
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 3
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 30
          timeoutSeconds: 5
        volumeMounts:
        - name: logs
          mountPath: /app/logs
        - name: tmp
          mountPath: /tmp
      volumes:
      - name: logs
        emptyDir: {}
      - name: tmp
        emptyDir: {}
      terminationGracePeriodSeconds: 30
      restartPolicy: Always
---
apiVersion: v1
kind: Service
metadata:
  name: reasoning-kernel
  namespace: reasoning-kernel
  labels:
    app: reasoning-kernel
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8000"
spec:
  selector:
    app: reasoning-kernel
  ports:
  - port: 80
    targetPort: 8000
    protocol: TCP
    name: http
  type: ClusterIP
```

### **Ingress Configuration**

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: reasoning-kernel-ingress
  namespace: reasoning-kernel
  annotations:
    kubernetes.io/ingress.class: "nginx"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    nginx.ingress.kubernetes.io/rate-limit: "100"
    nginx.ingress.kubernetes.io/rate-limit-window: "1m"
spec:
  tls:
  - hosts:
    - api.reasoning-kernel.com
    secretName: reasoning-kernel-tls
  rules:
  - host: api.reasoning-kernel.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: reasoning-kernel
            port:
              number: 80
```

### **Horizontal Pod Autoscaler**

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: reasoning-kernel-hpa
  namespace: reasoning-kernel
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: reasoning-kernel
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15
      - type: Pods
        value: 4
        periodSeconds: 15
      selectPolicy: Max
```

## üîí Security Configuration

### **Network Policies**

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: reasoning-kernel-network-policy
  namespace: reasoning-kernel
spec:
  podSelector:
    matchLabels:
      app: reasoning-kernel
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: ingress-nginx
    - podSelector:
        matchLabels:
          app: prometheus
    ports:
    - protocol: TCP
      port: 8000
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: redis
    ports:
    - protocol: TCP
      port: 6379
  - to: []
    ports:
    - protocol: TCP
      port: 443
    - protocol: TCP
      port: 53
    - protocol: UDP
      port: 53
```

### **Pod Security Policy**

```yaml
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: reasoning-kernel-psp
spec:
  privileged: false
  allowPrivilegeEscalation: false
  requiredDropCapabilities:
    - ALL
  volumes:
    - 'configMap'
    - 'emptyDir'
    - 'projected'
    - 'secret'
    - 'downwardAPI'
    - 'persistentVolumeClaim'
  runAsUser:
    rule: 'MustRunAsNonRoot'
  supplementalGroups:
    rule: 'MustRunAs'
    ranges:
      - min: 1
        max: 65535
  fsGroup:
    rule: 'MustRunAs'
    ranges:
      - min: 1
        max: 65535
```

## üå©Ô∏è Cloud Deployment Options

### **AWS EKS Deployment**

```yaml
# eks-cluster.yaml
apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

metadata:
  name: reasoning-kernel-cluster
  region: us-west-2

nodeGroups:
  - name: reasoning-kernel-nodes
    instanceType: m5.xlarge
    minSize: 3
    maxSize: 10
    desiredCapacity: 3
    volumeSize: 100
    ssh:
      enableSsm: true
    iam:
      withAddonPolicies:
        autoScaler: true
        cloudWatch: true
        ebs: true
        efs: true

addons:
  - name: vpc-cni
  - name: coredns
  - name: kube-proxy
  - name: aws-ebs-csi-driver
```

### **Azure AKS Deployment**

```bash
# Create resource group
az group create --name reasoning-kernel-rg --location eastus

# Create AKS cluster
az aks create \
  --resource-group reasoning-kernel-rg \
  --name reasoning-kernel-aks \
  --node-count 3 \
  --node-vm-size Standard_D4s_v3 \
  --enable-addons monitoring \
  --enable-autoscaler \
  --min-count 3 \
  --max-count 10 \
  --generate-ssh-keys

# Get credentials
az aks get-credentials \
  --resource-group reasoning-kernel-rg \
  --name reasoning-kernel-aks
```

### **Google GKE Deployment**

```bash
# Create GKE cluster
gcloud container clusters create reasoning-kernel-cluster \
  --zone us-central1-a \
  --machine-type e2-standard-4 \
  --num-nodes 3 \
  --enable-autoscaling \
  --min-nodes 3 \
  --max-nodes 10 \
  --enable-autorepair \
  --enable-autoupgrade

# Get credentials
gcloud container clusters get-credentials reasoning-kernel-cluster \
  --zone us-central1-a
```

## üîß Environment Configuration

### **Production Environment Variables**

```bash
# Core Configuration
LOG_LEVEL=INFO
PYTHONUNBUFFERED=1
MAX_WORKERS=4
WORKER_TIMEOUT=300

# Security Settings
API_KEY_ENABLED=true
FORCE_HTTPS=true
RATE_LIMITING_ENABLED=true
REQUEST_VALIDATION_ENABLED=true
AUDIT_LOGGING_ENABLED=true
CORS_ALLOW_ORIGINS=https://your-domain.com

# Redis Configuration
REDIS_URL=redis://redis:6379/0
REDIS_MAX_CONNECTIONS=100
REDIS_TIMEOUT=30

# AI Model Configuration
AZURE_OPENAI_API_KEY=your-key
AZURE_OPENAI_ENDPOINT=https://your-instance.openai.azure.com/
AZURE_OPENAI_DEPLOYMENT=gpt-4
AZURE_OPENAI_API_VERSION=2024-02-15-preview

# Performance Settings
CACHE_TTL_HOURS=1
MAX_CONCURRENT_REQUESTS=100
REQUEST_TIMEOUT=120

# Monitoring
PROMETHEUS_METRICS_ENABLED=true
OPENTELEMETRY_ENABLED=true
JAEGER_ENDPOINT=http://jaeger:14268/api/traces
```

### **Configuration Validation Script**

```python
#!/usr/bin/env python3
"""Production configuration validation script"""

import os
import sys
import redis
from urllib.parse import urlparse

def validate_config():
    """Validate production configuration"""
    errors = []
    
    # Required environment variables
    required_vars = [
        'AZURE_OPENAI_API_KEY',
        'AZURE_OPENAI_ENDPOINT',
        'REDIS_URL',
        'SESSION_SECRET'
    ]
    
    for var in required_vars:
        if not os.getenv(var):
            errors.append(f"Missing required environment variable: {var}")
    
    # Validate Redis connection
    try:
        redis_url = os.getenv('REDIS_URL')
        if redis_url:
            r = redis.from_url(redis_url)
            r.ping()
            print("‚úÖ Redis connection successful")
        else:
            errors.append("REDIS_URL not configured")
    except Exception as e:
        errors.append(f"Redis connection failed: {e}")
    
    # Security configuration validation
    if os.getenv('FORCE_HTTPS', '').lower() != 'true':
        errors.append("FORCE_HTTPS should be enabled in production")
    
    if os.getenv('API_KEY_ENABLED', '').lower() != 'true':
        errors.append("API_KEY_ENABLED should be enabled in production")
    
    # CORS validation
    cors_origins = os.getenv('CORS_ALLOW_ORIGINS', '')
    if '*' in cors_origins and os.getenv('ENVIRONMENT') == 'production':
        errors.append("Wildcard CORS origins not allowed in production")
    
    if errors:
        print("‚ùå Configuration validation failed:")
        for error in errors:
            print(f"  - {error}")
        sys.exit(1)
    else:
        print("‚úÖ Configuration validation passed")

if __name__ == "__main__":
    validate_config()
```

## üìä Monitoring & Observability

### **Prometheus Configuration**

```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'reasoning-kernel'
    static_configs:
      - targets: ['reasoning-kernel:8000']
    metrics_path: '/metrics'
    scrape_interval: 15s
    
  - job_name: 'redis'
    static_configs:
      - targets: ['redis:6379']
    
  - job_name: 'kubernetes-pods'
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
```

### **Grafana Dashboard**

```json
{
  "dashboard": {
    "title": "Reasoning Kernel Production Dashboard",
    "panels": [
      {
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{endpoint}}"
          }
        ]
      },
      {
        "title": "Response Time",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          }
        ]
      },
      {
        "title": "Error Rate",
        "type": "singlestat",
        "targets": [
          {
            "expr": "rate(http_requests_total{status=~\"5..\"}[5m]) / rate(http_requests_total[5m])",
            "legendFormat": "Error Rate"
          }
        ]
      }
    ]
  }
}
```

## üö® Deployment Checklist

### **Pre-Deployment**
- [ ] Environment variables configured and validated
- [ ] Secrets properly managed (Azure Key Vault, K8s Secrets)
- [ ] Redis cluster configured with persistence
- [ ] SSL/TLS certificates provisioned
- [ ] DNS records configured
- [ ] Load balancer configured
- [ ] Monitoring stack deployed (Prometheus, Grafana)
- [ ] Log aggregation configured
- [ ] Backup strategy implemented

### **Security Checklist**
- [ ] API keys generated for admin bootstrapping
- [ ] Rate limiting enabled and configured
- [ ] Input validation enabled
- [ ] Audit logging enabled
- [ ] CORS origins properly restricted
- [ ] HTTPS enforcement enabled
- [ ] Security headers configured
- [ ] Network policies applied (Kubernetes)

### **Performance Checklist**
- [ ] Resource limits and requests configured
- [ ] Horizontal Pod Autoscaler configured
- [ ] Circuit breakers configured for external services
- [ ] Caching layer operational
- [ ] Database connection pooling configured
- [ ] Performance monitoring alerts configured

### **Post-Deployment**
- [ ] Health checks passing
- [ ] API endpoints responding correctly
- [ ] Reasoning pipeline functional
- [ ] Security system operational
- [ ] Monitoring dashboards operational
- [ ] Log aggregation working
- [ ] Backup verification completed
- [ ] Performance baseline established
- [ ] Security scan completed
- [ ] Documentation updated

## üîÑ Deployment Automation

### **CI/CD Pipeline (GitHub Actions)**

```yaml
name: Production Deployment

on:
  push:
    tags:
      - 'v*'

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
      
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2
      
    - name: Login to Container Registry
      uses: docker/login-action@v2
      with:
        registry: ${{ secrets.CONTAINER_REGISTRY }}
        username: ${{ secrets.REGISTRY_USERNAME }}
        password: ${{ secrets.REGISTRY_PASSWORD }}
        
    - name: Build and push Docker image
      uses: docker/build-push-action@v4
      with:
        context: .
        push: true
        tags: |
          ${{ secrets.CONTAINER_REGISTRY }}/reasoning-kernel:${{ github.ref_name }}
          ${{ secrets.CONTAINER_REGISTRY }}/reasoning-kernel:latest
        cache-from: type=gha
        cache-to: type=gha,mode=max
        
    - name: Configure kubectl
      uses: azure/k8s-set-context@v1
      with:
        method: kubeconfig
        kubeconfig: ${{ secrets.KUBECONFIG }}
        
    - name: Deploy to Kubernetes
      run: |
        sed -i 's|IMAGE_TAG|${{ github.ref_name }}|g' k8s/deployment.yaml
        kubectl apply -f k8s/
        kubectl rollout status deployment/reasoning-kernel -n reasoning-kernel
        
    - name: Run post-deployment tests
      run: |
        kubectl wait --for=condition=ready pod -l app=reasoning-kernel -n reasoning-kernel --timeout=300s
        ./scripts/smoke-test.sh ${{ secrets.PRODUCTION_URL }}
```

This comprehensive deployment guide provides everything needed to deploy the Reasoning Kernel to production with enterprise-grade security, monitoring, and scalability.
