#!/usr/bin/env python3
"""
Mac M2/M3 Apple Silicon ä¸“ç”¨å¯åŠ¨è„šæœ¬
Qwen3-4B-Thinking-2507 åŒ»å­¦LLMå¾®è°ƒ
"""

import os
import sys
import torch
import psutil
from pathlib import Path
from medical_llm_trainer import MedicalLLMTrainer
import warnings

# æŠ‘åˆ¶MPSç›¸å…³è­¦å‘Š
warnings.filterwarnings("ignore", category=UserWarning, module="torch")

def check_system_requirements():
    """æ£€æŸ¥ç³»ç»Ÿè¦æ±‚"""
    print("=== ç³»ç»Ÿç¯å¢ƒæ£€æŸ¥ ===")
    
    # æ£€æŸ¥Pythonç‰ˆæœ¬
    python_version = sys.version_info
    print(f"Pythonç‰ˆæœ¬: {python_version.major}.{python_version.minor}.{python_version.micro}")
    
    # æ£€æŸ¥å†…å­˜
    memory = psutil.virtual_memory()
    print(f"ç³»ç»Ÿå†…å­˜: {memory.total // (1024**3)} GB (å¯ç”¨: {memory.available // (1024**3)} GB)")
    
    # æ£€æŸ¥PyTorchå’ŒMPS
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    
    if torch.backends.mps.is_available():
        print("âœ“ Apple Silicon MPS å¯ç”¨")
        device = "mps"
    elif torch.cuda.is_available():
        print(f"âœ“ CUDA å¯ç”¨: {torch.cuda.get_device_name(0)}")
        device = "cuda"
    else:
        print("âš ï¸ ä»…CPUå¯ç”¨")
        device = "cpu"
    
    print(f"æ¨èè®­ç»ƒè®¾å¤‡: {device}")
    
    # å†…å­˜å»ºè®®
    if memory.total < 16 * (1024**3):  # å°äº16GB
        print("âš ï¸ å†…å­˜è¾ƒå°ï¼Œå»ºè®®ä½¿ç”¨æ›´å°çš„batch_sizeå’Œmax_length")
    
    return device

def optimize_for_mac_m2():
    """Mac M2ä¼˜åŒ–è®¾ç½®"""
    print("\n=== Mac M2 ä¼˜åŒ–è®¾ç½® ===")
    
    # è®¾ç½®MPSç¯å¢ƒå˜é‡
    os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
    os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'
    
    # æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒ
    if os.environ.get('VIRTUAL_ENV'):
        print(f"âœ“ è™šæ‹Ÿç¯å¢ƒå·²æ¿€æ´»: {os.environ['VIRTUAL_ENV']}")
    else:
        print("âš ï¸ å»ºè®®ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ")
        print("è¯·è¿è¡Œ: source venv/bin/activate")
    
    print("âœ“ MPSä¼˜åŒ–è®¾ç½®å·²åº”ç”¨")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ Mac M2/M3 Qwen3-4B-Thinking-2507 åŒ»å­¦LLMå¾®è°ƒ")
    print("=" * 50)
    
    # ç³»ç»Ÿæ£€æŸ¥
    device = check_system_requirements()
    
    # Mac M2ä¼˜åŒ–
    optimize_for_mac_m2()
    
    # æ£€æŸ¥Unslothå¯ç”¨æ€§
    print("\n=== æ£€æŸ¥åŠ é€Ÿåº“ ===")
    try:
        from unsloth import FastModel
        unsloth_available = True
        print("âœ“ Unslothå¯ç”¨ - å°†ä½¿ç”¨åŠ é€Ÿè®­ç»ƒ")
    except ImportError:
        unsloth_available = False
        print("âš ï¸ Unslothä¸å¯ç”¨ - ä½¿ç”¨æ ‡å‡†è®­ç»ƒ")
    
    # é…ç½®è®­ç»ƒå‚æ•°
    print("\n=== é…ç½®è®­ç»ƒå‚æ•° ===")
    
    # Mac M2ä¼˜åŒ–é…ç½®
    config = {
        "model_name": "Qwen/Qwen3-4B-Thinking-2507",
        "output_dir": "./medical_llm_output_mac_m2",
        "use_qlora": False,  # Mac M2å»ºè®®å…³é—­é‡åŒ–
        "max_seq_length": 1024,  # é™ä½ä»¥èŠ‚çœå†…å­˜
        "use_unsloth": unsloth_available
    }
    
    # æ ¹æ®å†…å­˜è°ƒæ•´é…ç½®
    memory_gb = psutil.virtual_memory().total // (1024**3)
    if memory_gb < 16:
        config["max_seq_length"] = 512
        print("âš ï¸ å†…å­˜è¾ƒå°ï¼Œé™ä½max_seq_lengthåˆ°512")
    
    print(f"æ¨¡å‹: {config['model_name']}")
    print(f"é‡åŒ–: {'å…³é—­' if not config['use_qlora'] else 'å¼€å¯'}")
    print(f"åºåˆ—é•¿åº¦: {config['max_seq_length']}")
    print(f"UnslothåŠ é€Ÿ: {'å¼€å¯' if config['use_unsloth'] else 'å…³é—­'}")
    
    # åˆå§‹åŒ–è®­ç»ƒå™¨
    print("\n=== åˆå§‹åŒ–è®­ç»ƒå™¨ ===")
    try:
        trainer = MedicalLLMTrainer(**config)
        print("âœ“ è®­ç»ƒå™¨åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âœ— è®­ç»ƒå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        print("\nå»ºè®®:")
        print("1. æ£€æŸ¥æ˜¯å¦åœ¨è™šæ‹Ÿç¯å¢ƒä¸­: source venv/bin/activate")
        print("2. é‡æ–°è¿è¡Œå®‰è£…è„šæœ¬: ./setup_qwen3.sh")
        print("3. å¦‚æœå†…å­˜ä¸è¶³ï¼Œå°è¯•å…³é—­å…¶ä»–åº”ç”¨ç¨‹åº")
        return
    
    # æµ‹è¯•æ¨ç†
    print("\n=== æµ‹è¯•æ¨ç†èƒ½åŠ› ===")
    test_text = "Helicobacter pylori infection causes gastric inflammation and is linked to peptic ulcers."
    
    try:
        print("æµ‹è¯•æ€è€ƒæ¨¡å¼æ¨ç†...")
        result = trainer.inference(test_text, max_length=256, enable_thinking=True)
        print(f"âœ“ æ¨ç†æˆåŠŸ")
        print(f"ç»“æœé¢„è§ˆ: {result[:100]}...")
    except Exception as e:
        print(f"âš ï¸ æ¨ç†æµ‹è¯•å¤±è´¥: {e}")
        print("è¿™å¯èƒ½æ˜¯å†…å­˜ä¸è¶³æˆ–æ¨¡å‹åŠ è½½é—®é¢˜")
    
    # è®­ç»ƒå»ºè®®
    print("\n=== è®­ç»ƒå»ºè®® ===")
    print("Mac M2/M3 è®­ç»ƒé…ç½®å»ºè®®:")
    print("- batch_size: 1")
    print("- gradient_accumulation_steps: 8")
    print("- max_seq_length: 1024 (æˆ–æ›´å°)")
    print("- use_qlora: False (é¿å…é‡åŒ–é—®é¢˜)")
    print("- å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹")
    print("- ç›‘æ§å†…å­˜ä½¿ç”¨æƒ…å†µ")
    
    print("\nå¼€å§‹å®Œæ•´è®­ç»ƒè¯·è¿è¡Œ:")
    print("python medical_llm_trainer.py")
    print("\næˆ–ä½¿ç”¨Mac M2ä¼˜åŒ–é…ç½®:")
    print("python medical_llm_trainer.py --config config_mac_m2.yaml")

if __name__ == "__main__":
    main()
