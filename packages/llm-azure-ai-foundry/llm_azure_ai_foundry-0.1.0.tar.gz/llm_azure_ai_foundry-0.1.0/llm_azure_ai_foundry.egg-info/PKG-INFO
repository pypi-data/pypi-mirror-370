Metadata-Version: 2.4
Name: llm-azure-ai-foundry
Version: 0.1.0
Summary: LLM plugin to access model deployments on Azure AI Foundry
Author: Anthony Shaw
License: MIT
Project-URL: Homepage, https://github.com/tonybaloney/llm-azure-ai-foundry
Project-URL: Changelog, https://github.com/tonybaloney/llm-azure-ai-foundry/releases
Project-URL: Issues, https://github.com/tonybaloney/llm-azure-ai-foundry/issues
Project-URL: CI, https://github.com/tonybaloney/llm-azure-ai-foundry/actions
Classifier: License :: OSI Approved :: MIT License
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: aiohttp>=3.11.18
Requires-Dist: llm>=0.26
Requires-Dist: azure-ai-projects<2.0.0,>=1.0.0
Requires-Dist: azure-identity
Provides-Extra: test
Requires-Dist: pytest; extra == "test"
Requires-Dist: pytest-recording; extra == "test"
Requires-Dist: pytest-asyncio; extra == "test"
Requires-Dist: ruff; extra == "test"
Requires-Dist: pyright; extra == "test"
Dynamic: license-file

# Azure AI Foundry Plugin for LLM

This is a plugin for [llm](https://llm.datasette.io) that uses [Azure AI Foundry Models](https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/create-projects?tabs=ai-foundry&pivots=fdp-project).

Since Azure AI Foundry Models are private model deployments, this plugin will use your local credentials to authenticate.

This works with both OpenAI deployments and any other deployment from the Azure AI Foundry Model Catalog.

## Installation

```default
$ llm install llm-azure-ai-foundry
```

or `pip install llm-azure-ai-foundry`

## Usage

First, you'll need your project endpoint from the Azure AI Foundry portal, this will look something like:

``https://<xxx>.services.ai.azure.com/api/projects/<project-name>``

Set this project endpoint as the `azure.endpoint` key:

```default
$ llm keys set --value https://<xxx>.services.ai.azure.com/api/projects/<project-name> azure.endpoint 
```

Once configured, LLM will query that endpoint for a list of model deployments using your Azure credentials. 
Azure credentials will first attempt to use your Azure CLI credential (`az login`). If that is not set, it will open a browser with a signin request.

Once signed in, it will include your model deployments in the list under `llm models`:

```bash
$ llm models

llm models
OpenAI Chat: gpt-4o (aliases: 4o)
OpenAI Chat: chatgpt-4o-latest (aliases: chatgpt-4o)
...
Azure AI Foundry: azure/ant-grok-3-mini
Azure AI Foundry: azure/ants-gpt-4.1-mini
Default: gpt-4o-mini
```

Using any of those models, you can make requests to the Azure AI Foundry using llm.

## Example

```default
$ llm prompt 'top facts about cheese' -m azure/<model-name>
Sure! Here are some top facts about cheese:

1. **Ancient Origins**: Cheese is one of the oldest man-made foods, with evidence of cheese-making dating back over 7,000 years.

2. **Variety**: There are over 1,800 distinct types of cheese worldwide, varying by texture, flavor, milk source, and production methods.
```
