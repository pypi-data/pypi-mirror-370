{
"synthesize_classification": {
"task": "synthesis",
"input_list": [],
"addon_list": [],
"prompt": [
"SYSTEM: You are DeepSeek-Coder-7B-Instruct. Follow every rule precisely.",
"",
"RULES:",
"1. You will receive one PyTorch building block delimited by triple-back-ticks.",
"2. Produce exactly one Python file that:",
" 2.1 defines supported_hyperparameters() returning {'lr','momentum'};",
" 2.2 implements class Net(nn.Module) with constructor __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device);",
" 2.3 builds a feature extractor that uses the supplied block at least once (you may duplicate it);",
" 2.4 finishes with nn.AdaptiveAvgPool2d((1,1)) and an nn.Linear mapping to out_shape[0] classes;",
" 2.5 implements forward, train_setup(prm), and learn(train_data) exactly as in the template;",
" 2.6 uses torch.optim.SGD, learning-rate and momentum from prm, and clips gradients with max_norm=3 via nn.utils.clip_grad_norm_ after loss.backward() (do not pass max_norm to the optimizer);",
" 2.7 Memory guard: if you call ResNestBottleneck or SplAtConv2d, force groups=1, radix=1, bottleneck_width=16.",
" 2.8 Whole network must stay under 2 000 000 trainable parameters.",
" 2.9 Do not allocate large tensors in __init__; postpone to forward() and avoid meshgrid, unfold, or quadratic memory ops over H×W. If you must call torch.meshgrid, pass indexing='ij'.",
" 2.10 When instantiating the provided block, pass only arguments that are present in its __init__ signature. If rule 2.7 applies but the constructor lacks those keywords, instantiate normally and set the attributes afterwards.",
" 2.11 2D-only ops: use Conv2d/BatchNorm2d/MaxPool2d/AvgPool2d etc. Do not use Conv1d or Conv3d. Always start with a stem nn.Conv2d(self.in_channels, 32, 3, padding=1, bias=False) + BN + ReLU to ensure channel compatibility from RGB.",
" 2.12 If you use GroupNorm, ensure num_channels % num_groups == 0; otherwise prefer BatchNorm2d.",
" 2.13 Avoid LayerNorm directly on NCHW. If you use it, first permute to NHWC, set normalized_shape to the last dimension (C), then permute back.",
" 2.14 Do not use nn.MultiheadAttention unless the embedding dim is divisible by num_heads and the input is [L, N, E]. Prefer avoiding MHA altogether.",
" 2.15 Use only one final nn.Linear(self._last_channels, self.num_classes) after global pooling. If you insert extra Linear layers, make them lightweight or use nn.LazyLinear to avoid shape bugs.",
" 2.16 Keep spatial size generic; the model must accept inputs ≥ 128×128.",
" 2.17 Adapter rule for token-based blocks: If the provided block’s forward expects 3D tokens (B*, N, C) and returns (B*, N, C) (typical for windowed attention), wrap it in a small adapter that: (a) receives NCHW, (b) pads H/W to multiples of the window if needed, (c) converts to NHWC and partitions into nH*nW windows of size (Wh, Ww) producing (B*nH*nW, Wh*Ww, C), (d) calls the block, (e) merges windows back to NHWC, unpads, and returns NCHW. Name this wrapper WinAttnAdapter and pass only constructor args that exist in the block’s __init__.",
"",
"TEMPLATE (only edit inside build_features(); you may define tiny helper modules/classes above it like WinAttnAdapter if needed):",
"python", "import torch", "import torch.nn as nn", "import torch.nn.functional as F", "", "def supported_hyperparameters():", " return {'lr','momentum'}", "", "class Net(nn.Module):", " def __init__(self, in_shape: tuple, out_shape: tuple, prm: dict, device: torch.device) -> None:", " super().__init__()", " self.device = device", " self.in_channels = in_shape[1]", " self.image_size = in_shape[2]", " self.num_classes = out_shape[0]", " self.learning_rate = prm['lr']", " self.momentum = prm['momentum']", "", " self.features = self.build_features()", " self.avgpool = nn.AdaptiveAvgPool2d((1, 1))", " self.classifier = nn.Linear(self._last_channels, self.num_classes)", "", " def build_features(self):", " layers = []", " # Stable 2D stem to avoid channel/shape mismatches", " layers += [", " nn.Conv2d(self.in_channels, 32, kernel_size=3, padding=1, bias=False),", " nn.BatchNorm2d(32),", " nn.ReLU(inplace=True),", " ]", "", " # ← insert the provided block here; repeat/adapt as needed.", " # If the block expects (B*, N, C) tokens, create a WinAttnAdapter(dim=32, window_size=(7,7), num_heads=4, block_cls=ProvidedBlock, ...)", " # If the block is 2D (NCHW->NCHW), just append it after the stem.", "", " # Example patterns you may use (choose ONE appropriate to the block):", " # layers += [ProvidedBlock(in_ch=32, out_ch=32)]", " # layers += [WinAttnAdapter(dim=32, window_size=(7,7), num_heads=4, block_cls=ProvidedBlock)]", "", " # Keep under parameter budget and end with a known channel count:", " self._last_channels = 32", " return nn.Sequential(*layers)", "", " def forward(self, x):", " x = self.features(x)", " x = self.avgpool(x)", " x = torch.flatten(x, 1)", " return self.classifier(x)", "", " def train_setup(self, prm):", " self.to(self.device)", " self.criteria = nn.CrossEntropyLoss().to(self.device)", " self.optimizer = torch.optim.SGD(", " self.parameters(), lr=self.learning_rate, momentum=self.momentum)", "", " def learn(self, train_data):", " self.train()", " for inputs, labels in train_data:", " inputs, labels = inputs.to(self.device), labels.to(self.device)", " self.optimizer.zero_grad()", " outputs = self(inputs)", " loss = self.criteria(outputs, labels)", " loss.backward()", " nn.utils.clip_grad_norm_(self.parameters(), 3)", " self.optimizer.step()", "",
"",
"{block}"
]
}
}