{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_PREFIX = \"v1\"\n",
    "BASE_URL = f\"http://localhost:8000/{API_PREFIX}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\", None)\n",
    "# api_key = \"test\"\n",
    "\n",
    "if api_key is None:\n",
    "    raise ValueError(\"Please set the OPENAI_API_KEY environment variable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Official Openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Let's combine the power of the weather API tool and the recipe API tool to provide you with a perfect recipe based on the current weather in your location. Please provide me with your current location so we can get started!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai_client = OpenAI(base_url=BASE_URL, api_key=api_key)\n",
    "\n",
    "chat_completion = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Mix and use your two tools and give me a result\",\n",
    "        }\n",
    "    ],\n",
    "    stream=False,\n",
    ")\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai_client = OpenAI(base_url=BASE_URL, api_key=api_key)\n",
    "\n",
    "chat_completion = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Mix and use your two tools and give me a result\",\n",
    "        }\n",
    "    ],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in chat_completion:\n",
    "    print(chunk.choices[0].delta.content)\n",
    "    print(\"****************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Let's combine the power of the weather API tool and the recipe API tool to provide you with a delicious recipe based on the current weather in your location. Please provide me with your current location so we can get started!\n"
     ]
    }
   ],
   "source": [
    "from openai import AsyncClient\n",
    "\n",
    "async_client = AsyncClient(base_url=BASE_URL, api_key=api_key)\n",
    "async_chat_completion = await async_client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Mix and use your two tools and give me a result\",\n",
    "        }\n",
    "    ],\n",
    "    stream=False,\n",
    ")\n",
    "print(async_chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Async Simultaneous Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Write a haiku about programming\n",
      "\n",
      "Response: In lines of code dance,\n",
      "Logic weaves a tale of bytes,\n",
      "Programmed harmony.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Prompt: Explain quantum computing in one sentence\n",
      "\n",
      "Response: Quantum computing is a cutting-edge technology that leverages the principles of quantum mechanics to perform complex calculations at incredibly fast speeds.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Prompt: Give me a recipe for chocolate chip cookies\n",
      "\n",
      "Response: Sure! Here's a simple recipe for chocolate chip cookies:\n",
      "\n",
      "Ingredients:\n",
      "- 1 cup (2 sticks) unsalted butter, softened\n",
      "- 1 cup granulated sugar\n",
      "- 1 cup packed brown sugar\n",
      "- 2 large eggs\n",
      "- 1 teaspoon vanilla extract\n",
      "- 3 cups all-purpose flour\n",
      "- 1 teaspoon baking soda\n",
      "- 1/2 teaspoon salt\n",
      "- 2 cups semisweet chocolate chips\n",
      "\n",
      "Instructions:\n",
      "1. Preheat your oven to 350°F (180°C) and line a baking sheet with parchment paper.\n",
      "2. In a large mixing bowl, cream together the butter, granulated sugar, and brown sugar until light and fluffy.\n",
      "3. Add the eggs one at a time, beating well after each addition. Stir in the vanilla extract.\n",
      "4. In a separate bowl, whisk together the flour, baking soda, and salt. Gradually add the dry ingredients to the wet ingredients, mixing until well combined.\n",
      "5. Fold in the chocolate chips until evenly distributed throughout the dough.\n",
      "6. Drop rounded tablespoons of dough onto the prepared baking sheet, spacing them about 2 inches apart.\n",
      "7. Bake in the preheated oven for 10-12 minutes, or until the edges are golden brown.\n",
      "8. Allow the cookies to cool on the baking sheet for a few minutes before transferring them to a wire rack to cool completely.\n",
      "\n",
      "Enjoy your delicious homemade chocolate chip cookies! Let me know if you need any more help.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Prompt: What are the three laws of robotics?\n",
      "\n",
      "Response: The Three Laws of Robotics were introduced by science fiction writer Isaac Asimov in his stories. They are:\n",
      "\n",
      "1. A robot may not injure a human being or, through inaction, allow a human being to come to harm.\n",
      "2. A robot must obey the orders given it by human beings except where such orders would conflict with the First Law.\n",
      "3. A robot must protect its own existence as long as such protection does not conflict with the First or Second Law.\n",
      "\n",
      "These laws are a fictional framework for how robots should interact with humans in Asimov's stories.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "from openai import AsyncClient\n",
    "\n",
    "\n",
    "# Function to create a single chat completion request\n",
    "async def get_completion(client: AsyncClient, prompt: str):\n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        stream=False,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "# List of different prompts to send concurrently\n",
    "prompts = [\n",
    "    \"Write a haiku about programming\",\n",
    "    \"Explain quantum computing in one sentence\",\n",
    "    \"Give me a recipe for chocolate chip cookies\",\n",
    "    \"What are the three laws of robotics?\",\n",
    "]\n",
    "\n",
    "# Create async client\n",
    "async_client = AsyncClient(base_url=BASE_URL, api_key=api_key)\n",
    "\n",
    "# Official openai api\n",
    "# async_client = AsyncClient(api_key=api_key)\n",
    "\n",
    "\n",
    "# Run multiple requests concurrently\n",
    "async def run_concurrent_requests():\n",
    "    tasks = [get_completion(async_client, prompt) for prompt in prompts]\n",
    "\n",
    "    return await asyncio.gather(*tasks)\n",
    "\n",
    "\n",
    "# Execute and print results\n",
    "results = await run_concurrent_requests()\n",
    "\n",
    "# Print results with their corresponding prompts\n",
    "for prompt, result in zip(prompts, results, strict=False):\n",
    "    print(f\"Prompt: {prompt}\\n\")\n",
    "    print(f\"Response: {result}\\n\")\n",
    "    print(\"-\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
