========
Showcase
========

In this section, we collect publications, tutorials, and other resources that have used small-text.

----

.. contents:: Overview
   :depth: 1
   :local:
   :backlinks: none

----

Papers
------

2024
^^^^

- | Lukas Kriesch and Sebastian Losacker. 2024.
  | `A global patent dataset of bioeconomy-related inventions <https://doi.org/10.1038/s41597-024-04163-6>`_
  | In: Scientific Data Volume 11, Article number: 1308.

- | David Hanny, Sebastian Schmidt, and Bernd Resch. 2024.
  | `Active Learning for Identifying Disaster-Related Tweets: A Comparison with Keyword Filtering and Generic Fine-Tuning. <https://doi.org/10.1007/978-3-031-66428-1_8>`_
  | In: Intelligent Systems and Applications (IntelliSys 2024). Lecture Notes in Networks and Systems, pages 126â€“142.

- | Muhammad Afzal, Jamil Hussain, Asim Abbas, Maqbool Hussain, Muhammad Attique, and Sungyoung Lee. 2024.
  | `Transformer-based active learning for multi-class text annotation and classification. <https://doi.org/10.1177/20552076241287357>`_
  | In: DIGITAL HEALTH Volume 10.

2023
^^^^

- | David Kartchner, Irfan Al-Hussaini, Haydn Turner, Jennifer Deng, Shubham Lohiya, Prasanth Bathala, and Cassie S. Mitchell. 2023.
  | `BioSift: A Dataset for Filtering Biomedical Abstracts for Drug Repurposing and Clinical Meta-Analysis. <https://dl.acm.org/doi/10.1145/3539618.3591897>`_
  | In: Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 2913â€“2923.

- | Klaus Schmidt, Andreas Niekler, Cathleen Kantner, and Manuel Burghardt. 2023.
  | `Classifying Speech Acts in Political Communication: A Transformer-based Approach with Weak Supervision and Active Learning <http://dx.doi.org/10.15439/2023F3485>`_
  | In: Proceedings of the 18th Conference on Computer Science and Intelligence Systems, ACSIS, Vol. 35, pages 739â€“748.

2022
^^^^

- | Hannah Kirk, Bertie Vidgen, and Scott Hale. 2022.
  | `Is More Data Better? Re-thinking the Importance of Efficiency in Abusive Language Detection with Transformers-Based Active Learning. <https://aclanthology.org/2022.trac-1.7/>`_
  | In Proceedings of the Third Workshop on Threat, Aggression and Cyberbullying (TRAC 2022), pages 52â€“61, Gyeongju, Republic of Korea. Association for Computational Linguistics.

- | Julius Gonsior, Christian Falkenberg, Silvio Magino, Anja Reusch, Maik Thiele, and Wolfgang Lehner. 2022.
  | `To Softmax, or not to Softmax: that is the question when applying Active Learning for Transformer Models. <https://arxiv.org/abs/2210.03005>`_
  | ArXiv, abs/2210.03005.

- | Julia Romberg and Tobias Escher. 2022.
  | `Automated Topic Categorisation of Citizensâ€™ Contributions: Reducing Manual Labelling Efforts Through Active Learning. <https://link.springer.com/chapter/10.1007/978-3-031-15086-9_24>`_
  | In EGOV 2022: Electronic Government, pages 369â€“385, Cham. Springer International Publishing.

- | Christopher SchrÃ¶der, Andreas Niekler, and Martin Potthast. 2022.
  | `Revisiting Uncertainty-based Query Strategies for Active Learning with Transformers. <https://aclanthology.org/2022.findings-acl.172/>`_
  | In Findings of the Association for Computational Linguistics: ACL 2022, pages 2194â€“2203.

Tutorials
---------

- | `ðŸ‘‚ Active learning for text classification with small-text <https://docs.v1.argilla.io/en/latest/tutorials/notebooks/training-textclassification-smalltext-activelearning.html>`_
